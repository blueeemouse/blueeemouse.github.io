<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueeemouse.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="0.abstract PLM（Pretrained Language Models）对于信息检索领域的帮助，主要在于提高了文本的表征能力，能提取出更好的embedding，从而帮助之后的相关性建模（这种把文本用embedding来表征的方法叫dense retrieval） 这篇论文会从四个角度来介绍dense retrieval：architecture，training，index">
<meta property="og:type" content="article">
<meta property="og:title" content="Dense Text Retrieval based on Pretrained Language Models：A Survey">
<meta property="og:url" content="https://blueeemouse.github.io/2025/05/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/IR/Dense%20Text%20Retrieval%20based%20on%20Pretrained%20Language%20Models%EF%BC%9AA%20Survey/index.html">
<meta property="og:site_name" content="bluemouse&#39;s blog">
<meta property="og:description" content="0.abstract PLM（Pretrained Language Models）对于信息检索领域的帮助，主要在于提高了文本的表征能力，能提取出更好的embedding，从而帮助之后的相关性建模（这种把文本用embedding来表征的方法叫dense retrieval） 这篇论文会从四个角度来介绍dense retrieval：architecture，training，index">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-05-15T14:54:00.000Z">
<meta property="article:modified_time" content="2025-05-16T08:33:54.746Z">
<meta property="article:author" content="bluemouse">
<meta property="article:tag" content="Information Retrieval">
<meta property="article:tag" content="survey">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueeemouse.github.io/2025/05/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/IR/Dense%20Text%20Retrieval%20based%20on%20Pretrained%20Language%20Models%EF%BC%9AA%20Survey/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Dense Text Retrieval based on Pretrained Language Models：A Survey | bluemouse's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">bluemouse's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/05/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/IR/Dense%20Text%20Retrieval%20based%20on%20Pretrained%20Language%20Models%EF%BC%9AA%20Survey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Dense Text Retrieval based on Pretrained Language Models：A Survey
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-05-15 22:54:00" itemprop="dateCreated datePublished" datetime="2025-05-15T22:54:00+08:00">2025-05-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-05-16 16:33:54" itemprop="dateModified" datetime="2025-05-16T16:33:54+08:00">2025-05-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/IR/" itemprop="url" rel="index"><span itemprop="name">IR</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="abstract">0.abstract</h1>
<h2 id="plmpretrained-language-models对于信息检索领域的帮助主要在于提高了文本的表征能力能提取出更好的embedding从而帮助之后的相关性建模这种把文本用embedding来表征的方法叫dense-retrieval">PLM（Pretrained
Language
Models）对于信息检索领域的帮助，主要在于提高了文本的表征能力，能提取出更好的embedding，从而帮助之后的相关性建模（这种把文本用embedding来表征的方法叫dense
retrieval）</h2>
<h2 id="这篇论文会从四个角度来介绍dense-retrievalarchitecturetrainingindexingintegration最后总结一下主流技术">这篇论文会从四个角度来介绍dense
retrieval：architecture，training，indexing，integration，最后总结一下主流技术</h2>
<span id="more"></span>
<h1 id="intro">1.intro</h1>
<h2 id="核心主题密集文本检索通过-plm-学习查询和文本的稠密向量表示基于语义匹配实现高效检索是传统稀疏检索如-bm25的重要演进">-
<strong>核心主题</strong>：密集文本检索通过 PLM
学习查询和文本的稠密向量表示，基于语义匹配实现高效检索，是传统稀疏检索（如
BM25）的重要演进。</h2>
<h2 id="发展脉络">- <strong>发展脉络</strong>：</h2>
<h3 id="传统方法向量空间模型vsm倒排索引概率模型如-bm25依赖词法匹配难以处理复杂语义">-
<strong>传统方法</strong>：向量空间模型（VSM）、倒排索引、概率模型（如
BM25）依赖词法匹配，难以处理复杂语义。</h3>
<h3 id="机器学习方法这里相当于进一步会用传统的机器学习方法来建模关系引入监督学习但依赖人工特征传统ml就是依赖人手工设计的特征">-
<strong>机器学习方法</strong>：这里相当于进一步，会用传统的机器学习方法来建模关系，引入监督学习，但依赖人工特征。（传统ml就是依赖人手工设计的特征）</h3>
<h3 id="神经网络与-plm神经信息检索neural-ir通过稠密向量实现语义匹配此时又需要区分一下大模型出现以前一般都是用一些小网络来提取embedding的可以称为pre-bert-model而大模型出现之后它的表达能力比以前的小模型显著提升了因此提取文本embedding的能力大幅度提升了大模型也在各大ir榜单上刷榜了故推动密集检索成为主流">-
<strong>神经网络与 PLM</strong>：神经信息检索（Neural
IR）通过稠密向量实现语义匹配，此时又需要区分一下，大模型出现以前，一般都是用一些小网络来提取embedding的，可以称为pre-Bert
model，而大模型出现之后，它的表达能力比以前的小模型显著提升了，因此提取文本embedding的能力大幅度提升了，大模型也在各大IR榜单上刷榜了，故推动密集检索成为主流。</h3>
<h3 id="密集检索优势通过-plm-捕捉深层语义解决术语不匹配问题尤其适用于复杂查询如开放域问答一些复杂的语义层面上的问题还想依靠以前的lexical-matching也就是词汇匹配那一套应该是不太行的比如很可能会有词汇上完全不搭界但语义上却是完全一致或非常类似的情况">-
<strong>密集检索优势</strong>：通过 PLM
捕捉深层语义，解决术语不匹配问题，尤其适用于复杂查询（如开放域问答）。（一些复杂的语义层面上的问题，还想依靠以前的lexical
matching，也就是词汇匹配那一套，应该是不太行的。比如，很可能会有词汇上完全不搭界，但语义上却是完全一致或非常类似的情况）</h3>
<h1 id="overview">2.overview</h1>
<h2 id="这里主要介绍ir里的任务设定术语和记号">这里主要介绍IR里的任务设定、术语和记号、</h2>
<h2 id="任务设定和术语">2.1.任务设定和术语</h2>
<h3 id="ir是指根据用户给出的自然语言形式的query从大量的文本库text里返回相关的文本这里的text可以有很多形式documentpassagesentence">IR，是指根据用户给出的自然语言形式的query，从大量的文本库（text）里，返回相关的文本。这里的text可以有很多形式，document，passage，sentence……</h3>
<h3 id="一般来说一个ir系统它的流程里一般都会有两个最基础的-第一个是first-stage-retrieval它要做的是从一大批候选项里快速筛选出一小批可能相关的文本也就是减少搜索范围因此要求高效率且高召回率要求高效率是因为要处理的数据很多要求高召回率是因为我们做一个初步的筛选但显然并不希望最终用户真正想看到的内容被筛掉这个流程一般会由一个retriever模型来完成-第二个是reranking-stage它要做的是对retriever给出的缩小范围后的候选项根据和query之间的关系远近进行排序这一步一般是由一个叫做reranker的模型来完成-这两个流程是最主要的当然现代的ir系统一般是多级的后面还会有更多的流程但这些就要根据具体的业务需求来决定">一般来说，一个IR系统，它的流程里一般都会有两个最基础的，<br>第一个是first-stage
retrieval，它要做的是，从一大批候选项里快速筛选出一小批可能相关的文本（也就是减少搜索范围），因此要求高效率且高召回率（要求高效率，是因为要处理的数据很多；要求高召回率，是因为我们做一个初步的筛选，但显然并不希望最终用户真正想看到的内容被筛掉），这个流程一般会由一个retriever模型来完成；<br>第二个是reranking
stage，它要做的是，对retriever给出的缩小范围后的候选项，根据和query之间的关系远近，进行排序，这一步一般是由一个叫做reranker的模型来完成。<br>这两个流程是最主要的，当然现代的IR系统一般是多级的，后面还会有更多的流程，但这些就要根据具体的业务需求来决定</h3>
<h2 id="dense-retrieval的一些公式和记号">2.2.Dense
Retrieval的一些公式和记号</h2>
<h3 id="一般用q来记表示queryd_i表示数据集里dd_i_i1m的一个text我们的目标是根据query返回n个最相关的textsld_1d_2cdots-d_n">一般用<span class="math inline">\(q\)</span>来记表示query，<span class="math inline">\(d_{i}\)</span>表示数据集里<span class="math inline">\(D=\{d_{i}\}_{i=1}^{m}\)</span>的一个text，我们的目标是根据query返回n个最相关的texts<span class="math inline">\(L=[d_{1},d_{2},\cdots d_{n}]\)</span></h3>
<h3 id="因为研究的是dense-retrieval用的是embedding来表征文本所以衡量相关性的时候可以用到一些相似性函数最简单的比如向量内积一般的公式可以抽象为relqdf_simphiqpsid其中phi和psi都是编码器">因为研究的是dense
retrieval，用的是embedding来表征文本，所以衡量相关性的时候可以用到一些相似性函数（最简单的，比如向量内积），一般的公式可以抽象为：<span class="math display">\[Rel(q,d)=f_{sim}(\phi(q),\psi(d))\]</span>其中<span class="math inline">\(\phi\)</span>和<span class="math inline">\(\psi\)</span>都是编码器</h3>
<h3 id="在数据方面现实应用里最容易获取的数据标签应该都是二分类的也就是要么相关要么不相关更细粒度的比如分级相关虽然效果上应该会更好但获取难度也更大这篇论文聚焦于二分类标签对于一个query-q我们记与它相关的样本为d_i这些样本就是训练数据了至于不相关的样本也即negative-texts也被称作negatives一般不能直接获得想要的话得用一些其它手段">在数据方面，现实应用里最容易获取的数据标签应该都是二分类的，也就是要么相关、要么不相关。更细粒度的，比如分级相关，虽然效果上应该会更好，但获取难度也更大。这篇论文聚焦于二分类标签。对于一个query
<span class="math inline">\(q\)</span>，我们记与它相关的样本为<span class="math inline">\(d_{i}^{+}\)</span>，这些样本就是训练数据了。至于不相关的样本，也即negative
texts（也被称作negatives），一般不能直接获得，想要的话得用一些其它手段</h3>
<h1 id="datasetsevaluation-and-resources">3.Datasets，Evaluation and
Resources</h1>
<h2 id="datasets">3.1.Datasets</h2>
<h3 id="数据集方面这篇文章介绍了三种类别的数据集information-retrieval的question-answering的以及其它方面的-用来评估dense-retrieval比较多的数据集应该是ms-marco以及natural-questions两个数据集基于ms-marco还有一些特定数据集用来评估一些特定方面的能力比如多语言的能力现在聚焦某一特定方面的数据集也是越来越多了比如之前还看到了有翻译成中文的轻小说数据集了">数据集方面，这篇文章介绍了三种类别的数据集，information
retrieval的，question answering的，以及其它方面的<br>用来评估dense
retrieval比较多的数据集，应该是MS MARCO以及Natural
Questions两个数据集。基于MS
MARCO，还有一些特定数据集，用来评估一些特定方面的能力，比如多语言的能力。现在聚焦某一特定方面的数据集也是越来越多了（比如之前还看到了有翻译成中文的轻小说数据集了）</h3>
<h3 id="但现在的数据集普遍有一个问题就是它们的query通常只有很少的relevance-judgements也就是说一个query只有很少的正样本然而实际很可能不是这样的只不过因为数据集太大了人力标注实在开销很大所以不能做到对所有数据都打上标签这样的话可能会造成false-negative的现象也就是那些其实是和query相关的text却因为没有被打上相关的标签而被当成不相关的了显然会降低模型的性能比如有可能出现自相矛盾的情况明明两个texts很相近都和query相关但只给其中一个打上了相关的标签而另一个因为疏忽忘记打上相关标签了那模型就会被告知一个内容是和当前query相关的但另一个很相近的内容又被告知是和当前query不相关的-另一个问题就是现在的数据集大多是英语的非英语的很少所以要训练一个非英语的dense-retriever也是有困难的有点类似之前训大模型最开始语料都是英文的中文的很少之后才开始大肆收集中文语料吧现在网上也是比较多的">但现在的数据集普遍有一个问题，就是它们的query通常只有很少的relevance
judgements，也就是说，一个query只有很少的正样本，然而实际很可能不是这样的，只不过因为数据集太大了，人力标注实在开销很大，所以不能做到对所有数据都打上标签。这样的话，可能会造成false
negative的现象，也就是那些其实是和query相关的text，却因为没有被打上相关的标签而被当成不相关的了，显然会降低模型的性能（比如有可能出现自相矛盾的情况。明明两个texts很相近，都和query相关，但只给其中一个打上了相关的标签，而另一个因为疏忽，忘记打上相关标签了，那模型就会被告知一个内容是和当前query相关的，但另一个很相近的内容又被告知是和当前query不相关的……）<br>另一个问题就是，现在的数据集大多是英语的，非英语的很少，所以要训练一个非英语的dense
retriever也是有困难的（有点类似之前训大模型，最开始语料都是英文的，中文的很少，之后才开始大肆收集中文语料吧，现在网上也是比较多的）</h3>
<h2 id="evaluation-metrics">3.2.Evaluation Metrics</h2>
<h3 id="评价ir系统主要评价这么几个方面effectivenessefficiencydiversitynovelty这篇论文注重的是effectiveness应该就是指检索得到的结果是否尽可能多地和query相关">评价IR系统，主要评价这么几个方面：effectiveness，efficiency，diversity，novelty。这篇论文注重的是effectiveness（应该就是指检索得到的结果是否尽可能多地和query相关）</h3>
<h3 id="主要有这么几个指标">主要有这么几个指标：</h3>
<h4 id="recallk它衡量的就是召回率我们希望检索得到的前k个结果尽可能都是和query相关的计算公式为recallkfrac1qsum_q1qfracretr_qkrel_q其中q表示query集合的大小retr_qk表示检索得到的前k个结果里有多少个和query是相关的rel_q则是指和query相关的所有text的数量可以看到分母是固定的我们希望的就是分子能尽可能大">Recall@k。它衡量的就是召回率，我们希望检索得到的前k个结果尽可能都是和query相关的，计算公式为：<span class="math display">\[Recall@k=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\frac{\#retr_{q,k}}{\#rel_{q}}\]</span>其中<span class="math inline">\(|Q|\)</span>表示query集合的大小，<span class="math inline">\(\#retr_{q,k}\)</span>表示检索得到的前k个结果里，有多少个和query是相关的；<span class="math inline">\(\#rel_{q}\)</span>则是指和query相关的所有text的数量。可以看到，分母是固定的，我们希望的就是分子能尽可能大</h4>
<h4 id="top-k-accuracy计算公式为accuracykfrac1qsum_q1qiretr_qk0其中icdot是-指示函数这里对于一个query我们只要求取回来的前k个结果里存在一个相关的即可看起来它的要求比recallk低了很多但主要是因为它的使用场景和recallk也是不一样的比如粗筛阶段我们也不要求初步筛出来的全都是相关的有相关的就可以可以交给后面的流程把它找出来且真的要求全都是相关的那计算量应该会更大但显然没必要在粗筛阶段就花这么大功夫之后精筛就可以交给reranker等其它后续模型来处理所以初筛就比较适合用这个top-k-accuracy">Top-k
Accuracy，计算公式为<span class="math display">\[Accuracy@k=\frac{1}{|Q|}\sum_{q=1}^{|Q|}I(\#retr_{q,k}&gt;0)\]</span>其中<span class="math inline">\(I(\cdot)\)</span>是
指示函数，这里对于一个query，我们只要求取回来的前k个结果里，存在一个相关的即可。看起来它的要求比<span class="math inline">\(Recall@k\)</span>低了很多，但主要是因为它的使用场景和<span class="math inline">\(Recall@k\)</span>也是不一样的。比如，粗筛阶段，我们也不要求初步筛出来的全都是相关的，有相关的就可以（可以交给后面的流程把它找出来）；且真的要求全都是相关的，那计算量应该会更大，但显然没必要在粗筛阶段就花这么大功夫。之后精筛就可以交给reranker等其它后续模型来处理。所以，初筛就比较适合用这个Top-k
Accuracy</h4>
<h4 id="mean-average-precisionmap涉及到了一些其它指标首先是precisionk这个指标就是单纯衡量检索结果里的前k个有多少个是和query相关的也就是衡量前k个检索结果的准确性计算公式如下precisionkfrac1qsum_q1qfracretr_qkk之后有一个average-precisionap指标它是针对一个query而言的它的计算公式如下ap_qfrac1rel_qsum_k1lprecisionktimes-iqk这里的precisionk是仅针对当前query而言的所以在它的定义里我们可以认为q就是1或者直接化简表达式为fracretr_qkk而l则表示这一次检索回来的所有结果数我们不妨从它的定义来看前面的分数先不管求和是对所有检索结果都要求和如果这第k个检索结果是相关的那我们看一下precisionk并把它加进来如果第k个检索结果是不相关的则直接不管它-最终map就是对所有query的ap指标进行平均操作也即mapfrac1qsum_q1qap_q">Mean
Average Precision（MAP），涉及到了一些其它指标。首先是<span class="math inline">\(Precision@k\)</span>，这个指标就是单纯衡量检索结果里的前k个，有多少个是和query相关的，也就是衡量前k个检索结果的准确性。计算公式如下：<span class="math display">\[Precision@k=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\frac{\#retr_{q,k}}{k}\]</span>之后有一个Average
Precision（AP）指标，它是针对一个query而言的，它的计算公式如下：<span class="math display">\[AP_{q}=\frac{1}{\#rel_{q}}\sum_{k=1}^{L}Precision@k\times
I(q,k)\]</span>这里的Precision@k是仅针对当前query而言的，所以在它的定义里，我们可以认为<span class="math inline">\(|Q|\)</span>就是1，或者直接化简表达式为<span class="math inline">\(\frac{\#retr_{q,k}}{k}\)</span>，而L则表示这一次检索回来的所有结果数。我们不妨从它的定义来看，前面的分数先不管，求和是对所有检索结果都要求和，如果这第k个检索结果是相关的，那我们看一下Precision@k，并把它加进来；如果第k个检索结果是不相关的，则直接不管它<br>最终，MAP就是对所有query的AP指标进行平均操作，也即：<span class="math display">\[MAP=\frac{1}{|Q|}\sum_{q=1}^{Q}AP_{q}\]</span></h4>
<h4 id="normalized-discounted-cumulative-gainndcg这个指标会更加简单易懂些它涉及到dcgdiscounted-cumulative-gain和idcgideal-discounted-cumulative-gaindcg计算公式如下dcg_qksum_i1kfrac2g_i-1log_2i1其中g_i表示第i个结案所结果和query的相关程度是一个分数显然越大越相关所以这个指标总体上看是衡量了前k个检索结果与query的相关性并且还与位置有关我们希望越相关的检索结果它的rank越靠前这样分母就越小最终的dcg越大-ndcg计算公式则如下frac1qsum_q1qfracdcg_qkidcg_qk显然它是对每个query都求一个量然后再平均而具体求的这个量就是实际的dcg和理想的dcg之间的比值理想的dcg计算大体上是把所有q的相关文档按照相关度降序排列这就是最理想的情况了第一个是相关度最高的第二个是相关度第二高的然后由此计算dcg即可得到idcg">Normalized
Discounted Cumulative
Gain（NDCG），这个指标会更加简单易懂些。它涉及到DCG（Discounted
Cumulative Gain）和IDCG（Ideal Discounted Cumulative
Gain）。DCG计算公式如下：<span class="math display">\[DCG_{q}@k=\sum_{i=1}^{k}\frac{2^{g_{i}}-1}{log_{2}(i+1)}\]</span>其中<span class="math inline">\(g_{i}\)</span>表示第i个结案所结果和query的相关程度，是一个分数，显然越大越相关。所以这个指标总体上看是衡量了前k个检索结果与query的相关性，并且还与位置有关。我们希望越相关的检索结果，它的rank越靠前，这样分母就越小，最终的DCG越大<br>NDCG计算公式则如下：<span class="math display">\[\frac{1}{|Q|}\sum_{q=1}^{|Q|}\frac{DCG_{q}@k}{IDCG_{q}@k}\]</span>显然它是对每个query都求一个量，然后再平均。而具体求的这个量，就是实际的DCG和理想的DCG之间的比值。理想的DCG计算，大体上是，把所有q的相关文档按照相关度降序排列，这就是最理想的情况了：第一个是相关度最高的，第二个是相关度第二高的……然后由此计算DCG即可得到IDCG</h4>
<h4 id="mean-reciprocal-rank平均倒数排名mrr也是比较直观的一个指标计算公式如下mrrfrac1qsum_q1qfrac1rank_q其中的rank_q表示在检索结果里第一个出现的真正相关的检索结果它出现的次序比如检索回10个结果返回的这10个结果肯定是按照模型觉得和query相关程度从高到低排的可能前三个其实都不是相关的第四个才是真正相关的那这个query的倒数排名就是frac14了-可以看到这个指标重点关注的是第一个相关的结果出现的位置在此之后的结果则不怎么关注了在一些只需要一个正确答案的场景下这个指标还是比较适合的比如qa里又比如多轮对话检索里这里主要是多轮对话就需要经常回顾上文而回顾上文也是一个检索的过程只不过是从历史对话里检索如果我们能把期望的上文尽可能靠前地检索回来那响应得也就会比较快比较流畅如果期望的上文排在很后面那可能前面模型就会回答一些不那么相关的东西或者是需要比较久才能进一步找到该回答的东西">Mean
Reciprocal
Rank，平均倒数排名，MRR，也是比较直观的一个指标，计算公式如下：<span class="math display">\[MRR=\frac{1}{|Q|}\sum_{q=1}^{|Q|}\frac{1}{rank_{q}}\]</span>其中的<span class="math inline">\(rank_{q}\)</span>表示在检索结果里，第一个出现的，真正相关的检索结果，它出现的次序（比如检索回10个结果，返回的这10个结果肯定是按照模型觉得和query相关程度从高到低排的，可能前三个其实都不是相关的，第四个才是真正相关的，那这个query的倒数排名就是<span class="math inline">\(\frac{1}{4}\)</span>了<br>可以看到，这个指标重点关注的是第一个相关的结果出现的位置，在此之后的结果则不怎么关注了。在一些只需要一个正确答案的场景下，这个指标还是比较适合的，比如QA里，又比如多轮对话检索里（这里主要是，多轮对话就需要经常回顾上文，而回顾上文也是一个检索的过程，只不过是从历史对话里检索。如果我们能把期望的上文尽可能靠前地检索回来，那响应得也就会比较快、比较流畅，如果期望的上文排在很后面，那可能前面模型就会回答一些不那么相关的东西，或者是需要比较久才能进一步找到该回答的东西）</h4>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Information-Retrieval/" rel="tag"># Information Retrieval</a>
              <a href="/tags/survey/" rel="tag"># survey</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/05/15/algo/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%95%B0%E7%BB%84/%E5%AD%98%E5%9C%A8%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A0/" rel="prev" title="存在重复元素">
      <i class="fa fa-chevron-left"></i> 存在重复元素
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/05/16/algo/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%95%B0%E7%BB%84/%E7%A7%BB%E5%8A%A8%E9%9B%B6/" rel="next" title="移动零">
      移动零 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#abstract"><span class="nav-number">1.</span> <span class="nav-text">0.abstract</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#plmpretrained-language-models%E5%AF%B9%E4%BA%8E%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E9%A2%86%E5%9F%9F%E7%9A%84%E5%B8%AE%E5%8A%A9%E4%B8%BB%E8%A6%81%E5%9C%A8%E4%BA%8E%E6%8F%90%E9%AB%98%E4%BA%86%E6%96%87%E6%9C%AC%E7%9A%84%E8%A1%A8%E5%BE%81%E8%83%BD%E5%8A%9B%E8%83%BD%E6%8F%90%E5%8F%96%E5%87%BA%E6%9B%B4%E5%A5%BD%E7%9A%84embedding%E4%BB%8E%E8%80%8C%E5%B8%AE%E5%8A%A9%E4%B9%8B%E5%90%8E%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E5%BB%BA%E6%A8%A1%E8%BF%99%E7%A7%8D%E6%8A%8A%E6%96%87%E6%9C%AC%E7%94%A8embedding%E6%9D%A5%E8%A1%A8%E5%BE%81%E7%9A%84%E6%96%B9%E6%B3%95%E5%8F%ABdense-retrieval"><span class="nav-number">1.1.</span> <span class="nav-text">PLM（Pretrained
Language
Models）对于信息检索领域的帮助，主要在于提高了文本的表征能力，能提取出更好的embedding，从而帮助之后的相关性建模（这种把文本用embedding来表征的方法叫dense
retrieval）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E4%BC%9A%E4%BB%8E%E5%9B%9B%E4%B8%AA%E8%A7%92%E5%BA%A6%E6%9D%A5%E4%BB%8B%E7%BB%8Ddense-retrievalarchitecturetrainingindexingintegration%E6%9C%80%E5%90%8E%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8B%E4%B8%BB%E6%B5%81%E6%8A%80%E6%9C%AF"><span class="nav-number">1.2.</span> <span class="nav-text">这篇论文会从四个角度来介绍dense
retrieval：architecture，training，indexing，integration，最后总结一下主流技术</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#intro"><span class="nav-number">2.</span> <span class="nav-text">1.intro</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E4%B8%BB%E9%A2%98%E5%AF%86%E9%9B%86%E6%96%87%E6%9C%AC%E6%A3%80%E7%B4%A2%E9%80%9A%E8%BF%87-plm-%E5%AD%A6%E4%B9%A0%E6%9F%A5%E8%AF%A2%E5%92%8C%E6%96%87%E6%9C%AC%E7%9A%84%E7%A8%A0%E5%AF%86%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88%E6%A3%80%E7%B4%A2%E6%98%AF%E4%BC%A0%E7%BB%9F%E7%A8%80%E7%96%8F%E6%A3%80%E7%B4%A2%E5%A6%82-bm25%E7%9A%84%E9%87%8D%E8%A6%81%E6%BC%94%E8%BF%9B"><span class="nav-number">2.1.</span> <span class="nav-text">-
核心主题：密集文本检索通过 PLM
学习查询和文本的稠密向量表示，基于语义匹配实现高效检索，是传统稀疏检索（如
BM25）的重要演进。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%91%E5%B1%95%E8%84%89%E7%BB%9C"><span class="nav-number">2.2.</span> <span class="nav-text">- 发展脉络：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%B3%95%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4%E6%A8%A1%E5%9E%8Bvsm%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B%E5%A6%82-bm25%E4%BE%9D%E8%B5%96%E8%AF%8D%E6%B3%95%E5%8C%B9%E9%85%8D%E9%9A%BE%E4%BB%A5%E5%A4%84%E7%90%86%E5%A4%8D%E6%9D%82%E8%AF%AD%E4%B9%89"><span class="nav-number">2.2.1.</span> <span class="nav-text">-
传统方法：向量空间模型（VSM）、倒排索引、概率模型（如
BM25）依赖词法匹配，难以处理复杂语义。</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E8%BF%99%E9%87%8C%E7%9B%B8%E5%BD%93%E4%BA%8E%E8%BF%9B%E4%B8%80%E6%AD%A5%E4%BC%9A%E7%94%A8%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%9D%A5%E5%BB%BA%E6%A8%A1%E5%85%B3%E7%B3%BB%E5%BC%95%E5%85%A5%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%BD%86%E4%BE%9D%E8%B5%96%E4%BA%BA%E5%B7%A5%E7%89%B9%E5%BE%81%E4%BC%A0%E7%BB%9Fml%E5%B0%B1%E6%98%AF%E4%BE%9D%E8%B5%96%E4%BA%BA%E6%89%8B%E5%B7%A5%E8%AE%BE%E8%AE%A1%E7%9A%84%E7%89%B9%E5%BE%81"><span class="nav-number">2.2.2.</span> <span class="nav-text">-
机器学习方法：这里相当于进一步，会用传统的机器学习方法来建模关系，引入监督学习，但依赖人工特征。（传统ml就是依赖人手工设计的特征）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E-plm%E7%A5%9E%E7%BB%8F%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2neural-ir%E9%80%9A%E8%BF%87%E7%A8%A0%E5%AF%86%E5%90%91%E9%87%8F%E5%AE%9E%E7%8E%B0%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D%E6%AD%A4%E6%97%B6%E5%8F%88%E9%9C%80%E8%A6%81%E5%8C%BA%E5%88%86%E4%B8%80%E4%B8%8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%87%BA%E7%8E%B0%E4%BB%A5%E5%89%8D%E4%B8%80%E8%88%AC%E9%83%BD%E6%98%AF%E7%94%A8%E4%B8%80%E4%BA%9B%E5%B0%8F%E7%BD%91%E7%BB%9C%E6%9D%A5%E6%8F%90%E5%8F%96embedding%E7%9A%84%E5%8F%AF%E4%BB%A5%E7%A7%B0%E4%B8%BApre-bert-model%E8%80%8C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%87%BA%E7%8E%B0%E4%B9%8B%E5%90%8E%E5%AE%83%E7%9A%84%E8%A1%A8%E8%BE%BE%E8%83%BD%E5%8A%9B%E6%AF%94%E4%BB%A5%E5%89%8D%E7%9A%84%E5%B0%8F%E6%A8%A1%E5%9E%8B%E6%98%BE%E8%91%97%E6%8F%90%E5%8D%87%E4%BA%86%E5%9B%A0%E6%AD%A4%E6%8F%90%E5%8F%96%E6%96%87%E6%9C%ACembedding%E7%9A%84%E8%83%BD%E5%8A%9B%E5%A4%A7%E5%B9%85%E5%BA%A6%E6%8F%90%E5%8D%87%E4%BA%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%9F%E5%9C%A8%E5%90%84%E5%A4%A7ir%E6%A6%9C%E5%8D%95%E4%B8%8A%E5%88%B7%E6%A6%9C%E4%BA%86%E6%95%85%E6%8E%A8%E5%8A%A8%E5%AF%86%E9%9B%86%E6%A3%80%E7%B4%A2%E6%88%90%E4%B8%BA%E4%B8%BB%E6%B5%81"><span class="nav-number">2.2.3.</span> <span class="nav-text">-
神经网络与 PLM：神经信息检索（Neural
IR）通过稠密向量实现语义匹配，此时又需要区分一下，大模型出现以前，一般都是用一些小网络来提取embedding的，可以称为pre-Bert
model，而大模型出现之后，它的表达能力比以前的小模型显著提升了，因此提取文本embedding的能力大幅度提升了，大模型也在各大IR榜单上刷榜了，故推动密集检索成为主流。</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%86%E9%9B%86%E6%A3%80%E7%B4%A2%E4%BC%98%E5%8A%BF%E9%80%9A%E8%BF%87-plm-%E6%8D%95%E6%8D%89%E6%B7%B1%E5%B1%82%E8%AF%AD%E4%B9%89%E8%A7%A3%E5%86%B3%E6%9C%AF%E8%AF%AD%E4%B8%8D%E5%8C%B9%E9%85%8D%E9%97%AE%E9%A2%98%E5%B0%A4%E5%85%B6%E9%80%82%E7%94%A8%E4%BA%8E%E5%A4%8D%E6%9D%82%E6%9F%A5%E8%AF%A2%E5%A6%82%E5%BC%80%E6%94%BE%E5%9F%9F%E9%97%AE%E7%AD%94%E4%B8%80%E4%BA%9B%E5%A4%8D%E6%9D%82%E7%9A%84%E8%AF%AD%E4%B9%89%E5%B1%82%E9%9D%A2%E4%B8%8A%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%98%E6%83%B3%E4%BE%9D%E9%9D%A0%E4%BB%A5%E5%89%8D%E7%9A%84lexical-matching%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%AF%8D%E6%B1%87%E5%8C%B9%E9%85%8D%E9%82%A3%E4%B8%80%E5%A5%97%E5%BA%94%E8%AF%A5%E6%98%AF%E4%B8%8D%E5%A4%AA%E8%A1%8C%E7%9A%84%E6%AF%94%E5%A6%82%E5%BE%88%E5%8F%AF%E8%83%BD%E4%BC%9A%E6%9C%89%E8%AF%8D%E6%B1%87%E4%B8%8A%E5%AE%8C%E5%85%A8%E4%B8%8D%E6%90%AD%E7%95%8C%E4%BD%86%E8%AF%AD%E4%B9%89%E4%B8%8A%E5%8D%B4%E6%98%AF%E5%AE%8C%E5%85%A8%E4%B8%80%E8%87%B4%E6%88%96%E9%9D%9E%E5%B8%B8%E7%B1%BB%E4%BC%BC%E7%9A%84%E6%83%85%E5%86%B5"><span class="nav-number">2.2.4.</span> <span class="nav-text">-
密集检索优势：通过 PLM
捕捉深层语义，解决术语不匹配问题，尤其适用于复杂查询（如开放域问答）。（一些复杂的语义层面上的问题，还想依靠以前的lexical
matching，也就是词汇匹配那一套，应该是不太行的。比如，很可能会有词汇上完全不搭界，但语义上却是完全一致或非常类似的情况）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#overview"><span class="nav-number">3.</span> <span class="nav-text">2.overview</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%99%E9%87%8C%E4%B8%BB%E8%A6%81%E4%BB%8B%E7%BB%8Dir%E9%87%8C%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%AE%BE%E5%AE%9A%E6%9C%AF%E8%AF%AD%E5%92%8C%E8%AE%B0%E5%8F%B7"><span class="nav-number">3.1.</span> <span class="nav-text">这里主要介绍IR里的任务设定、术语和记号、</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A1%E8%AE%BE%E5%AE%9A%E5%92%8C%E6%9C%AF%E8%AF%AD"><span class="nav-number">3.2.</span> <span class="nav-text">2.1.任务设定和术语</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ir%E6%98%AF%E6%8C%87%E6%A0%B9%E6%8D%AE%E7%94%A8%E6%88%B7%E7%BB%99%E5%87%BA%E7%9A%84%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%BD%A2%E5%BC%8F%E7%9A%84query%E4%BB%8E%E5%A4%A7%E9%87%8F%E7%9A%84%E6%96%87%E6%9C%AC%E5%BA%93text%E9%87%8C%E8%BF%94%E5%9B%9E%E7%9B%B8%E5%85%B3%E7%9A%84%E6%96%87%E6%9C%AC%E8%BF%99%E9%87%8C%E7%9A%84text%E5%8F%AF%E4%BB%A5%E6%9C%89%E5%BE%88%E5%A4%9A%E5%BD%A2%E5%BC%8Fdocumentpassagesentence"><span class="nav-number">3.2.1.</span> <span class="nav-text">IR，是指根据用户给出的自然语言形式的query，从大量的文本库（text）里，返回相关的文本。这里的text可以有很多形式，document，passage，sentence……</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E8%88%AC%E6%9D%A5%E8%AF%B4%E4%B8%80%E4%B8%AAir%E7%B3%BB%E7%BB%9F%E5%AE%83%E7%9A%84%E6%B5%81%E7%A8%8B%E9%87%8C%E4%B8%80%E8%88%AC%E9%83%BD%E4%BC%9A%E6%9C%89%E4%B8%A4%E4%B8%AA%E6%9C%80%E5%9F%BA%E7%A1%80%E7%9A%84-%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%98%AFfirst-stage-retrieval%E5%AE%83%E8%A6%81%E5%81%9A%E7%9A%84%E6%98%AF%E4%BB%8E%E4%B8%80%E5%A4%A7%E6%89%B9%E5%80%99%E9%80%89%E9%A1%B9%E9%87%8C%E5%BF%AB%E9%80%9F%E7%AD%9B%E9%80%89%E5%87%BA%E4%B8%80%E5%B0%8F%E6%89%B9%E5%8F%AF%E8%83%BD%E7%9B%B8%E5%85%B3%E7%9A%84%E6%96%87%E6%9C%AC%E4%B9%9F%E5%B0%B1%E6%98%AF%E5%87%8F%E5%B0%91%E6%90%9C%E7%B4%A2%E8%8C%83%E5%9B%B4%E5%9B%A0%E6%AD%A4%E8%A6%81%E6%B1%82%E9%AB%98%E6%95%88%E7%8E%87%E4%B8%94%E9%AB%98%E5%8F%AC%E5%9B%9E%E7%8E%87%E8%A6%81%E6%B1%82%E9%AB%98%E6%95%88%E7%8E%87%E6%98%AF%E5%9B%A0%E4%B8%BA%E8%A6%81%E5%A4%84%E7%90%86%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BE%88%E5%A4%9A%E8%A6%81%E6%B1%82%E9%AB%98%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%98%AF%E5%9B%A0%E4%B8%BA%E6%88%91%E4%BB%AC%E5%81%9A%E4%B8%80%E4%B8%AA%E5%88%9D%E6%AD%A5%E7%9A%84%E7%AD%9B%E9%80%89%E4%BD%86%E6%98%BE%E7%84%B6%E5%B9%B6%E4%B8%8D%E5%B8%8C%E6%9C%9B%E6%9C%80%E7%BB%88%E7%94%A8%E6%88%B7%E7%9C%9F%E6%AD%A3%E6%83%B3%E7%9C%8B%E5%88%B0%E7%9A%84%E5%86%85%E5%AE%B9%E8%A2%AB%E7%AD%9B%E6%8E%89%E8%BF%99%E4%B8%AA%E6%B5%81%E7%A8%8B%E4%B8%80%E8%88%AC%E4%BC%9A%E7%94%B1%E4%B8%80%E4%B8%AAretriever%E6%A8%A1%E5%9E%8B%E6%9D%A5%E5%AE%8C%E6%88%90-%E7%AC%AC%E4%BA%8C%E4%B8%AA%E6%98%AFreranking-stage%E5%AE%83%E8%A6%81%E5%81%9A%E7%9A%84%E6%98%AF%E5%AF%B9retriever%E7%BB%99%E5%87%BA%E7%9A%84%E7%BC%A9%E5%B0%8F%E8%8C%83%E5%9B%B4%E5%90%8E%E7%9A%84%E5%80%99%E9%80%89%E9%A1%B9%E6%A0%B9%E6%8D%AE%E5%92%8Cquery%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%E8%BF%9C%E8%BF%91%E8%BF%9B%E8%A1%8C%E6%8E%92%E5%BA%8F%E8%BF%99%E4%B8%80%E6%AD%A5%E4%B8%80%E8%88%AC%E6%98%AF%E7%94%B1%E4%B8%80%E4%B8%AA%E5%8F%AB%E5%81%9Areranker%E7%9A%84%E6%A8%A1%E5%9E%8B%E6%9D%A5%E5%AE%8C%E6%88%90-%E8%BF%99%E4%B8%A4%E4%B8%AA%E6%B5%81%E7%A8%8B%E6%98%AF%E6%9C%80%E4%B8%BB%E8%A6%81%E7%9A%84%E5%BD%93%E7%84%B6%E7%8E%B0%E4%BB%A3%E7%9A%84ir%E7%B3%BB%E7%BB%9F%E4%B8%80%E8%88%AC%E6%98%AF%E5%A4%9A%E7%BA%A7%E7%9A%84%E5%90%8E%E9%9D%A2%E8%BF%98%E4%BC%9A%E6%9C%89%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%B5%81%E7%A8%8B%E4%BD%86%E8%BF%99%E4%BA%9B%E5%B0%B1%E8%A6%81%E6%A0%B9%E6%8D%AE%E5%85%B7%E4%BD%93%E7%9A%84%E4%B8%9A%E5%8A%A1%E9%9C%80%E6%B1%82%E6%9D%A5%E5%86%B3%E5%AE%9A"><span class="nav-number">3.2.2.</span> <span class="nav-text">一般来说，一个IR系统，它的流程里一般都会有两个最基础的，第一个是first-stage
retrieval，它要做的是，从一大批候选项里快速筛选出一小批可能相关的文本（也就是减少搜索范围），因此要求高效率且高召回率（要求高效率，是因为要处理的数据很多；要求高召回率，是因为我们做一个初步的筛选，但显然并不希望最终用户真正想看到的内容被筛掉），这个流程一般会由一个retriever模型来完成；第二个是reranking
stage，它要做的是，对retriever给出的缩小范围后的候选项，根据和query之间的关系远近，进行排序，这一步一般是由一个叫做reranker的模型来完成。这两个流程是最主要的，当然现代的IR系统一般是多级的，后面还会有更多的流程，但这些就要根据具体的业务需求来决定</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dense-retrieval%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%AC%E5%BC%8F%E5%92%8C%E8%AE%B0%E5%8F%B7"><span class="nav-number">3.3.</span> <span class="nav-text">2.2.Dense
Retrieval的一些公式和记号</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E8%88%AC%E7%94%A8q%E6%9D%A5%E8%AE%B0%E8%A1%A8%E7%A4%BAqueryd_i%E8%A1%A8%E7%A4%BA%E6%95%B0%E6%8D%AE%E9%9B%86%E9%87%8Cdd_i_i1m%E7%9A%84%E4%B8%80%E4%B8%AAtext%E6%88%91%E4%BB%AC%E7%9A%84%E7%9B%AE%E6%A0%87%E6%98%AF%E6%A0%B9%E6%8D%AEquery%E8%BF%94%E5%9B%9En%E4%B8%AA%E6%9C%80%E7%9B%B8%E5%85%B3%E7%9A%84textsld_1d_2cdots-d_n"><span class="nav-number">3.3.1.</span> <span class="nav-text">一般用\(q\)来记表示query，\(d_{i}\)表示数据集里\(D&#x3D;\{d_{i}\}_{i&#x3D;1}^{m}\)的一个text，我们的目标是根据query返回n个最相关的texts\(L&#x3D;[d_{1},d_{2},\cdots d_{n}]\)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%A0%E4%B8%BA%E7%A0%94%E7%A9%B6%E7%9A%84%E6%98%AFdense-retrieval%E7%94%A8%E7%9A%84%E6%98%AFembedding%E6%9D%A5%E8%A1%A8%E5%BE%81%E6%96%87%E6%9C%AC%E6%89%80%E4%BB%A5%E8%A1%A1%E9%87%8F%E7%9B%B8%E5%85%B3%E6%80%A7%E7%9A%84%E6%97%B6%E5%80%99%E5%8F%AF%E4%BB%A5%E7%94%A8%E5%88%B0%E4%B8%80%E4%BA%9B%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%87%BD%E6%95%B0%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E6%AF%94%E5%A6%82%E5%90%91%E9%87%8F%E5%86%85%E7%A7%AF%E4%B8%80%E8%88%AC%E7%9A%84%E5%85%AC%E5%BC%8F%E5%8F%AF%E4%BB%A5%E6%8A%BD%E8%B1%A1%E4%B8%BArelqdf_simphiqpsid%E5%85%B6%E4%B8%ADphi%E5%92%8Cpsi%E9%83%BD%E6%98%AF%E7%BC%96%E7%A0%81%E5%99%A8"><span class="nav-number">3.3.2.</span> <span class="nav-text">因为研究的是dense
retrieval，用的是embedding来表征文本，所以衡量相关性的时候可以用到一些相似性函数（最简单的，比如向量内积），一般的公式可以抽象为：\[Rel(q,d)&#x3D;f_{sim}(\phi(q),\psi(d))\]其中\(\phi\)和\(\psi\)都是编码器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%A8%E6%95%B0%E6%8D%AE%E6%96%B9%E9%9D%A2%E7%8E%B0%E5%AE%9E%E5%BA%94%E7%94%A8%E9%87%8C%E6%9C%80%E5%AE%B9%E6%98%93%E8%8E%B7%E5%8F%96%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A0%87%E7%AD%BE%E5%BA%94%E8%AF%A5%E9%83%BD%E6%98%AF%E4%BA%8C%E5%88%86%E7%B1%BB%E7%9A%84%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%A6%81%E4%B9%88%E7%9B%B8%E5%85%B3%E8%A6%81%E4%B9%88%E4%B8%8D%E7%9B%B8%E5%85%B3%E6%9B%B4%E7%BB%86%E7%B2%92%E5%BA%A6%E7%9A%84%E6%AF%94%E5%A6%82%E5%88%86%E7%BA%A7%E7%9B%B8%E5%85%B3%E8%99%BD%E7%84%B6%E6%95%88%E6%9E%9C%E4%B8%8A%E5%BA%94%E8%AF%A5%E4%BC%9A%E6%9B%B4%E5%A5%BD%E4%BD%86%E8%8E%B7%E5%8F%96%E9%9A%BE%E5%BA%A6%E4%B9%9F%E6%9B%B4%E5%A4%A7%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%81%9A%E7%84%A6%E4%BA%8E%E4%BA%8C%E5%88%86%E7%B1%BB%E6%A0%87%E7%AD%BE%E5%AF%B9%E4%BA%8E%E4%B8%80%E4%B8%AAquery-q%E6%88%91%E4%BB%AC%E8%AE%B0%E4%B8%8E%E5%AE%83%E7%9B%B8%E5%85%B3%E7%9A%84%E6%A0%B7%E6%9C%AC%E4%B8%BAd_i%E8%BF%99%E4%BA%9B%E6%A0%B7%E6%9C%AC%E5%B0%B1%E6%98%AF%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%BA%86%E8%87%B3%E4%BA%8E%E4%B8%8D%E7%9B%B8%E5%85%B3%E7%9A%84%E6%A0%B7%E6%9C%AC%E4%B9%9F%E5%8D%B3negative-texts%E4%B9%9F%E8%A2%AB%E7%A7%B0%E4%BD%9Cnegatives%E4%B8%80%E8%88%AC%E4%B8%8D%E8%83%BD%E7%9B%B4%E6%8E%A5%E8%8E%B7%E5%BE%97%E6%83%B3%E8%A6%81%E7%9A%84%E8%AF%9D%E5%BE%97%E7%94%A8%E4%B8%80%E4%BA%9B%E5%85%B6%E5%AE%83%E6%89%8B%E6%AE%B5"><span class="nav-number">3.3.3.</span> <span class="nav-text">在数据方面，现实应用里最容易获取的数据标签应该都是二分类的，也就是要么相关、要么不相关。更细粒度的，比如分级相关，虽然效果上应该会更好，但获取难度也更大。这篇论文聚焦于二分类标签。对于一个query
\(q\)，我们记与它相关的样本为\(d_{i}^{+}\)，这些样本就是训练数据了。至于不相关的样本，也即negative
texts（也被称作negatives），一般不能直接获得，想要的话得用一些其它手段</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#datasetsevaluation-and-resources"><span class="nav-number">4.</span> <span class="nav-text">3.Datasets，Evaluation and
Resources</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#datasets"><span class="nav-number">4.1.</span> <span class="nav-text">3.1.Datasets</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%96%B9%E9%9D%A2%E8%BF%99%E7%AF%87%E6%96%87%E7%AB%A0%E4%BB%8B%E7%BB%8D%E4%BA%86%E4%B8%89%E7%A7%8D%E7%B1%BB%E5%88%AB%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86information-retrieval%E7%9A%84question-answering%E7%9A%84%E4%BB%A5%E5%8F%8A%E5%85%B6%E5%AE%83%E6%96%B9%E9%9D%A2%E7%9A%84-%E7%94%A8%E6%9D%A5%E8%AF%84%E4%BC%B0dense-retrieval%E6%AF%94%E8%BE%83%E5%A4%9A%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BA%94%E8%AF%A5%E6%98%AFms-marco%E4%BB%A5%E5%8F%8Anatural-questions%E4%B8%A4%E4%B8%AA%E6%95%B0%E6%8D%AE%E9%9B%86%E5%9F%BA%E4%BA%8Ems-marco%E8%BF%98%E6%9C%89%E4%B8%80%E4%BA%9B%E7%89%B9%E5%AE%9A%E6%95%B0%E6%8D%AE%E9%9B%86%E7%94%A8%E6%9D%A5%E8%AF%84%E4%BC%B0%E4%B8%80%E4%BA%9B%E7%89%B9%E5%AE%9A%E6%96%B9%E9%9D%A2%E7%9A%84%E8%83%BD%E5%8A%9B%E6%AF%94%E5%A6%82%E5%A4%9A%E8%AF%AD%E8%A8%80%E7%9A%84%E8%83%BD%E5%8A%9B%E7%8E%B0%E5%9C%A8%E8%81%9A%E7%84%A6%E6%9F%90%E4%B8%80%E7%89%B9%E5%AE%9A%E6%96%B9%E9%9D%A2%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B9%9F%E6%98%AF%E8%B6%8A%E6%9D%A5%E8%B6%8A%E5%A4%9A%E4%BA%86%E6%AF%94%E5%A6%82%E4%B9%8B%E5%89%8D%E8%BF%98%E7%9C%8B%E5%88%B0%E4%BA%86%E6%9C%89%E7%BF%BB%E8%AF%91%E6%88%90%E4%B8%AD%E6%96%87%E7%9A%84%E8%BD%BB%E5%B0%8F%E8%AF%B4%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BA%86"><span class="nav-number">4.1.1.</span> <span class="nav-text">数据集方面，这篇文章介绍了三种类别的数据集，information
retrieval的，question answering的，以及其它方面的用来评估dense
retrieval比较多的数据集，应该是MS MARCO以及Natural
Questions两个数据集。基于MS
MARCO，还有一些特定数据集，用来评估一些特定方面的能力，比如多语言的能力。现在聚焦某一特定方面的数据集也是越来越多了（比如之前还看到了有翻译成中文的轻小说数据集了）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%86%E7%8E%B0%E5%9C%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E6%99%AE%E9%81%8D%E6%9C%89%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%E5%B0%B1%E6%98%AF%E5%AE%83%E4%BB%AC%E7%9A%84query%E9%80%9A%E5%B8%B8%E5%8F%AA%E6%9C%89%E5%BE%88%E5%B0%91%E7%9A%84relevance-judgements%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%AF%B4%E4%B8%80%E4%B8%AAquery%E5%8F%AA%E6%9C%89%E5%BE%88%E5%B0%91%E7%9A%84%E6%AD%A3%E6%A0%B7%E6%9C%AC%E7%84%B6%E8%80%8C%E5%AE%9E%E9%99%85%E5%BE%88%E5%8F%AF%E8%83%BD%E4%B8%8D%E6%98%AF%E8%BF%99%E6%A0%B7%E7%9A%84%E5%8F%AA%E4%B8%8D%E8%BF%87%E5%9B%A0%E4%B8%BA%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%AA%E5%A4%A7%E4%BA%86%E4%BA%BA%E5%8A%9B%E6%A0%87%E6%B3%A8%E5%AE%9E%E5%9C%A8%E5%BC%80%E9%94%80%E5%BE%88%E5%A4%A7%E6%89%80%E4%BB%A5%E4%B8%8D%E8%83%BD%E5%81%9A%E5%88%B0%E5%AF%B9%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%E9%83%BD%E6%89%93%E4%B8%8A%E6%A0%87%E7%AD%BE%E8%BF%99%E6%A0%B7%E7%9A%84%E8%AF%9D%E5%8F%AF%E8%83%BD%E4%BC%9A%E9%80%A0%E6%88%90false-negative%E7%9A%84%E7%8E%B0%E8%B1%A1%E4%B9%9F%E5%B0%B1%E6%98%AF%E9%82%A3%E4%BA%9B%E5%85%B6%E5%AE%9E%E6%98%AF%E5%92%8Cquery%E7%9B%B8%E5%85%B3%E7%9A%84text%E5%8D%B4%E5%9B%A0%E4%B8%BA%E6%B2%A1%E6%9C%89%E8%A2%AB%E6%89%93%E4%B8%8A%E7%9B%B8%E5%85%B3%E7%9A%84%E6%A0%87%E7%AD%BE%E8%80%8C%E8%A2%AB%E5%BD%93%E6%88%90%E4%B8%8D%E7%9B%B8%E5%85%B3%E7%9A%84%E4%BA%86%E6%98%BE%E7%84%B6%E4%BC%9A%E9%99%8D%E4%BD%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%80%A7%E8%83%BD%E6%AF%94%E5%A6%82%E6%9C%89%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E8%87%AA%E7%9B%B8%E7%9F%9B%E7%9B%BE%E7%9A%84%E6%83%85%E5%86%B5%E6%98%8E%E6%98%8E%E4%B8%A4%E4%B8%AAtexts%E5%BE%88%E7%9B%B8%E8%BF%91%E9%83%BD%E5%92%8Cquery%E7%9B%B8%E5%85%B3%E4%BD%86%E5%8F%AA%E7%BB%99%E5%85%B6%E4%B8%AD%E4%B8%80%E4%B8%AA%E6%89%93%E4%B8%8A%E4%BA%86%E7%9B%B8%E5%85%B3%E7%9A%84%E6%A0%87%E7%AD%BE%E8%80%8C%E5%8F%A6%E4%B8%80%E4%B8%AA%E5%9B%A0%E4%B8%BA%E7%96%8F%E5%BF%BD%E5%BF%98%E8%AE%B0%E6%89%93%E4%B8%8A%E7%9B%B8%E5%85%B3%E6%A0%87%E7%AD%BE%E4%BA%86%E9%82%A3%E6%A8%A1%E5%9E%8B%E5%B0%B1%E4%BC%9A%E8%A2%AB%E5%91%8A%E7%9F%A5%E4%B8%80%E4%B8%AA%E5%86%85%E5%AE%B9%E6%98%AF%E5%92%8C%E5%BD%93%E5%89%8Dquery%E7%9B%B8%E5%85%B3%E7%9A%84%E4%BD%86%E5%8F%A6%E4%B8%80%E4%B8%AA%E5%BE%88%E7%9B%B8%E8%BF%91%E7%9A%84%E5%86%85%E5%AE%B9%E5%8F%88%E8%A2%AB%E5%91%8A%E7%9F%A5%E6%98%AF%E5%92%8C%E5%BD%93%E5%89%8Dquery%E4%B8%8D%E7%9B%B8%E5%85%B3%E7%9A%84-%E5%8F%A6%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%E5%B0%B1%E6%98%AF%E7%8E%B0%E5%9C%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%A7%E5%A4%9A%E6%98%AF%E8%8B%B1%E8%AF%AD%E7%9A%84%E9%9D%9E%E8%8B%B1%E8%AF%AD%E7%9A%84%E5%BE%88%E5%B0%91%E6%89%80%E4%BB%A5%E8%A6%81%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E9%9D%9E%E8%8B%B1%E8%AF%AD%E7%9A%84dense-retriever%E4%B9%9F%E6%98%AF%E6%9C%89%E5%9B%B0%E9%9A%BE%E7%9A%84%E6%9C%89%E7%82%B9%E7%B1%BB%E4%BC%BC%E4%B9%8B%E5%89%8D%E8%AE%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9C%80%E5%BC%80%E5%A7%8B%E8%AF%AD%E6%96%99%E9%83%BD%E6%98%AF%E8%8B%B1%E6%96%87%E7%9A%84%E4%B8%AD%E6%96%87%E7%9A%84%E5%BE%88%E5%B0%91%E4%B9%8B%E5%90%8E%E6%89%8D%E5%BC%80%E5%A7%8B%E5%A4%A7%E8%82%86%E6%94%B6%E9%9B%86%E4%B8%AD%E6%96%87%E8%AF%AD%E6%96%99%E5%90%A7%E7%8E%B0%E5%9C%A8%E7%BD%91%E4%B8%8A%E4%B9%9F%E6%98%AF%E6%AF%94%E8%BE%83%E5%A4%9A%E7%9A%84"><span class="nav-number">4.1.2.</span> <span class="nav-text">但现在的数据集普遍有一个问题，就是它们的query通常只有很少的relevance
judgements，也就是说，一个query只有很少的正样本，然而实际很可能不是这样的，只不过因为数据集太大了，人力标注实在开销很大，所以不能做到对所有数据都打上标签。这样的话，可能会造成false
negative的现象，也就是那些其实是和query相关的text，却因为没有被打上相关的标签而被当成不相关的了，显然会降低模型的性能（比如有可能出现自相矛盾的情况。明明两个texts很相近，都和query相关，但只给其中一个打上了相关的标签，而另一个因为疏忽，忘记打上相关标签了，那模型就会被告知一个内容是和当前query相关的，但另一个很相近的内容又被告知是和当前query不相关的……）另一个问题就是，现在的数据集大多是英语的，非英语的很少，所以要训练一个非英语的dense
retriever也是有困难的（有点类似之前训大模型，最开始语料都是英文的，中文的很少，之后才开始大肆收集中文语料吧，现在网上也是比较多的）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#evaluation-metrics"><span class="nav-number">4.2.</span> <span class="nav-text">3.2.Evaluation Metrics</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%84%E4%BB%B7ir%E7%B3%BB%E7%BB%9F%E4%B8%BB%E8%A6%81%E8%AF%84%E4%BB%B7%E8%BF%99%E4%B9%88%E5%87%A0%E4%B8%AA%E6%96%B9%E9%9D%A2effectivenessefficiencydiversitynovelty%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%B3%A8%E9%87%8D%E7%9A%84%E6%98%AFeffectiveness%E5%BA%94%E8%AF%A5%E5%B0%B1%E6%98%AF%E6%8C%87%E6%A3%80%E7%B4%A2%E5%BE%97%E5%88%B0%E7%9A%84%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%B0%BD%E5%8F%AF%E8%83%BD%E5%A4%9A%E5%9C%B0%E5%92%8Cquery%E7%9B%B8%E5%85%B3"><span class="nav-number">4.2.1.</span> <span class="nav-text">评价IR系统，主要评价这么几个方面：effectiveness，efficiency，diversity，novelty。这篇论文注重的是effectiveness（应该就是指检索得到的结果是否尽可能多地和query相关）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E6%9C%89%E8%BF%99%E4%B9%88%E5%87%A0%E4%B8%AA%E6%8C%87%E6%A0%87"><span class="nav-number">4.2.2.</span> <span class="nav-text">主要有这么几个指标：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#recallk%E5%AE%83%E8%A1%A1%E9%87%8F%E7%9A%84%E5%B0%B1%E6%98%AF%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%88%91%E4%BB%AC%E5%B8%8C%E6%9C%9B%E6%A3%80%E7%B4%A2%E5%BE%97%E5%88%B0%E7%9A%84%E5%89%8Dk%E4%B8%AA%E7%BB%93%E6%9E%9C%E5%B0%BD%E5%8F%AF%E8%83%BD%E9%83%BD%E6%98%AF%E5%92%8Cquery%E7%9B%B8%E5%85%B3%E7%9A%84%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F%E4%B8%BArecallkfrac1qsum_q1qfracretr_qkrel_q%E5%85%B6%E4%B8%ADq%E8%A1%A8%E7%A4%BAquery%E9%9B%86%E5%90%88%E7%9A%84%E5%A4%A7%E5%B0%8Fretr_qk%E8%A1%A8%E7%A4%BA%E6%A3%80%E7%B4%A2%E5%BE%97%E5%88%B0%E7%9A%84%E5%89%8Dk%E4%B8%AA%E7%BB%93%E6%9E%9C%E9%87%8C%E6%9C%89%E5%A4%9A%E5%B0%91%E4%B8%AA%E5%92%8Cquery%E6%98%AF%E7%9B%B8%E5%85%B3%E7%9A%84rel_q%E5%88%99%E6%98%AF%E6%8C%87%E5%92%8Cquery%E7%9B%B8%E5%85%B3%E7%9A%84%E6%89%80%E6%9C%89text%E7%9A%84%E6%95%B0%E9%87%8F%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E5%88%86%E6%AF%8D%E6%98%AF%E5%9B%BA%E5%AE%9A%E7%9A%84%E6%88%91%E4%BB%AC%E5%B8%8C%E6%9C%9B%E7%9A%84%E5%B0%B1%E6%98%AF%E5%88%86%E5%AD%90%E8%83%BD%E5%B0%BD%E5%8F%AF%E8%83%BD%E5%A4%A7"><span class="nav-number">4.2.2.1.</span> <span class="nav-text">Recall@k。它衡量的就是召回率，我们希望检索得到的前k个结果尽可能都是和query相关的，计算公式为：\[Recall@k&#x3D;\frac{1}{|Q|}\sum_{q&#x3D;1}^{|Q|}\frac{\#retr_{q,k}}{\#rel_{q}}\]其中\(|Q|\)表示query集合的大小，\(\#retr_{q,k}\)表示检索得到的前k个结果里，有多少个和query是相关的；\(\#rel_{q}\)则是指和query相关的所有text的数量。可以看到，分母是固定的，我们希望的就是分子能尽可能大</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#top-k-accuracy%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F%E4%B8%BAaccuracykfrac1qsum_q1qiretr_qk0%E5%85%B6%E4%B8%ADicdot%E6%98%AF-%E6%8C%87%E7%A4%BA%E5%87%BD%E6%95%B0%E8%BF%99%E9%87%8C%E5%AF%B9%E4%BA%8E%E4%B8%80%E4%B8%AAquery%E6%88%91%E4%BB%AC%E5%8F%AA%E8%A6%81%E6%B1%82%E5%8F%96%E5%9B%9E%E6%9D%A5%E7%9A%84%E5%89%8Dk%E4%B8%AA%E7%BB%93%E6%9E%9C%E9%87%8C%E5%AD%98%E5%9C%A8%E4%B8%80%E4%B8%AA%E7%9B%B8%E5%85%B3%E7%9A%84%E5%8D%B3%E5%8F%AF%E7%9C%8B%E8%B5%B7%E6%9D%A5%E5%AE%83%E7%9A%84%E8%A6%81%E6%B1%82%E6%AF%94recallk%E4%BD%8E%E4%BA%86%E5%BE%88%E5%A4%9A%E4%BD%86%E4%B8%BB%E8%A6%81%E6%98%AF%E5%9B%A0%E4%B8%BA%E5%AE%83%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E5%92%8Crecallk%E4%B9%9F%E6%98%AF%E4%B8%8D%E4%B8%80%E6%A0%B7%E7%9A%84%E6%AF%94%E5%A6%82%E7%B2%97%E7%AD%9B%E9%98%B6%E6%AE%B5%E6%88%91%E4%BB%AC%E4%B9%9F%E4%B8%8D%E8%A6%81%E6%B1%82%E5%88%9D%E6%AD%A5%E7%AD%9B%E5%87%BA%E6%9D%A5%E7%9A%84%E5%85%A8%E9%83%BD%E6%98%AF%E7%9B%B8%E5%85%B3%E7%9A%84%E6%9C%89%E7%9B%B8%E5%85%B3%E7%9A%84%E5%B0%B1%E5%8F%AF%E4%BB%A5%E5%8F%AF%E4%BB%A5%E4%BA%A4%E7%BB%99%E5%90%8E%E9%9D%A2%E7%9A%84%E6%B5%81%E7%A8%8B%E6%8A%8A%E5%AE%83%E6%89%BE%E5%87%BA%E6%9D%A5%E4%B8%94%E7%9C%9F%E7%9A%84%E8%A6%81%E6%B1%82%E5%85%A8%E9%83%BD%E6%98%AF%E7%9B%B8%E5%85%B3%E7%9A%84%E9%82%A3%E8%AE%A1%E7%AE%97%E9%87%8F%E5%BA%94%E8%AF%A5%E4%BC%9A%E6%9B%B4%E5%A4%A7%E4%BD%86%E6%98%BE%E7%84%B6%E6%B2%A1%E5%BF%85%E8%A6%81%E5%9C%A8%E7%B2%97%E7%AD%9B%E9%98%B6%E6%AE%B5%E5%B0%B1%E8%8A%B1%E8%BF%99%E4%B9%88%E5%A4%A7%E5%8A%9F%E5%A4%AB%E4%B9%8B%E5%90%8E%E7%B2%BE%E7%AD%9B%E5%B0%B1%E5%8F%AF%E4%BB%A5%E4%BA%A4%E7%BB%99reranker%E7%AD%89%E5%85%B6%E5%AE%83%E5%90%8E%E7%BB%AD%E6%A8%A1%E5%9E%8B%E6%9D%A5%E5%A4%84%E7%90%86%E6%89%80%E4%BB%A5%E5%88%9D%E7%AD%9B%E5%B0%B1%E6%AF%94%E8%BE%83%E9%80%82%E5%90%88%E7%94%A8%E8%BF%99%E4%B8%AAtop-k-accuracy"><span class="nav-number">4.2.2.2.</span> <span class="nav-text">Top-k
Accuracy，计算公式为\[Accuracy@k&#x3D;\frac{1}{|Q|}\sum_{q&#x3D;1}^{|Q|}I(\#retr_{q,k}&gt;0)\]其中\(I(\cdot)\)是
指示函数，这里对于一个query，我们只要求取回来的前k个结果里，存在一个相关的即可。看起来它的要求比\(Recall@k\)低了很多，但主要是因为它的使用场景和\(Recall@k\)也是不一样的。比如，粗筛阶段，我们也不要求初步筛出来的全都是相关的，有相关的就可以（可以交给后面的流程把它找出来）；且真的要求全都是相关的，那计算量应该会更大，但显然没必要在粗筛阶段就花这么大功夫。之后精筛就可以交给reranker等其它后续模型来处理。所以，初筛就比较适合用这个Top-k
Accuracy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mean-average-precisionmap%E6%B6%89%E5%8F%8A%E5%88%B0%E4%BA%86%E4%B8%80%E4%BA%9B%E5%85%B6%E5%AE%83%E6%8C%87%E6%A0%87%E9%A6%96%E5%85%88%E6%98%AFprecisionk%E8%BF%99%E4%B8%AA%E6%8C%87%E6%A0%87%E5%B0%B1%E6%98%AF%E5%8D%95%E7%BA%AF%E8%A1%A1%E9%87%8F%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E9%87%8C%E7%9A%84%E5%89%8Dk%E4%B8%AA%E6%9C%89%E5%A4%9A%E5%B0%91%E4%B8%AA%E6%98%AF%E5%92%8Cquery%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%A1%A1%E9%87%8F%E5%89%8Dk%E4%B8%AA%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E7%9A%84%E5%87%86%E7%A1%AE%E6%80%A7%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F%E5%A6%82%E4%B8%8Bprecisionkfrac1qsum_q1qfracretr_qkk%E4%B9%8B%E5%90%8E%E6%9C%89%E4%B8%80%E4%B8%AAaverage-precisionap%E6%8C%87%E6%A0%87%E5%AE%83%E6%98%AF%E9%92%88%E5%AF%B9%E4%B8%80%E4%B8%AAquery%E8%80%8C%E8%A8%80%E7%9A%84%E5%AE%83%E7%9A%84%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F%E5%A6%82%E4%B8%8Bap_qfrac1rel_qsum_k1lprecisionktimes-iqk%E8%BF%99%E9%87%8C%E7%9A%84precisionk%E6%98%AF%E4%BB%85%E9%92%88%E5%AF%B9%E5%BD%93%E5%89%8Dquery%E8%80%8C%E8%A8%80%E7%9A%84%E6%89%80%E4%BB%A5%E5%9C%A8%E5%AE%83%E7%9A%84%E5%AE%9A%E4%B9%89%E9%87%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E8%AE%A4%E4%B8%BAq%E5%B0%B1%E6%98%AF1%E6%88%96%E8%80%85%E7%9B%B4%E6%8E%A5%E5%8C%96%E7%AE%80%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%BAfracretr_qkk%E8%80%8Cl%E5%88%99%E8%A1%A8%E7%A4%BA%E8%BF%99%E4%B8%80%E6%AC%A1%E6%A3%80%E7%B4%A2%E5%9B%9E%E6%9D%A5%E7%9A%84%E6%89%80%E6%9C%89%E7%BB%93%E6%9E%9C%E6%95%B0%E6%88%91%E4%BB%AC%E4%B8%8D%E5%A6%A8%E4%BB%8E%E5%AE%83%E7%9A%84%E5%AE%9A%E4%B9%89%E6%9D%A5%E7%9C%8B%E5%89%8D%E9%9D%A2%E7%9A%84%E5%88%86%E6%95%B0%E5%85%88%E4%B8%8D%E7%AE%A1%E6%B1%82%E5%92%8C%E6%98%AF%E5%AF%B9%E6%89%80%E6%9C%89%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E9%83%BD%E8%A6%81%E6%B1%82%E5%92%8C%E5%A6%82%E6%9E%9C%E8%BF%99%E7%AC%ACk%E4%B8%AA%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E6%98%AF%E7%9B%B8%E5%85%B3%E7%9A%84%E9%82%A3%E6%88%91%E4%BB%AC%E7%9C%8B%E4%B8%80%E4%B8%8Bprecisionk%E5%B9%B6%E6%8A%8A%E5%AE%83%E5%8A%A0%E8%BF%9B%E6%9D%A5%E5%A6%82%E6%9E%9C%E7%AC%ACk%E4%B8%AA%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E6%98%AF%E4%B8%8D%E7%9B%B8%E5%85%B3%E7%9A%84%E5%88%99%E7%9B%B4%E6%8E%A5%E4%B8%8D%E7%AE%A1%E5%AE%83-%E6%9C%80%E7%BB%88map%E5%B0%B1%E6%98%AF%E5%AF%B9%E6%89%80%E6%9C%89query%E7%9A%84ap%E6%8C%87%E6%A0%87%E8%BF%9B%E8%A1%8C%E5%B9%B3%E5%9D%87%E6%93%8D%E4%BD%9C%E4%B9%9F%E5%8D%B3mapfrac1qsum_q1qap_q"><span class="nav-number">4.2.2.3.</span> <span class="nav-text">Mean
Average Precision（MAP），涉及到了一些其它指标。首先是\(Precision@k\)，这个指标就是单纯衡量检索结果里的前k个，有多少个是和query相关的，也就是衡量前k个检索结果的准确性。计算公式如下：\[Precision@k&#x3D;\frac{1}{|Q|}\sum_{q&#x3D;1}^{|Q|}\frac{\#retr_{q,k}}{k}\]之后有一个Average
Precision（AP）指标，它是针对一个query而言的，它的计算公式如下：\[AP_{q}&#x3D;\frac{1}{\#rel_{q}}\sum_{k&#x3D;1}^{L}Precision@k\times
I(q,k)\]这里的Precision@k是仅针对当前query而言的，所以在它的定义里，我们可以认为\(|Q|\)就是1，或者直接化简表达式为\(\frac{\#retr_{q,k}}{k}\)，而L则表示这一次检索回来的所有结果数。我们不妨从它的定义来看，前面的分数先不管，求和是对所有检索结果都要求和，如果这第k个检索结果是相关的，那我们看一下Precision@k，并把它加进来；如果第k个检索结果是不相关的，则直接不管它最终，MAP就是对所有query的AP指标进行平均操作，也即：\[MAP&#x3D;\frac{1}{|Q|}\sum_{q&#x3D;1}^{Q}AP_{q}\]</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#normalized-discounted-cumulative-gainndcg%E8%BF%99%E4%B8%AA%E6%8C%87%E6%A0%87%E4%BC%9A%E6%9B%B4%E5%8A%A0%E7%AE%80%E5%8D%95%E6%98%93%E6%87%82%E4%BA%9B%E5%AE%83%E6%B6%89%E5%8F%8A%E5%88%B0dcgdiscounted-cumulative-gain%E5%92%8Cidcgideal-discounted-cumulative-gaindcg%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F%E5%A6%82%E4%B8%8Bdcg_qksum_i1kfrac2g_i-1log_2i1%E5%85%B6%E4%B8%ADg_i%E8%A1%A8%E7%A4%BA%E7%AC%ACi%E4%B8%AA%E7%BB%93%E6%A1%88%E6%89%80%E7%BB%93%E6%9E%9C%E5%92%8Cquery%E7%9A%84%E7%9B%B8%E5%85%B3%E7%A8%8B%E5%BA%A6%E6%98%AF%E4%B8%80%E4%B8%AA%E5%88%86%E6%95%B0%E6%98%BE%E7%84%B6%E8%B6%8A%E5%A4%A7%E8%B6%8A%E7%9B%B8%E5%85%B3%E6%89%80%E4%BB%A5%E8%BF%99%E4%B8%AA%E6%8C%87%E6%A0%87%E6%80%BB%E4%BD%93%E4%B8%8A%E7%9C%8B%E6%98%AF%E8%A1%A1%E9%87%8F%E4%BA%86%E5%89%8Dk%E4%B8%AA%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E4%B8%8Equery%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E5%B9%B6%E4%B8%94%E8%BF%98%E4%B8%8E%E4%BD%8D%E7%BD%AE%E6%9C%89%E5%85%B3%E6%88%91%E4%BB%AC%E5%B8%8C%E6%9C%9B%E8%B6%8A%E7%9B%B8%E5%85%B3%E7%9A%84%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E5%AE%83%E7%9A%84rank%E8%B6%8A%E9%9D%A0%E5%89%8D%E8%BF%99%E6%A0%B7%E5%88%86%E6%AF%8D%E5%B0%B1%E8%B6%8A%E5%B0%8F%E6%9C%80%E7%BB%88%E7%9A%84dcg%E8%B6%8A%E5%A4%A7-ndcg%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F%E5%88%99%E5%A6%82%E4%B8%8Bfrac1qsum_q1qfracdcg_qkidcg_qk%E6%98%BE%E7%84%B6%E5%AE%83%E6%98%AF%E5%AF%B9%E6%AF%8F%E4%B8%AAquery%E9%83%BD%E6%B1%82%E4%B8%80%E4%B8%AA%E9%87%8F%E7%84%B6%E5%90%8E%E5%86%8D%E5%B9%B3%E5%9D%87%E8%80%8C%E5%85%B7%E4%BD%93%E6%B1%82%E7%9A%84%E8%BF%99%E4%B8%AA%E9%87%8F%E5%B0%B1%E6%98%AF%E5%AE%9E%E9%99%85%E7%9A%84dcg%E5%92%8C%E7%90%86%E6%83%B3%E7%9A%84dcg%E4%B9%8B%E9%97%B4%E7%9A%84%E6%AF%94%E5%80%BC%E7%90%86%E6%83%B3%E7%9A%84dcg%E8%AE%A1%E7%AE%97%E5%A4%A7%E4%BD%93%E4%B8%8A%E6%98%AF%E6%8A%8A%E6%89%80%E6%9C%89q%E7%9A%84%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3%E6%8C%89%E7%85%A7%E7%9B%B8%E5%85%B3%E5%BA%A6%E9%99%8D%E5%BA%8F%E6%8E%92%E5%88%97%E8%BF%99%E5%B0%B1%E6%98%AF%E6%9C%80%E7%90%86%E6%83%B3%E7%9A%84%E6%83%85%E5%86%B5%E4%BA%86%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%98%AF%E7%9B%B8%E5%85%B3%E5%BA%A6%E6%9C%80%E9%AB%98%E7%9A%84%E7%AC%AC%E4%BA%8C%E4%B8%AA%E6%98%AF%E7%9B%B8%E5%85%B3%E5%BA%A6%E7%AC%AC%E4%BA%8C%E9%AB%98%E7%9A%84%E7%84%B6%E5%90%8E%E7%94%B1%E6%AD%A4%E8%AE%A1%E7%AE%97dcg%E5%8D%B3%E5%8F%AF%E5%BE%97%E5%88%B0idcg"><span class="nav-number">4.2.2.4.</span> <span class="nav-text">Normalized
Discounted Cumulative
Gain（NDCG），这个指标会更加简单易懂些。它涉及到DCG（Discounted
Cumulative Gain）和IDCG（Ideal Discounted Cumulative
Gain）。DCG计算公式如下：\[DCG_{q}@k&#x3D;\sum_{i&#x3D;1}^{k}\frac{2^{g_{i}}-1}{log_{2}(i+1)}\]其中\(g_{i}\)表示第i个结案所结果和query的相关程度，是一个分数，显然越大越相关。所以这个指标总体上看是衡量了前k个检索结果与query的相关性，并且还与位置有关。我们希望越相关的检索结果，它的rank越靠前，这样分母就越小，最终的DCG越大NDCG计算公式则如下：\[\frac{1}{|Q|}\sum_{q&#x3D;1}^{|Q|}\frac{DCG_{q}@k}{IDCG_{q}@k}\]显然它是对每个query都求一个量，然后再平均。而具体求的这个量，就是实际的DCG和理想的DCG之间的比值。理想的DCG计算，大体上是，把所有q的相关文档按照相关度降序排列，这就是最理想的情况了：第一个是相关度最高的，第二个是相关度第二高的……然后由此计算DCG即可得到IDCG</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mean-reciprocal-rank%E5%B9%B3%E5%9D%87%E5%80%92%E6%95%B0%E6%8E%92%E5%90%8Dmrr%E4%B9%9F%E6%98%AF%E6%AF%94%E8%BE%83%E7%9B%B4%E8%A7%82%E7%9A%84%E4%B8%80%E4%B8%AA%E6%8C%87%E6%A0%87%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F%E5%A6%82%E4%B8%8Bmrrfrac1qsum_q1qfrac1rank_q%E5%85%B6%E4%B8%AD%E7%9A%84rank_q%E8%A1%A8%E7%A4%BA%E5%9C%A8%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E9%87%8C%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%87%BA%E7%8E%B0%E7%9A%84%E7%9C%9F%E6%AD%A3%E7%9B%B8%E5%85%B3%E7%9A%84%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E5%AE%83%E5%87%BA%E7%8E%B0%E7%9A%84%E6%AC%A1%E5%BA%8F%E6%AF%94%E5%A6%82%E6%A3%80%E7%B4%A2%E5%9B%9E10%E4%B8%AA%E7%BB%93%E6%9E%9C%E8%BF%94%E5%9B%9E%E7%9A%84%E8%BF%9910%E4%B8%AA%E7%BB%93%E6%9E%9C%E8%82%AF%E5%AE%9A%E6%98%AF%E6%8C%89%E7%85%A7%E6%A8%A1%E5%9E%8B%E8%A7%89%E5%BE%97%E5%92%8Cquery%E7%9B%B8%E5%85%B3%E7%A8%8B%E5%BA%A6%E4%BB%8E%E9%AB%98%E5%88%B0%E4%BD%8E%E6%8E%92%E7%9A%84%E5%8F%AF%E8%83%BD%E5%89%8D%E4%B8%89%E4%B8%AA%E5%85%B6%E5%AE%9E%E9%83%BD%E4%B8%8D%E6%98%AF%E7%9B%B8%E5%85%B3%E7%9A%84%E7%AC%AC%E5%9B%9B%E4%B8%AA%E6%89%8D%E6%98%AF%E7%9C%9F%E6%AD%A3%E7%9B%B8%E5%85%B3%E7%9A%84%E9%82%A3%E8%BF%99%E4%B8%AAquery%E7%9A%84%E5%80%92%E6%95%B0%E6%8E%92%E5%90%8D%E5%B0%B1%E6%98%AFfrac14%E4%BA%86-%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E8%BF%99%E4%B8%AA%E6%8C%87%E6%A0%87%E9%87%8D%E7%82%B9%E5%85%B3%E6%B3%A8%E7%9A%84%E6%98%AF%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%9B%B8%E5%85%B3%E7%9A%84%E7%BB%93%E6%9E%9C%E5%87%BA%E7%8E%B0%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%9C%A8%E6%AD%A4%E4%B9%8B%E5%90%8E%E7%9A%84%E7%BB%93%E6%9E%9C%E5%88%99%E4%B8%8D%E6%80%8E%E4%B9%88%E5%85%B3%E6%B3%A8%E4%BA%86%E5%9C%A8%E4%B8%80%E4%BA%9B%E5%8F%AA%E9%9C%80%E8%A6%81%E4%B8%80%E4%B8%AA%E6%AD%A3%E7%A1%AE%E7%AD%94%E6%A1%88%E7%9A%84%E5%9C%BA%E6%99%AF%E4%B8%8B%E8%BF%99%E4%B8%AA%E6%8C%87%E6%A0%87%E8%BF%98%E6%98%AF%E6%AF%94%E8%BE%83%E9%80%82%E5%90%88%E7%9A%84%E6%AF%94%E5%A6%82qa%E9%87%8C%E5%8F%88%E6%AF%94%E5%A6%82%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E6%A3%80%E7%B4%A2%E9%87%8C%E8%BF%99%E9%87%8C%E4%B8%BB%E8%A6%81%E6%98%AF%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E5%B0%B1%E9%9C%80%E8%A6%81%E7%BB%8F%E5%B8%B8%E5%9B%9E%E9%A1%BE%E4%B8%8A%E6%96%87%E8%80%8C%E5%9B%9E%E9%A1%BE%E4%B8%8A%E6%96%87%E4%B9%9F%E6%98%AF%E4%B8%80%E4%B8%AA%E6%A3%80%E7%B4%A2%E7%9A%84%E8%BF%87%E7%A8%8B%E5%8F%AA%E4%B8%8D%E8%BF%87%E6%98%AF%E4%BB%8E%E5%8E%86%E5%8F%B2%E5%AF%B9%E8%AF%9D%E9%87%8C%E6%A3%80%E7%B4%A2%E5%A6%82%E6%9E%9C%E6%88%91%E4%BB%AC%E8%83%BD%E6%8A%8A%E6%9C%9F%E6%9C%9B%E7%9A%84%E4%B8%8A%E6%96%87%E5%B0%BD%E5%8F%AF%E8%83%BD%E9%9D%A0%E5%89%8D%E5%9C%B0%E6%A3%80%E7%B4%A2%E5%9B%9E%E6%9D%A5%E9%82%A3%E5%93%8D%E5%BA%94%E5%BE%97%E4%B9%9F%E5%B0%B1%E4%BC%9A%E6%AF%94%E8%BE%83%E5%BF%AB%E6%AF%94%E8%BE%83%E6%B5%81%E7%95%85%E5%A6%82%E6%9E%9C%E6%9C%9F%E6%9C%9B%E7%9A%84%E4%B8%8A%E6%96%87%E6%8E%92%E5%9C%A8%E5%BE%88%E5%90%8E%E9%9D%A2%E9%82%A3%E5%8F%AF%E8%83%BD%E5%89%8D%E9%9D%A2%E6%A8%A1%E5%9E%8B%E5%B0%B1%E4%BC%9A%E5%9B%9E%E7%AD%94%E4%B8%80%E4%BA%9B%E4%B8%8D%E9%82%A3%E4%B9%88%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B8%9C%E8%A5%BF%E6%88%96%E8%80%85%E6%98%AF%E9%9C%80%E8%A6%81%E6%AF%94%E8%BE%83%E4%B9%85%E6%89%8D%E8%83%BD%E8%BF%9B%E4%B8%80%E6%AD%A5%E6%89%BE%E5%88%B0%E8%AF%A5%E5%9B%9E%E7%AD%94%E7%9A%84%E4%B8%9C%E8%A5%BF"><span class="nav-number">4.2.2.5.</span> <span class="nav-text">Mean
Reciprocal
Rank，平均倒数排名，MRR，也是比较直观的一个指标，计算公式如下：\[MRR&#x3D;\frac{1}{|Q|}\sum_{q&#x3D;1}^{|Q|}\frac{1}{rank_{q}}\]其中的\(rank_{q}\)表示在检索结果里，第一个出现的，真正相关的检索结果，它出现的次序（比如检索回10个结果，返回的这10个结果肯定是按照模型觉得和query相关程度从高到低排的，可能前三个其实都不是相关的，第四个才是真正相关的，那这个query的倒数排名就是\(\frac{1}{4}\)了可以看到，这个指标重点关注的是第一个相关的结果出现的位置，在此之后的结果则不怎么关注了。在一些只需要一个正确答案的场景下，这个指标还是比较适合的，比如QA里，又比如多轮对话检索里（这里主要是，多轮对话就需要经常回顾上文，而回顾上文也是一个检索的过程，只不过是从历史对话里检索。如果我们能把期望的上文尽可能靠前地检索回来，那响应得也就会比较快、比较流畅，如果期望的上文排在很后面，那可能前面模型就会回答一些不那么相关的东西，或者是需要比较久才能进一步找到该回答的东西）</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">bluemouse</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">170</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">98</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bluemouse</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
