<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueeemouse.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="# title: chap6.深度学习中的分布式训练——算法及系统 date: 2025-05-26 15:51 tags: [分布式训练] categories: [mlsys, foundation] --- # 1. 分布式训练的必要性 ## 随着问题规模的增大（包括数据量和计算量层面的），单一设备处理速度逐渐无法满足我们的需求（比如太慢了，或者是干脆单设备放不下模型了）而用分布式算">
<meta property="og:type" content="article">
<meta property="og:title" content="bluemouse&#39;s blog">
<meta property="og:url" content="https://blueeemouse.github.io/2025/05/26/mlsys_foundation/chap6.%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E2%80%94%E2%80%94%E7%AE%97%E6%B3%95%E5%8F%8A%E7%B3%BB%E7%BB%9F/index.html">
<meta property="og:site_name" content="bluemouse&#39;s blog">
<meta property="og:description" content="# title: chap6.深度学习中的分布式训练——算法及系统 date: 2025-05-26 15:51 tags: [分布式训练] categories: [mlsys, foundation] --- # 1. 分布式训练的必要性 ## 随着问题规模的增大（包括数据量和计算量层面的），单一设备处理速度逐渐无法满足我们的需求（比如太慢了，或者是干脆单设备放不下模型了）而用分布式算">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-05-26T07:08:24.173Z">
<meta property="article:modified_time" content="2025-05-26T10:01:21.313Z">
<meta property="article:author" content="bluemouse">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueeemouse.github.io/2025/05/26/mlsys_foundation/chap6.%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E2%80%94%E2%80%94%E7%AE%97%E6%B3%95%E5%8F%8A%E7%B3%BB%E7%BB%9F/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title> | bluemouse's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">bluemouse's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/05/26/mlsys_foundation/chap6.%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E2%80%94%E2%80%94%E7%AE%97%E6%B3%95%E5%8F%8A%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-05-26 15:08:24 / Modified: 18:01:21" itemprop="dateCreated datePublished" datetime="2025-05-26T15:08:24+08:00">2025-05-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="section">#</h2>
<p>title: chap6.深度学习中的分布式训练——算法及系统 date: 2025-05-26
15:51 tags: [分布式训练] categories: [mlsys, foundation] --- # 1.
分布式训练的必要性 ##
随着问题规模的增大（包括数据量和计算量层面的），单一设备处理速度逐渐无法满足我们的需求（比如太慢了，或者是干脆单设备放不下模型了）<br>而用分布式算法，把问题划分为若干小问题后，再经过分布式系统来执行处理，能做到较快解决较大的问题
## 这里还介绍两个并行加速定律，来说明分布式训练的意义。 <span id="more"></span> ###
第一个是阿姆达尔定律（Amdahl's
law），这是一个比较悲观的定律。它认为，用分布式计算，是存在一个加速比的理论上限的，也就是不能仅仅依靠分布式训练来无限制，或者说较大幅度地提高计算效率，最终还是得落到提高串行处理效率，也就是单个硬件的效率上。其公式如下：<span class="math display">\[S_{latency}(s)=\frac{1}{(1-p)+\frac{p}{s}}\]</span>其中，<span class="math inline">\(S_{latency}\)</span>表示加速比，p代表任务里可以用分布式训练进行加速的比例（例如，可能一半是可以用分布式训练加速的），s表示并行执行单元的个数，显然s越大，理论上加速比例就越大。但根据这个公式，会发现，即使s增大到无穷，加速比也不过是<span class="math inline">\(\frac{1}{1-p}\)</span>，也就是有上限的。它的推导也比较简单：
#### 首先，我们把程序执行时间划分一下：<span class="math inline">\(T_{1}=W_{ser}+W_{par}\)</span>（其中<span class="math inline">\(W_{ser}\)</span>表示无法并行执行的部分，下标ser表示serial；<span class="math inline">\(W_{par}\)</span>表示可以并行执行的部分，下标par表示parallel）
####
然后，假设我们有s个并行执行单元，则此时理想情况下，可并行的部分的时间，应该能做到变为原来的<span class="math inline">\(\frac{1}{s}\)</span>，因此，有：<span class="math inline">\(T_{p}\geq
W_{ser}+\frac{W_{par}}{s}\)</span>（其中，<span class="math inline">\(T_{p}\)</span>表示实际的并行执行之后的总时间。右边的部分就是理想的执行时间）
###### 这里多说一下，之所以理想的时间中，并行部分的执行时间恰好就是<span class="math inline">\(\frac{1}{s}\)</span>，可以这样直观理解：我们对可并行部分，要把任务分到s个执行单元上去执行。最终我们衡量这部分的运行时间，看的其实不是执行时间最短的那个单元，而是执行时间最长的那个单元。因此，我们现在就来看一下，s个单元里，最短的时间可以是多少呢？这里我们可以把<span class="math inline">\(W_{par}\)</span>理解为某种工作量，工作量是一定的。因此，分到各个执行单元上的时候，如果有某个执行单元的工作量小于平均值<span class="math inline">\(\frac{W_{par}}{s}\)</span>，则一定会有某个执行单元的工作量大于平均值<span class="math inline">\(\frac{W_{par}}{s}\)</span>。则此时并行执行的总时间应该大于<span class="math inline">\(\frac{W_{par}}{s}\)</span>。故，最小的时间确实是发生在我们把任务量平均分到每个执行单元上的时候。
#### 此时，我们根据加速比的定义（<span class="math inline">\(\frac{T_{1}}{T_{p}}\)</span>，即原执行时间比上加速后的时间），可得到：<span class="math inline">\(S_{latency}\leq
\frac{W_{ser}+W_{par}}{W_{ser}+\frac{W_{par}}{s}}\)</span><br>进一步的，我们记p为<span class="math inline">\(T_{1}\)</span>中可并行加速的部分的占比，则有：<span class="math inline">\(W_{ser}=(1-p)T_{1}\)</span>，<span class="math inline">\(W_{par}=pT_{1}\)</span><br>此时再把上面的不等式整理一下，有：<span class="math inline">\(S_{latency}\leq \frac{(1-p)+p}{1-p+\frac{p}{s}} =
\frac{1}{1-p+\frac{p}{s}}\)</span> ###
第二个则是古斯塔夫定律（Gustafson's
law），它类似于对上面阿姆达尔定律的一个反击，是一个乐观的定律。它认为其实线性加速比是有可能的，因此，我们确实是有机会通过增加执行单元的数量来得到比较好的加速比的。其推导其实和上面有些类似，但关键在于一个地方，就是，古斯塔夫定律认为，随着并行度的增加，可解问题的规模也在增加；而上面的阿姆达尔定律则假设问题规模总是固定的：
#### 这里我们记，在拥有s个并行执行单元的机器上，执行时间为：<span class="math inline">\(T_{1}=W_{ser}+W_{par}\)</span>，这里初始的时间记号没变，含义和上面一样。下面，是关键的一步：<br>在单处理器上，我们可得到，执行时间为：<span class="math inline">\(T_{s}=W_{ser}+sW_{par}\)</span> ####
看起来和上面好像没什么区别？但这里，我们是先定义了并行执行的时间。然后，在相同的问题规模下，我们再看，如果要在单处理器上执行，会是多少时间。上面阿姆达尔定律，则是：先看一下在单处理器情况下，执行时间是多少，之后再看用s个并行执行单元后，执行时间又是多少。最大的区别在于，上面阿姆达尔定律，它假设了可并行的部分的问题任务量是一定的，即固定为<span class="math inline">\(W_{par}\)</span>；此处的古斯塔夫定律，它先考察并行执行下的时间，此时可并行部分的任务量是<span class="math inline">\(W_{par}\)</span>，则之后在单处理器上执行的时候，总的并行部分的任务量应该是<span class="math inline">\(SW_{par}\)</span>（？再理解一下） ####
此时，我们依然按照加速比的定义，可得到：<span class="math inline">\(S_{latency}(s)=\frac{W_{ser}+sW_{par}}{W_{ser}+W_{par}}\)</span>；依然引入p记号，则有：<span class="math inline">\(S_{latency}(s)=\frac{1-p+sp}{1}=1-p+sp\)</span><br>可以看到，当并行执行单元s增多的时候，且足够大的时候，是有可能可以做到接近线性加速比的
# 2. 并行化的基本方案 ##
大体上分算子内并行和算子间并行。算子内并行，没太明白……<br>而算子间并行，大体上分两种，一种是模型并行，一种是数据并行。这两个比较主要
## 2.1. 模型并行 ### 2.1.1. 朴素idea： ####
简单说，这个并行方式是要把计算图划分，然后放到不同的设备上进行执行。因此需要跨设备传递中间的激活值，以及每个设备都需要用梯度更新它那部分的模型
### 2.1.2. 朴素idea的问题： ####
但如果只是简单地把计算图划分（具体到代码上，一般是把模型的module之类的给划分，比如，可能模型里有两个sequential，第一个sequential放到cuda0上，第二个sequential放到cuda1上，这样），那其实未必能起到加速的效果。因为，给定一个batch，要前向计算，以上面的两个sequential的情况为例，就是要先在cuda0上经过第一个seq，再把这部分的结果放到cuda1上，经过seq2<br>这样，每个时刻，其实只有一个gpu在运行，且我们还多了跨设备传递数据的步骤，很可能不仅没加速，还比原来用单卡慢了
### 2.1.3. 优化方式： ####
因此需要优化。跨设备的搬移数据，不太好优化，但如果能尽量避免设备的空闲，显然是一个极大的改进。因此，考虑流水线。大概的idea是：我们把一个batch再给切分为若干split，之后每个split挨个进入到cuda设备里。用上面的例子进行说明，假如一个batch被我们划分为4个split，则split0先进入cuda0，然后下一个时刻，split0进入cuda1，split1进入cuda0；再下一个时刻，split0算完了，split1进入cuda1，split2进入cuda2……
###
上面的朴素的流水线，一般仅在开头结尾的iteration有gpu的空洞（也就是有设备的空闲），而中间大多数时候，两块gpu都能同时运行，效果比用流水线之前的是要好很多的<br>另一个点是，划分split的时候，并非越多越好，因为跨设备移动数据是比较耗时的（但本身划分较多的split的时候，是相当于流水线级数增多了吗？）
###
下面再介绍两种具体一点的算法。第一个是Gpipe算法，第二个是PipeDream算法
### 2.1.4. Gpipe算法： ####
它的idea是，对batch进行拆分，从而减少设备空闲（也就是所谓Bubble），且是在一个batch的所有前馈都结束之后，才开始反向传播（这样看，它和上面朴素的流水线改进，有什么区别？）
### 2.1.5. PipeDream算法 ####
它相当于在Gpipe算法上作出一些改进。主要是，上面Gpipe算法要等所有的前馈完成了，才一起反向传播（这样本身是有什么好处吗？如果什么好处都没有，显然一开始不会设计成这样啊？），但这样就很浪费设备，因为有时候得等一些split完成前馈，才能反传。因此，PipeDream就是在这方面作出了改进，第一个split的前馈一旦算完，就立刻开始反向传播。且每个split的反向传播，都被设计为占据两个时隙（可以简单理解为两个时间单位），进而人为制造出bubble，从而让后续的前馈运算能在这个间隙里进行，消除bubble（感觉还是没太明白啊？）
## 2.2. 数据并行 ### 2.2.1. 朴素idea： ####
所谓数据并行，就是，不同设备上，执行相同的计算图（可以理解为，我们不切分模型了，每个设备上都放一个完整的模型。然后每个设备上都可以各自算一批数据，完成前向和后向，接着就是跨设备的聚合梯度，并利用聚合后的梯度来更新模型）（但可以看到，这个并行方式其实是适用于“单个模型可以放在单卡上”的情况的，如果模型太大了，导致放不下，其实这个并行方式就不奏效了，可能得两种并行方式结合起来）
### 2.2.2. 集合通信（collective communication）中的通信原语（primitive）
####
集合通信，可以简单理解为，设备间数据的传输（因为此时每个设备上都有各自的前向和后向，所以需要聚合梯度，也就是需要传递数据）。而通信原语，可以简单理解为一些基本的传输操作
#### 通信原语，主要分三种：一对多，多对一，多对多 #### 一对多： #####
主要有Scatter和Broadcast #####
Scatter：它就是把主节点的数据进行划分，并分发到其它的指定的节点（节点，可以简单理解成设备，也就是一张gpu。但不同语境下应该有不同的理解）
#####
Broadcast：它是某个节点，把自身的数据，发送到集群里的其它节点上（注意，这就是Broadcast和Scatter的区别了，Broadcast发送的是自己的数据，而Scatter是把大的数据给拆散，分发到各个设备上）（一般Broadcast操作用于在分布式机器学习中的参数初始化）
#### 多对一： ##### 主要有Reduce和Gather #####
Reduce：被称为规约于是暖，是一系列简单运算操作的统称。细分有很多，包括：Sum、Min、Max等。这里不妨以Sum为例，理解一下：例如现在四个设备上各自有一个二维向量，然后要求把这些向量给累加起来，那Reduce操作就可以把四个设备上的二维向量聚集到一个设备上（比如gpu0），然后相加，从而在这个指定的设备上得到结果
#####
Gather：它是指，把多个节点上的数据收集到单个节点上（注意，这里和上面的Reduce的不同在于，Reduce收集完了是要做一些操作的，但这里Gather只是单纯的收集起来。它可以理解为反向的Scatter）
#### 多对多： ##### 主要有All-Gather和All-Reduce #####
All-Gather：可以理解为Gather+Broadcast。也就是，先把各个节点的数据收集起来，放到一个节点上，然后再从这个节点出发，进行Broadcast
#####
All-Reduce：它的目的是，要在所有的节点上都进行相同的Reduce操作。因此，我们可以看成是Reduce+Broadcast（这样，在一个节点上，我们会先得到Reduce的结果，之后再从这个节点，进行Broadcast，从而每个节点都能得到Reduce后的操作）
######
All-Reduce的基础是点对点通信，点对点通信又可以分为同步的和异步的通信（先略。简单说，同步的就是得等接收端那里开始接受数据了，发送端才能结束；异步则不需要这么麻烦，发送完数据，发送端就结束了）
###### 下面再探讨All-Reduce的实现算法（这个感觉有点重点啊） ###### 1.
Reduce+Broadcast<br>也就是最朴素的实现。它一般是采用一个参数服务器的分布式架构，也就是会有一个节点充当服务器（或者说中心节点），它会先存放Reduce的结果，经过本地计算后，再Broadcast到各个其它节点上<br>如果我们给定如下的记号：<span class="math inline">\(\alpha\)</span>表示两个通信节点之间的时延latency，S表示数据块大小（Size），B表示两个通信节点之间的带宽（Bandwidth），C表示每字节数据的计算耗时（Computation），N表示节点个数（Number），则总体的耗时为<span class="math display">\[2*(\alpha+\frac{S}{B})+N*S*C\]</span>现在我们看一下这个式子，前半的部分表示数据传递上的耗时。节点之间的通信，发出数据需要花时间，接收数据也要花时间，所以有个因子2；而<span class="math inline">\(\alpha\)</span>是时延，可以简单理解为硬性的时间开销；<span class="math inline">\(\frac{S}{B}\)</span>则表示，大小为S的数据，发送要多久（以及接收要多久）；后半部分则是每个节点都要进行计算，在计算方面的时间开销<br>这个算法的最大缺点就是，parameter
server的那个节点，它的带宽会成为瓶颈（因为这个节点，它一开始reduce的时候，就得从其它节点那里接收很多数据，这里就得耗时了；之后它又得进行broadcast，要往其它节点那里发送很多数据，也很耗时）（怎么越看越感觉这个公式有点问题？）</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/05/23/algo/%E7%AE%97%E6%B3%95%E9%9D%A2%E8%AF%95%E9%A2%98/%E5%A0%86%E3%80%81%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E7%AC%ACK%E4%B8%AA%E6%9C%80%E5%A4%A7%E5%85%83%E7%B4%A0/" rel="prev" title="数组中的第K个最大元素">
      <i class="fa fa-chevron-left"></i> 数组中的第K个最大元素
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/05/26/mlsys_foundation/chap2.Pytorch%E5%9F%BA%E7%A1%80/" rel="next" title="chap2.Pytorch基础">
      chap2.Pytorch基础 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#section"><span class="nav-number">1.</span> <span class="nav-text">#</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">bluemouse</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">96</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bluemouse</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
