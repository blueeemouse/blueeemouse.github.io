<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueeemouse.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="或许得思考一下为什么RAG一直被人诟病？它的问题到底在哪里？GraphRAG，解决了RAG的哪些问题？还有哪些本质问题没有解决？不妨先从传统RAG开始说起。那它的最开始的操作，把文档进行chunk，其实就是一个有很多弊端的操作：硬性切分，导致内容可能割裂（例如一个完整的内容被切割到两个，乃至多个chunk中）还有一个问题，现在的RAG里的很多技术，或者说方法，感觉都可能随着基模的发展而变得无用。比">
<meta property="og:type" content="article">
<meta property="og:title" content="bluemouse&#39;s blog">
<meta property="og:url" content="https://blueeemouse.github.io/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/%E5%85%B3%E4%BA%8ERAG%E7%9A%84%E6%80%9D%E8%80%83/index.html">
<meta property="og:site_name" content="bluemouse&#39;s blog">
<meta property="og:description" content="或许得思考一下为什么RAG一直被人诟病？它的问题到底在哪里？GraphRAG，解决了RAG的哪些问题？还有哪些本质问题没有解决？不妨先从传统RAG开始说起。那它的最开始的操作，把文档进行chunk，其实就是一个有很多弊端的操作：硬性切分，导致内容可能割裂（例如一个完整的内容被切割到两个，乃至多个chunk中）还有一个问题，现在的RAG里的很多技术，或者说方法，感觉都可能随着基模的发展而变得无用。比">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-09-28T07:49:03.178Z">
<meta property="article:modified_time" content="2026-01-14T13:27:27.526Z">
<meta property="article:author" content="bluemouse">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueeemouse.github.io/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/%E5%85%B3%E4%BA%8ERAG%E7%9A%84%E6%80%9D%E8%80%83/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title> | bluemouse's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">bluemouse's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/%E5%85%B3%E4%BA%8ERAG%E7%9A%84%E6%80%9D%E8%80%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-28 15:49:03" itemprop="dateCreated datePublished" datetime="2025-09-28T15:49:03+08:00">2025-09-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2026-01-14 21:27:27" itemprop="dateModified" datetime="2026-01-14T21:27:27+08:00">2026-01-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="或许得思考一下为什么RAG一直被人诟病？它的问题到底在哪里？GraphRAG，解决了RAG的哪些问题？还有哪些本质问题没有解决？"><a href="#或许得思考一下为什么RAG一直被人诟病？它的问题到底在哪里？GraphRAG，解决了RAG的哪些问题？还有哪些本质问题没有解决？" class="headerlink" title="或许得思考一下为什么RAG一直被人诟病？它的问题到底在哪里？GraphRAG，解决了RAG的哪些问题？还有哪些本质问题没有解决？"></a>或许得思考一下为什么RAG一直被人诟病？它的问题到底在哪里？GraphRAG，解决了RAG的哪些问题？还有哪些本质问题没有解决？</h1><h2 id="不妨先从传统RAG开始说起。那它的最开始的操作，把文档进行chunk，其实就是一个有很多弊端的操作：硬性切分，导致内容可能割裂（例如一个完整的内容被切割到两个，乃至多个chunk中）"><a href="#不妨先从传统RAG开始说起。那它的最开始的操作，把文档进行chunk，其实就是一个有很多弊端的操作：硬性切分，导致内容可能割裂（例如一个完整的内容被切割到两个，乃至多个chunk中）" class="headerlink" title="不妨先从传统RAG开始说起。那它的最开始的操作，把文档进行chunk，其实就是一个有很多弊端的操作：硬性切分，导致内容可能割裂（例如一个完整的内容被切割到两个，乃至多个chunk中）"></a>不妨先从传统RAG开始说起。那它的最开始的操作，把文档进行chunk，其实就是一个有很多弊端的操作：硬性切分，导致内容可能割裂（例如一个完整的内容被切割到两个，乃至多个chunk中）</h2><h2 id="还有一个问题，现在的RAG里的很多技术，或者说方法，感觉都可能随着基模的发展而变得无用。比如，我们把知识库组织成graph的格式，这是为了更好体现data之间的关系。其实相当于我们显式地把这些关系给提炼出来，以便模型能掌握到（或者说，是我们在担心，如果不提炼出来，那模型就感知不到这个关系）。但假如，基模不断发展，它的推理能力也不断提高，最终我们只需要把检索到的内容直接拿给它，它就能推理出这些关系，甚至还能自发的研究更深层的关系，那不就没必要搞graph了吗？"><a href="#还有一个问题，现在的RAG里的很多技术，或者说方法，感觉都可能随着基模的发展而变得无用。比如，我们把知识库组织成graph的格式，这是为了更好体现data之间的关系。其实相当于我们显式地把这些关系给提炼出来，以便模型能掌握到（或者说，是我们在担心，如果不提炼出来，那模型就感知不到这个关系）。但假如，基模不断发展，它的推理能力也不断提高，最终我们只需要把检索到的内容直接拿给它，它就能推理出这些关系，甚至还能自发的研究更深层的关系，那不就没必要搞graph了吗？" class="headerlink" title="还有一个问题，现在的RAG里的很多技术，或者说方法，感觉都可能随着基模的发展而变得无用。比如，我们把知识库组织成graph的格式，这是为了更好体现data之间的关系。其实相当于我们显式地把这些关系给提炼出来，以便模型能掌握到（或者说，是我们在担心，如果不提炼出来，那模型就感知不到这个关系）。但假如，基模不断发展，它的推理能力也不断提高，最终我们只需要把检索到的内容直接拿给它，它就能推理出这些关系，甚至还能自发的研究更深层的关系，那不就没必要搞graph了吗？"></a>还有一个问题，现在的RAG里的很多技术，或者说方法，感觉都可能随着基模的发展而变得无用。比如，我们把知识库组织成graph的格式，这是为了更好体现data之间的关系。其实相当于我们显式地把这些关系给提炼出来，以便模型能掌握到（或者说，是我们在担心，如果不提炼出来，那模型就感知不到这个关系）。但假如，基模不断发展，它的推理能力也不断提高，最终我们只需要把检索到的内容直接拿给它，它就能推理出这些关系，甚至还能自发的研究更深层的关系，那不就没必要搞graph了吗？</h2><h2 id="另，RAG里很多时候都是在借用模型本身的能力，自己做的实质就是一个prompt-engineer，这就显得很没有技术含量。但或许也该换个角度看，不管这个事在别人看来是否有含金量，如果它确实有效，我们不妨也能称上一句simple-and-effective"><a href="#另，RAG里很多时候都是在借用模型本身的能力，自己做的实质就是一个prompt-engineer，这就显得很没有技术含量。但或许也该换个角度看，不管这个事在别人看来是否有含金量，如果它确实有效，我们不妨也能称上一句simple-and-effective" class="headerlink" title="另，RAG里很多时候都是在借用模型本身的能力，自己做的实质就是一个prompt engineer，这就显得很没有技术含量。但或许也该换个角度看，不管这个事在别人看来是否有含金量，如果它确实有效，我们不妨也能称上一句simple and effective"></a>另，RAG里很多时候都是在借用模型本身的能力，自己做的实质就是一个prompt engineer，这就显得很没有技术含量。但或许也该换个角度看，不管这个事在别人看来是否有含金量，如果它确实有效，我们不妨也能称上一句simple and effective</h2><h2 id="RAG的延迟，很严重吗？确实，粗筛、rerank、精筛，假如这一套流程走下来，给人感觉步骤很多，而且因为是级联的方式，上一步的误差有可能影响下一步的误差（但就没可能是，我们下一步是基于上一步的结果进行纠正和前进吗？）。这是讲故事还是确有其事？有必要、有可能通过轻量化等技术减缓延迟，从而提高其实用性吗"><a href="#RAG的延迟，很严重吗？确实，粗筛、rerank、精筛，假如这一套流程走下来，给人感觉步骤很多，而且因为是级联的方式，上一步的误差有可能影响下一步的误差（但就没可能是，我们下一步是基于上一步的结果进行纠正和前进吗？）。这是讲故事还是确有其事？有必要、有可能通过轻量化等技术减缓延迟，从而提高其实用性吗" class="headerlink" title="RAG的延迟，很严重吗？确实，粗筛、rerank、精筛，假如这一套流程走下来，给人感觉步骤很多，而且因为是级联的方式，上一步的误差有可能影响下一步的误差（但就没可能是，我们下一步是基于上一步的结果进行纠正和前进吗？）。这是讲故事还是确有其事？有必要、有可能通过轻量化等技术减缓延迟，从而提高其实用性吗"></a>RAG的延迟，很严重吗？确实，粗筛、rerank、精筛，假如这一套流程走下来，给人感觉步骤很多，而且因为是级联的方式，上一步的误差有可能影响下一步的误差（但就没可能是，我们下一步是基于上一步的结果进行纠正和前进吗？）。这是讲故事还是确有其事？有必要、有可能通过轻量化等技术减缓延迟，从而提高其实用性吗</h2><h1 id="但不得不说，即使模型的上下文窗口再怎么增长（且不说它持续增长的情况下，性能是否能和短上下文的时候的性能持平），也不可能把所有的资料都一口气吃下去。不管是大一点的本地资料库，还是网络上的资料，这都应该没可能全部吃进去。也就是说，对更大范围的知识，以及最新知识的获取，始终是模型的一个必要的需求。至于说最终手段是不是RAG，或者说这个手段还叫不叫RAG，那感觉没那么重要。简单来说，借用一下机器之心的话，“RAG-本身所代表的核心思想——为-LLM-提供精准、可靠的外部知识——的需求是永恒的”"><a href="#但不得不说，即使模型的上下文窗口再怎么增长（且不说它持续增长的情况下，性能是否能和短上下文的时候的性能持平），也不可能把所有的资料都一口气吃下去。不管是大一点的本地资料库，还是网络上的资料，这都应该没可能全部吃进去。也就是说，对更大范围的知识，以及最新知识的获取，始终是模型的一个必要的需求。至于说最终手段是不是RAG，或者说这个手段还叫不叫RAG，那感觉没那么重要。简单来说，借用一下机器之心的话，“RAG-本身所代表的核心思想——为-LLM-提供精准、可靠的外部知识——的需求是永恒的”" class="headerlink" title="但不得不说，即使模型的上下文窗口再怎么增长（且不说它持续增长的情况下，性能是否能和短上下文的时候的性能持平），也不可能把所有的资料都一口气吃下去。不管是大一点的本地资料库，还是网络上的资料，这都应该没可能全部吃进去。也就是说，对更大范围的知识，以及最新知识的获取，始终是模型的一个必要的需求。至于说最终手段是不是RAG，或者说这个手段还叫不叫RAG，那感觉没那么重要。简单来说，借用一下机器之心的话，“RAG 本身所代表的核心思想——为 LLM 提供精准、可靠的外部知识——的需求是永恒的”"></a>但不得不说，即使模型的上下文窗口再怎么增长（且不说它持续增长的情况下，性能是否能和短上下文的时候的性能持平），也不可能把所有的资料都一口气吃下去。不管是大一点的本地资料库，还是网络上的资料，这都应该没可能全部吃进去。也就是说，对更大范围的知识，以及最新知识的获取，始终是模型的一个必要的需求。至于说最终手段是不是RAG，或者说这个手段还叫不叫RAG，那感觉没那么重要。简单来说，借用一下机器之心的话，“RAG 本身所代表的核心思想——为 LLM 提供精准、可靠的外部知识——的需求是永恒的”</h1><h2 id="来看看机器之心推文里的说法："><a href="#来看看机器之心推文里的说法：" class="headerlink" title="来看看机器之心推文里的说法："></a>来看看机器之心推文里的说法：</h2><h3 id="未来的图景更可能是："><a href="#未来的图景更可能是：" class="headerlink" title="未来的图景更可能是："></a>未来的图景更可能是：</h3><ul>
<li><h4 id="RAG-的角色转变：RAG-不再是所有应用的默认核心架构，而是被「降级」为-Agent-工具箱中的一个强大组件。它将与代码解释器、API-调用、文件系统操作等工具平起平坐。"><a href="#RAG-的角色转变：RAG-不再是所有应用的默认核心架构，而是被「降级」为-Agent-工具箱中的一个强大组件。它将与代码解释器、API-调用、文件系统操作等工具平起平坐。" class="headerlink" title="RAG 的角色转变：RAG 不再是所有应用的默认核心架构，而是被「降级」为 Agent 工具箱中的一个强大组件。它将与代码解释器、API 调用、文件系统操作等工具平起平坐。"></a><strong>RAG 的角色转变</strong>：RAG 不再是所有应用的默认核心架构，而是被「降级」为 Agent 工具箱中的一个强大组件。它将与代码解释器、API 调用、文件系统操作等工具平起平坐。</h4></li>
<li><h4 id="场景决定架构：对于需要从海量、非结构化数据中快速筛选信息的场景（如智能客服、企业知识库初筛），由-Agent-驱动的、高度工程化的高级-RAG-系统仍是最佳选择。"><a href="#场景决定架构：对于需要从海量、非结构化数据中快速筛选信息的场景（如智能客服、企业知识库初筛），由-Agent-驱动的、高度工程化的高级-RAG-系统仍是最佳选择。" class="headerlink" title="场景决定架构：对于需要从海量、非结构化数据中快速筛选信息的场景（如智能客服、企业知识库初筛），由 Agent 驱动的、高度工程化的高级 RAG 系统仍是最佳选择。"></a><strong>场景决定架构</strong>：对于需要从海量、非结构化数据中快速筛选信息的场景（如智能客服、企业知识库初筛），由 Agent 驱动的、高度工程化的高级 RAG 系统仍是最佳选择。</h4></li>
<li><h4 id="长上下文的统治力：对于需要对少量、结构复杂的文档进行深度推理和分析的场景（如财报分析、法律合同审查），「长上下文窗口-Agent-调查」的范式将展现出碾压性的优势。"><a href="#长上下文的统治力：对于需要对少量、结构复杂的文档进行深度推理和分析的场景（如财报分析、法律合同审查），「长上下文窗口-Agent-调查」的范式将展现出碾压性的优势。" class="headerlink" title="长上下文的统治力：对于需要对少量、结构复杂的文档进行深度推理和分析的场景（如财报分析、法律合同审查），「长上下文窗口 + Agent 调查」的范式将展现出碾压性的优势。"></a><strong>长上下文的统治力</strong>：对于需要对少量、结构复杂的文档进行深度推理和分析的场景（如财报分析、法律合同审查），「长上下文窗口 + Agent 调查」的范式将展现出碾压性的优势。</h4></li>
</ul>
<h3 id="对于开发者而言，关键在于理解不同技术范式的优劣，并根据具体的应用场景，灵活地将它们组合成最高效、最可靠的解决方案。"><a href="#对于开发者而言，关键在于理解不同技术范式的优劣，并根据具体的应用场景，灵活地将它们组合成最高效、最可靠的解决方案。" class="headerlink" title="对于开发者而言，关键在于理解不同技术范式的优劣，并根据具体的应用场景，灵活地将它们组合成最高效、最可靠的解决方案。"></a>对于开发者而言，关键在于理解不同技术范式的优劣，并根据具体的应用场景，灵活地将它们组合成最高效、最可靠的解决方案。</h3><h2 id="总结一下，少量上下文的情况下，还真不太需要RAG了。尤其是随着上下文窗口的增长，“少量”的定义也将不断扩大。这点不可否认。但话又说回来，RAG本来也不是针对这个场景的吧。回忆一下，最经典的RAG的故事，是说模型要接触最新的知识，以及其它的可能有用的知识吧关于第一点，RAG的降级，只能说，没彻底死了就是好的。可RAG什么时候成了必须品了？没感觉过啊？但确实，把它当一个工具还是不错的而第二点，确实，当场景需要从大量非结构化数据里快速筛选信息的时候，依然需要RAG技术吧，只不过可能推理啊，检索啊之类的，结合一下agent，效果应该会更好"><a href="#总结一下，少量上下文的情况下，还真不太需要RAG了。尤其是随着上下文窗口的增长，“少量”的定义也将不断扩大。这点不可否认。但话又说回来，RAG本来也不是针对这个场景的吧。回忆一下，最经典的RAG的故事，是说模型要接触最新的知识，以及其它的可能有用的知识吧关于第一点，RAG的降级，只能说，没彻底死了就是好的。可RAG什么时候成了必须品了？没感觉过啊？但确实，把它当一个工具还是不错的而第二点，确实，当场景需要从大量非结构化数据里快速筛选信息的时候，依然需要RAG技术吧，只不过可能推理啊，检索啊之类的，结合一下agent，效果应该会更好" class="headerlink" title="总结一下，少量上下文的情况下，还真不太需要RAG了。尤其是随着上下文窗口的增长，“少量”的定义也将不断扩大。这点不可否认。但话又说回来，RAG本来也不是针对这个场景的吧。回忆一下，最经典的RAG的故事，是说模型要接触最新的知识，以及其它的可能有用的知识吧关于第一点，RAG的降级，只能说，没彻底死了就是好的。可RAG什么时候成了必须品了？没感觉过啊？但确实，把它当一个工具还是不错的而第二点，确实，当场景需要从大量非结构化数据里快速筛选信息的时候，依然需要RAG技术吧，只不过可能推理啊，检索啊之类的，结合一下agent，效果应该会更好"></a>总结一下，少量上下文的情况下，还真不太需要RAG了。尤其是随着上下文窗口的增长，“少量”的定义也将不断扩大。这点不可否认。但话又说回来，RAG本来也不是针对这个场景的吧。回忆一下，最经典的RAG的故事，是说模型要接触最新的知识，以及其它的可能有用的知识吧<br>关于第一点，RAG的降级，只能说，没彻底死了就是好的。可RAG什么时候成了必须品了？没感觉过啊？但确实，把它当一个工具还是不错的<br>而第二点，确实，当场景需要从大量非结构化数据里快速筛选信息的时候，依然需要RAG技术吧，只不过可能推理啊，检索啊之类的，结合一下agent，效果应该会更好</h2><h1 id="还有个问题，随着deepseek-OCR的出现，有人说，会带来几个影响："><a href="#还有个问题，随着deepseek-OCR的出现，有人说，会带来几个影响：" class="headerlink" title="还有个问题，随着deepseek OCR的出现，有人说，会带来几个影响："></a>还有个问题，随着deepseek OCR的出现，有人说，会带来几个影响：</h1><h2 id="1-文本embedding会被抛弃。因为它觉得，ds-ocr能做到高效的压缩编码，相比起传统的语义embedding，压缩效率高太多了。而且它结合现在大厂（meta，Google）开始越来越多使用grep-ripgrep，做出判断，对文本，其实我们应该考虑直接去匹配原文。"><a href="#1-文本embedding会被抛弃。因为它觉得，ds-ocr能做到高效的压缩编码，相比起传统的语义embedding，压缩效率高太多了。而且它结合现在大厂（meta，Google）开始越来越多使用grep-ripgrep，做出判断，对文本，其实我们应该考虑直接去匹配原文。" class="headerlink" title="1. 文本embedding会被抛弃。因为它觉得，ds ocr能做到高效的压缩编码，相比起传统的语义embedding，压缩效率高太多了。而且它结合现在大厂（meta，Google）开始越来越多使用grep&#x2F;ripgrep，做出判断，对文本，其实我们应该考虑直接去匹配原文。"></a>1. 文本embedding会被抛弃。因为它觉得，ds ocr能做到高效的压缩编码，相比起传统的语义embedding，压缩效率高太多了。而且它结合现在大厂（meta，Google）开始越来越多使用grep&#x2F;ripgrep，做出判断，对文本，其实我们应该考虑直接去匹配原文。</h2><h3 id="但这应该只是纯文本的情况吧。多模态RAG呢？多模态的东西，你总得用embedding之类的latent表示吧，那这样，为了保持联系，文本不应该也用embedding表示？或者大家都用ds-ocr那样的latent-representation表示好了。起码得统一"><a href="#但这应该只是纯文本的情况吧。多模态RAG呢？多模态的东西，你总得用embedding之类的latent表示吧，那这样，为了保持联系，文本不应该也用embedding表示？或者大家都用ds-ocr那样的latent-representation表示好了。起码得统一" class="headerlink" title="但这应该只是纯文本的情况吧。多模态RAG呢？多模态的东西，你总得用embedding之类的latent表示吧，那这样，为了保持联系，文本不应该也用embedding表示？或者大家都用ds ocr那样的latent representation表示好了。起码得统一"></a>但这应该只是纯文本的情况吧。多模态RAG呢？多模态的东西，你总得用embedding之类的latent表示吧，那这样，为了保持联系，文本不应该也用embedding表示？或者大家都用ds ocr那样的latent representation表示好了。起码得统一</h3><h2 id="2-chunk的困境会被破除"><a href="#2-chunk的困境会被破除" class="headerlink" title="2. chunk的困境会被破除"></a>2. chunk的困境会被破除</h2><h3 id="具体来说，它认为，因为ds-ocr的压缩效率很高，可能一个100页的pdf，用ds-ocr压缩之后，也能轻松放到上下文窗口里。此时一看，就没有检索分块的必要了"><a href="#具体来说，它认为，因为ds-ocr的压缩效率很高，可能一个100页的pdf，用ds-ocr压缩之后，也能轻松放到上下文窗口里。此时一看，就没有检索分块的必要了" class="headerlink" title="具体来说，它认为，因为ds ocr的压缩效率很高，可能一个100页的pdf，用ds ocr压缩之后，也能轻松放到上下文窗口里。此时一看，就没有检索分块的必要了"></a>具体来说，它认为，因为ds ocr的压缩效率很高，可能一个100页的pdf，用ds ocr压缩之后，也能轻松放到上下文窗口里。此时一看，就没有检索分块的必要了</h3><h3 id="但这也仅仅是针对少数文档的情况吧，因为压缩效率很高，可以无需检索。一旦文档多了，比如有一个database的情况，该检索还是得检索吧，即使ds-ocr压缩效率很高。不过，确实好像这么一看，每个文档我也不需要chunk了？不过这样具体该怎么检索呢？每个文档给压缩成了若干visual-token，不好进行语义检索了吧？嗯，或许embedding也不是完全的一无是处，粗筛一下还是能用的吧"><a href="#但这也仅仅是针对少数文档的情况吧，因为压缩效率很高，可以无需检索。一旦文档多了，比如有一个database的情况，该检索还是得检索吧，即使ds-ocr压缩效率很高。不过，确实好像这么一看，每个文档我也不需要chunk了？不过这样具体该怎么检索呢？每个文档给压缩成了若干visual-token，不好进行语义检索了吧？嗯，或许embedding也不是完全的一无是处，粗筛一下还是能用的吧" class="headerlink" title="但这也仅仅是针对少数文档的情况吧，因为压缩效率很高，可以无需检索。一旦文档多了，比如有一个database的情况，该检索还是得检索吧，即使ds ocr压缩效率很高。不过，确实好像这么一看，每个文档我也不需要chunk了？不过这样具体该怎么检索呢？每个文档给压缩成了若干visual token，不好进行语义检索了吧？嗯，或许embedding也不是完全的一无是处，粗筛一下还是能用的吧"></a>但这也仅仅是针对少数文档的情况吧，因为压缩效率很高，可以无需检索。一旦文档多了，比如有一个database的情况，该检索还是得检索吧，即使ds ocr压缩效率很高。不过，确实好像这么一看，每个文档我也不需要chunk了？不过这样具体该怎么检索呢？每个文档给压缩成了若干visual token，不好进行语义检索了吧？嗯，或许embedding也不是完全的一无是处，粗筛一下还是能用的吧</h3><h1 id="structure-R1，这个有点像是把我想做的给做了。具体来说，它是把RAG检索回来的文档转化成结构化形式（感觉可以理解为，把结构信息显式化了，以便llm理解）"><a href="#structure-R1，这个有点像是把我想做的给做了。具体来说，它是把RAG检索回来的文档转化成结构化形式（感觉可以理解为，把结构信息显式化了，以便llm理解）" class="headerlink" title="structure-R1，这个有点像是把我想做的给做了。具体来说，它是把RAG检索回来的文档转化成结构化形式（感觉可以理解为，把结构信息显式化了，以便llm理解）"></a>structure-R1，这个有点像是把我想做的给做了。具体来说，它是把RAG检索回来的文档转化成结构化形式（感觉可以理解为，把结构信息显式化了，以便llm理解）</h1><h1 id="多跳RAG，感觉实质也是在为chunk和embedding带来的低效检索补窟窿。正是因为语义embedding的检索可能检索回来的东西不对，chunk又把完整内容给划分得太碎了，所以考虑引入graph结构，并且进行多跳操作，把可能的内容弥补回来（这样的话，精筛-rerank的时候，能不能有些不一样的评判标准？）另外，多模态的graph和文本的graph相比，多跳的时候有什么不一样吗"><a href="#多跳RAG，感觉实质也是在为chunk和embedding带来的低效检索补窟窿。正是因为语义embedding的检索可能检索回来的东西不对，chunk又把完整内容给划分得太碎了，所以考虑引入graph结构，并且进行多跳操作，把可能的内容弥补回来（这样的话，精筛-rerank的时候，能不能有些不一样的评判标准？）另外，多模态的graph和文本的graph相比，多跳的时候有什么不一样吗" class="headerlink" title="多跳RAG，感觉实质也是在为chunk和embedding带来的低效检索补窟窿。正是因为语义embedding的检索可能检索回来的东西不对，chunk又把完整内容给划分得太碎了，所以考虑引入graph结构，并且进行多跳操作，把可能的内容弥补回来（这样的话，精筛&#x2F;rerank的时候，能不能有些不一样的评判标准？）另外，多模态的graph和文本的graph相比，多跳的时候有什么不一样吗"></a>多跳RAG，感觉实质也是在为chunk和embedding带来的低效检索补窟窿。正是因为语义embedding的检索可能检索回来的东西不对，chunk又把完整内容给划分得太碎了，所以考虑引入graph结构，并且进行多跳操作，把可能的内容弥补回来（这样的话，精筛&#x2F;rerank的时候，能不能有些不一样的评判标准？）另外，多模态的graph和文本的graph相比，多跳的时候有什么不一样吗</h1><h1 id="还有，agentic-RAG有必要吗？它解决了哪些RAG的问题？RAG真的完全死了吗？"><a href="#还有，agentic-RAG有必要吗？它解决了哪些RAG的问题？RAG真的完全死了吗？" class="headerlink" title="还有，agentic RAG有必要吗？它解决了哪些RAG的问题？RAG真的完全死了吗？"></a>还有，agentic RAG有必要吗？它解决了哪些RAG的问题？RAG真的完全死了吗？</h1><h2 id="现在感觉，RAG并没有完全死吧。毕竟它最大的问题是，切chunk-语义向量检索导致的检索精度差以及上下文不连贯。那在相当一部分场景里是不好的。但用它来粗筛，或者是如果我们追求在大量数据上进行检索，且不那么要求高质量，那其实RAG还是有用武之地的（反而此时agentic-RAG成本会比较高）"><a href="#现在感觉，RAG并没有完全死吧。毕竟它最大的问题是，切chunk-语义向量检索导致的检索精度差以及上下文不连贯。那在相当一部分场景里是不好的。但用它来粗筛，或者是如果我们追求在大量数据上进行检索，且不那么要求高质量，那其实RAG还是有用武之地的（反而此时agentic-RAG成本会比较高）" class="headerlink" title="现在感觉，RAG并没有完全死吧。毕竟它最大的问题是，切chunk+语义向量检索导致的检索精度差以及上下文不连贯。那在相当一部分场景里是不好的。但用它来粗筛，或者是如果我们追求在大量数据上进行检索，且不那么要求高质量，那其实RAG还是有用武之地的（反而此时agentic RAG成本会比较高）"></a>现在感觉，RAG并没有完全死吧。毕竟它最大的问题是，切chunk+语义向量检索导致的检索精度差以及上下文不连贯。那在相当一部分场景里是不好的。但用它来粗筛，或者是如果我们追求在大量数据上进行检索，且不那么要求高质量，那其实RAG还是有用武之地的（反而此时agentic RAG成本会比较高）</h2><h2 id="最近，进一步激发“RAG已死”言论的，是claude-code的出现，不仅效果比cursor要好，还因为它没有用RAG，所以没有一个庞大的向量库需要维护，因此也省了很多空间。而Claude-code其实是用回了七十年代的grep和glob这些文件系统工具。看起来很返璞归真，再联想一下RAG的各种弊端，似乎RAG真的得被淘汰了？"><a href="#最近，进一步激发“RAG已死”言论的，是claude-code的出现，不仅效果比cursor要好，还因为它没有用RAG，所以没有一个庞大的向量库需要维护，因此也省了很多空间。而Claude-code其实是用回了七十年代的grep和glob这些文件系统工具。看起来很返璞归真，再联想一下RAG的各种弊端，似乎RAG真的得被淘汰了？" class="headerlink" title="最近，进一步激发“RAG已死”言论的，是claude code的出现，不仅效果比cursor要好，还因为它没有用RAG，所以没有一个庞大的向量库需要维护，因此也省了很多空间。而Claude code其实是用回了七十年代的grep和glob这些文件系统工具。看起来很返璞归真，再联想一下RAG的各种弊端，似乎RAG真的得被淘汰了？"></a>最近，进一步激发“RAG已死”言论的，是claude code的出现，不仅效果比cursor要好，还因为它没有用RAG，所以没有一个庞大的向量库需要维护，因此也省了很多空间。而Claude code其实是用回了七十年代的grep和glob这些文件系统工具。看起来很返璞归真，再联想一下RAG的各种弊端，似乎RAG真的得被淘汰了？</h2><h3 id="但，这只是因为grep和glob刚好在编程这一块很实用。毕竟代码本质上是一种非常规范的文本。但比如说，聊天记录之类的，这种就完全不规范了，那还用grep、glob这些，能行吗？就不好说了吧？"><a href="#但，这只是因为grep和glob刚好在编程这一块很实用。毕竟代码本质上是一种非常规范的文本。但比如说，聊天记录之类的，这种就完全不规范了，那还用grep、glob这些，能行吗？就不好说了吧？" class="headerlink" title="但，这只是因为grep和glob刚好在编程这一块很实用。毕竟代码本质上是一种非常规范的文本。但比如说，聊天记录之类的，这种就完全不规范了，那还用grep、glob这些，能行吗？就不好说了吧？"></a>但，这只是因为grep和glob刚好在编程这一块很实用。毕竟代码本质上是一种非常规范的文本。但比如说，聊天记录之类的，这种就完全不规范了，那还用grep、glob这些，能行吗？就不好说了吧？</h3><h3 id="更进一步的，这些都是针对文本的，忽略了多模态的情况啊。图像怎么办？还能glob-grep吗？显然不行吧？虽说文本你用grep这些，图像再单独走另一套也不是不行吧。但最起码，多模态的RAG，它还是有用的（说到底，我们对图像的处理，基本上还是得处理成向量吧？）"><a href="#更进一步的，这些都是针对文本的，忽略了多模态的情况啊。图像怎么办？还能glob-grep吗？显然不行吧？虽说文本你用grep这些，图像再单独走另一套也不是不行吧。但最起码，多模态的RAG，它还是有用的（说到底，我们对图像的处理，基本上还是得处理成向量吧？）" class="headerlink" title="更进一步的，这些都是针对文本的，忽略了多模态的情况啊。图像怎么办？还能glob&#x2F;grep吗？显然不行吧？虽说文本你用grep这些，图像再单独走另一套也不是不行吧。但最起码，多模态的RAG，它还是有用的（说到底，我们对图像的处理，基本上还是得处理成向量吧？）"></a>更进一步的，这些都是针对文本的，忽略了多模态的情况啊。图像怎么办？还能glob&#x2F;grep吗？显然不行吧？虽说文本你用grep这些，图像再单独走另一套也不是不行吧。但最起码，多模态的RAG，它还是有用的（说到底，我们对图像的处理，基本上还是得处理成向量吧？）</h3><h2 id="看看这几篇博文吧，感觉都挺好的："><a href="#看看这几篇博文吧，感觉都挺好的：" class="headerlink" title="看看这几篇博文吧，感觉都挺好的："></a>看看这几篇博文吧，感觉都挺好的：</h2><h3 id="RAG与Context-Engineer的关系"><a href="#RAG与Context-Engineer的关系" class="headerlink" title="RAG与Context Engineer的关系"></a><a target="_blank" rel="noopener" href="https://kirigaya.cn/blog/article?seq=356">RAG与Context Engineer的关系</a></h3><h3 id="一篇疑似对“RAG已死”的翻译的博文，不过读起来还是可以的"><a href="#一篇疑似对“RAG已死”的翻译的博文，不过读起来还是可以的" class="headerlink" title="一篇疑似对“RAG已死”的翻译的博文，不过读起来还是可以的"></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1961345919405514850">一篇疑似对“RAG已死”的翻译的博文</a>，不过读起来还是可以的</h3><h3 id="经典的RAG已死，或者说是RAG的讣告"><a href="#经典的RAG已死，或者说是RAG的讣告" class="headerlink" title="经典的RAG已死，或者说是RAG的讣告"></a>经典的<a target="_blank" rel="noopener" href="https://www.nicolasbustamante.com/p/the-rag-obituary-killed-by-agents">RAG已死，或者说是RAG的讣告</a></h3><h3 id="一篇非常务实的回答，关于RAG与agentic-RAG的优缺点"><a href="#一篇非常务实的回答，关于RAG与agentic-RAG的优缺点" class="headerlink" title="一篇非常务实的回答，关于RAG与agentic RAG的优缺点"></a><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/1923191592593892684/answer/1945642914484053463">一篇非常务实的回答，关于RAG与agentic RAG的优缺点</a></h3><h3 id="这个是关于agentic-RL的整理。感觉它可以拓宽眼界，从而能更加了解agentic-RAG的必要性，以及它的可能的用途"><a href="#这个是关于agentic-RL的整理。感觉它可以拓宽眼界，从而能更加了解agentic-RAG的必要性，以及它的可能的用途" class="headerlink" title="这个是关于agentic RL的整理。感觉它可以拓宽眼界，从而能更加了解agentic RAG的必要性，以及它的可能的用途"></a>这个是<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1963453208383984904">关于agentic RL的整理</a>。感觉它可以拓宽眼界，从而能更加了解agentic RAG的必要性，以及它的可能的用途</h3><h2 id="还有一个很关键的问题。上述关于RAG已死的言论，似乎都是默认在文本模态下工作的吧？一旦引入了图像、音频、视频之类的多模态，除了编码成向量，还能怎样？总不能像文本那样可以grep了吧？如果要在这方面做改进，感觉确实得在检索方面下一些功夫了，这个就比较底层，应该也比较难吧"><a href="#还有一个很关键的问题。上述关于RAG已死的言论，似乎都是默认在文本模态下工作的吧？一旦引入了图像、音频、视频之类的多模态，除了编码成向量，还能怎样？总不能像文本那样可以grep了吧？如果要在这方面做改进，感觉确实得在检索方面下一些功夫了，这个就比较底层，应该也比较难吧" class="headerlink" title="还有一个很关键的问题。上述关于RAG已死的言论，似乎都是默认在文本模态下工作的吧？一旦引入了图像、音频、视频之类的多模态，除了编码成向量，还能怎样？总不能像文本那样可以grep了吧？如果要在这方面做改进，感觉确实得在检索方面下一些功夫了，这个就比较底层，应该也比较难吧"></a>还有一个很关键的问题。上述关于RAG已死的言论，似乎都是默认在文本模态下工作的吧？一旦引入了图像、音频、视频之类的多模态，除了编码成向量，还能怎样？总不能像文本那样可以grep了吧？如果要在这方面做改进，感觉确实得在检索方面下一些功夫了，这个就比较底层，应该也比较难吧</h2><h2 id="agentic-RAG，它的一大优点，就是“能动性”，可以自主地根据场合做决定，而不需要依赖我们事先定义好的工作流。也就是，在当前场合下，它会自动采取一个动作。但这个动作具体怎么执行，通常还是人来规定的。这一点好不好？长远来说可能不好吧，我们当然希望agent能完全自主。但这个还是有点远的吧？至少现在，就这么些规定好的动作，让agent学会自主选择，都还挺难的，资源开销也不小了。关于动作内容的自主化，可能也是一个未来的研究方向吧"><a href="#agentic-RAG，它的一大优点，就是“能动性”，可以自主地根据场合做决定，而不需要依赖我们事先定义好的工作流。也就是，在当前场合下，它会自动采取一个动作。但这个动作具体怎么执行，通常还是人来规定的。这一点好不好？长远来说可能不好吧，我们当然希望agent能完全自主。但这个还是有点远的吧？至少现在，就这么些规定好的动作，让agent学会自主选择，都还挺难的，资源开销也不小了。关于动作内容的自主化，可能也是一个未来的研究方向吧" class="headerlink" title="agentic RAG，它的一大优点，就是“能动性”，可以自主地根据场合做决定，而不需要依赖我们事先定义好的工作流。也就是，在当前场合下，它会自动采取一个动作。但这个动作具体怎么执行，通常还是人来规定的。这一点好不好？长远来说可能不好吧，我们当然希望agent能完全自主。但这个还是有点远的吧？至少现在，就这么些规定好的动作，让agent学会自主选择，都还挺难的，资源开销也不小了。关于动作内容的自主化，可能也是一个未来的研究方向吧"></a>agentic RAG，它的一大优点，就是“能动性”，可以自主地根据场合做决定，而不需要依赖我们事先定义好的工作流。也就是，在当前场合下，它会自动采取一个动作。但这个动作具体怎么执行，通常还是人来规定的。这一点好不好？长远来说可能不好吧，我们当然希望agent能完全自主。但这个还是有点远的吧？至少现在，就这么些规定好的动作，让agent学会自主选择，都还挺难的，资源开销也不小了。关于动作内容的自主化，可能也是一个未来的研究方向吧</h2><h1 id="我们如果做agentic-mmgraphrag，可以吗？它的确是没什么人做，但是价值在哪呢？以及能不能和现有的大厂做出来的agent进行融入（就是作为插件加入到它们那边）？如果不行，那我们是否需要换一个关注点，比如它们的agent开销比较大（模型大-api调用花费多），而我们就专注在小模型上，这样对比也只需要跟小模型的方法对比，而且训练也只需要训练小模型，或许会好一些"><a href="#我们如果做agentic-mmgraphrag，可以吗？它的确是没什么人做，但是价值在哪呢？以及能不能和现有的大厂做出来的agent进行融入（就是作为插件加入到它们那边）？如果不行，那我们是否需要换一个关注点，比如它们的agent开销比较大（模型大-api调用花费多），而我们就专注在小模型上，这样对比也只需要跟小模型的方法对比，而且训练也只需要训练小模型，或许会好一些" class="headerlink" title="我们如果做agentic mmgraphrag，可以吗？它的确是没什么人做，但是价值在哪呢？以及能不能和现有的大厂做出来的agent进行融入（就是作为插件加入到它们那边）？如果不行，那我们是否需要换一个关注点，比如它们的agent开销比较大（模型大&#x2F;api调用花费多），而我们就专注在小模型上，这样对比也只需要跟小模型的方法对比，而且训练也只需要训练小模型，或许会好一些"></a>我们如果做agentic mmgraphrag，可以吗？它的确是没什么人做，但是价值在哪呢？以及能不能和现有的大厂做出来的agent进行融入（就是作为插件加入到它们那边）？如果不行，那我们是否需要换一个关注点，比如它们的agent开销比较大（模型大&#x2F;api调用花费多），而我们就专注在小模型上，这样对比也只需要跟小模型的方法对比，而且训练也只需要训练小模型，或许会好一些</h1><h1 id="RAG里确实基本假设是静态的知识库。遇到新的知识来了呢"><a href="#RAG里确实基本假设是静态的知识库。遇到新的知识来了呢" class="headerlink" title="RAG里确实基本假设是静态的知识库。遇到新的知识来了呢"></a>RAG里确实基本假设是静态的知识库。遇到新的知识来了呢</h1><h2 id="不断有新知识出现，这并不是一个可以直接由上网检索就能解决的问题，因为新知识出现的地方也不止是网上。很多企业应该都会有大量的业务数据，这些数据显然不可能公开，所以会有私有增量数据的情况。此时，就需要更新知识库了"><a href="#不断有新知识出现，这并不是一个可以直接由上网检索就能解决的问题，因为新知识出现的地方也不止是网上。很多企业应该都会有大量的业务数据，这些数据显然不可能公开，所以会有私有增量数据的情况。此时，就需要更新知识库了" class="headerlink" title="不断有新知识出现，这并不是一个可以直接由上网检索就能解决的问题，因为新知识出现的地方也不止是网上。很多企业应该都会有大量的业务数据，这些数据显然不可能公开，所以会有私有增量数据的情况。此时，就需要更新知识库了"></a>不断有新知识出现，这并不是一个可以直接由上网检索就能解决的问题，因为新知识出现的地方也不止是网上。很多企业应该都会有大量的业务数据，这些数据显然不可能公开，所以会有私有增量数据的情况。此时，就需要更新知识库了</h2><h3 id="更新知识库的时候也会有一些问题，比如，新旧知识之间的融合？合并？或者如果它们出现了冲突怎么办？又或者有一些问题需要跨度比较大的新旧知识，一起来分析，怎么办？旧的知识好像不应该一味地丢弃吧？（像之前读到过的VersionRAG，其实就是关注了一个相当小的方面。一个好一点的工作，应该能完全囊括它吧）"><a href="#更新知识库的时候也会有一些问题，比如，新旧知识之间的融合？合并？或者如果它们出现了冲突怎么办？又或者有一些问题需要跨度比较大的新旧知识，一起来分析，怎么办？旧的知识好像不应该一味地丢弃吧？（像之前读到过的VersionRAG，其实就是关注了一个相当小的方面。一个好一点的工作，应该能完全囊括它吧）" class="headerlink" title="更新知识库的时候也会有一些问题，比如，新旧知识之间的融合？合并？或者如果它们出现了冲突怎么办？又或者有一些问题需要跨度比较大的新旧知识，一起来分析，怎么办？旧的知识好像不应该一味地丢弃吧？（像之前读到过的VersionRAG，其实就是关注了一个相当小的方面。一个好一点的工作，应该能完全囊括它吧）"></a>更新知识库的时候也会有一些问题，比如，新旧知识之间的融合？合并？或者如果它们出现了冲突怎么办？又或者有一些问题需要跨度比较大的新旧知识，一起来分析，怎么办？旧的知识好像不应该一味地丢弃吧？（像之前读到过的VersionRAG，其实就是关注了一个相当小的方面。一个好一点的工作，应该能完全囊括它吧）</h3><h2 id="其实，RAG的一个重要应用领域就是私有数据库上的检索。即使llm继续发展，它调用网络检索工具的能力更加提高了，对于私有数据，没有获取权限也没办法。只有私有数据的拥有者可以部署模型，并构建RAG进行检索（或者说，我们也不需要一直强调RAG。但是私有数据的确需要被检索，这点是真的）（不过，如果是这样，那其实反正是要部署在私有数据上，为什么不用agentic-rag呢？这里可能就会涉及到rag-routing了？）（这样一想，倒是明确了，agentic-rag的efficiency肯定也是一个值得研究的东西）"><a href="#其实，RAG的一个重要应用领域就是私有数据库上的检索。即使llm继续发展，它调用网络检索工具的能力更加提高了，对于私有数据，没有获取权限也没办法。只有私有数据的拥有者可以部署模型，并构建RAG进行检索（或者说，我们也不需要一直强调RAG。但是私有数据的确需要被检索，这点是真的）（不过，如果是这样，那其实反正是要部署在私有数据上，为什么不用agentic-rag呢？这里可能就会涉及到rag-routing了？）（这样一想，倒是明确了，agentic-rag的efficiency肯定也是一个值得研究的东西）" class="headerlink" title="其实，RAG的一个重要应用领域就是私有数据库上的检索。即使llm继续发展，它调用网络检索工具的能力更加提高了，对于私有数据，没有获取权限也没办法。只有私有数据的拥有者可以部署模型，并构建RAG进行检索（或者说，我们也不需要一直强调RAG。但是私有数据的确需要被检索，这点是真的）（不过，如果是这样，那其实反正是要部署在私有数据上，为什么不用agentic rag呢？这里可能就会涉及到rag routing了？）（这样一想，倒是明确了，agentic rag的efficiency肯定也是一个值得研究的东西）"></a>其实，RAG的一个重要应用领域就是私有数据库上的检索。即使llm继续发展，它调用网络检索工具的能力更加提高了，对于私有数据，没有获取权限也没办法。只有私有数据的拥有者可以部署模型，并构建RAG进行检索（或者说，我们也不需要一直强调RAG。但是私有数据的确需要被检索，这点是真的）（不过，如果是这样，那其实反正是要部署在私有数据上，为什么不用agentic rag呢？这里可能就会涉及到rag routing了？）（这样一想，倒是明确了，agentic rag的efficiency肯定也是一个值得研究的东西）</h2><h2 id="哦对，而且之所以说在私有数据库上要进行检索，而不是微调模型喂给模型知识，也是因为微调很麻烦，资源需求大吧，还可能有遗忘其它知识的风险。RAG就是一种免训练的方法（In-Context-Learning固然也是一种方法，但是直观上，它只能在一些相对简单的任务上，通过提供一些例子帮助llm理解。而且不是有研究说，icl的话，提供过多的例子的时候，其实没太多提升吗）"><a href="#哦对，而且之所以说在私有数据库上要进行检索，而不是微调模型喂给模型知识，也是因为微调很麻烦，资源需求大吧，还可能有遗忘其它知识的风险。RAG就是一种免训练的方法（In-Context-Learning固然也是一种方法，但是直观上，它只能在一些相对简单的任务上，通过提供一些例子帮助llm理解。而且不是有研究说，icl的话，提供过多的例子的时候，其实没太多提升吗）" class="headerlink" title="哦对，而且之所以说在私有数据库上要进行检索，而不是微调模型喂给模型知识，也是因为微调很麻烦，资源需求大吧，还可能有遗忘其它知识的风险。RAG就是一种免训练的方法（In-Context Learning固然也是一种方法，但是直观上，它只能在一些相对简单的任务上，通过提供一些例子帮助llm理解。而且不是有研究说，icl的话，提供过多的例子的时候，其实没太多提升吗）"></a>哦对，而且之所以说在私有数据库上要进行检索，而不是微调模型喂给模型知识，也是因为微调很麻烦，资源需求大吧，还可能有遗忘其它知识的风险。RAG就是一种免训练的方法（In-Context Learning固然也是一种方法，但是直观上，它只能在一些相对简单的任务上，通过提供一些例子帮助llm理解。而且不是有研究说，icl的话，提供过多的例子的时候，其实没太多提升吗）</h2><h1 id="话说，rag的提出动机之一，是作为llm的外挂记忆。这就涉及到长期记忆这个东西了。最近研究得有点多。或许可以总结一下最近看到的memory方面的paper，看看它们到底相比于rag有什么改变，为何急不可耐地抨击和抛弃rag"><a href="#话说，rag的提出动机之一，是作为llm的外挂记忆。这就涉及到长期记忆这个东西了。最近研究得有点多。或许可以总结一下最近看到的memory方面的paper，看看它们到底相比于rag有什么改变，为何急不可耐地抨击和抛弃rag" class="headerlink" title="话说，rag的提出动机之一，是作为llm的外挂记忆。这就涉及到长期记忆这个东西了。最近研究得有点多。或许可以总结一下最近看到的memory方面的paper，看看它们到底相比于rag有什么改变，为何急不可耐地抨击和抛弃rag"></a>话说，rag的提出动机之一，是作为llm的外挂记忆。这就涉及到长期记忆这个东西了。最近研究得有点多。或许可以总结一下最近看到的memory方面的paper，看看它们到底相比于rag有什么改变，为何急不可耐地抨击和抛弃rag</h1>
    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/09/27/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20%20KV%20Cache%E5%8E%8B%E7%BC%A9%E6%96%B0%E9%98%B6%E6%AE%B5%EF%BC%9A%E8%B5%B0%E5%90%91%E9%97%AE%E9%A2%98%E6%8C%87%E4%BB%A4%E6%97%A0%E5%85%B3%E4%B8%8B%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%8E%A2%E7%B4%A2/" rel="prev" title="博客阅读 KV Cache压缩新阶段：走向问题指令无关下的压缩探索">
      <i class="fa fa-chevron-left"></i> 博客阅读 KV Cache压缩新阶段：走向问题指令无关下的压缩探索
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/video%E7%9B%B8%E5%85%B3%E7%9A%84RAGpaper%E8%B0%83%E7%A0%94/" rel="next" title="">
       <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%88%96%E8%AE%B8%E5%BE%97%E6%80%9D%E8%80%83%E4%B8%80%E4%B8%8B%E4%B8%BA%E4%BB%80%E4%B9%88RAG%E4%B8%80%E7%9B%B4%E8%A2%AB%E4%BA%BA%E8%AF%9F%E7%97%85%EF%BC%9F%E5%AE%83%E7%9A%84%E9%97%AE%E9%A2%98%E5%88%B0%E5%BA%95%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9FGraphRAG%EF%BC%8C%E8%A7%A3%E5%86%B3%E4%BA%86RAG%E7%9A%84%E5%93%AA%E4%BA%9B%E9%97%AE%E9%A2%98%EF%BC%9F%E8%BF%98%E6%9C%89%E5%93%AA%E4%BA%9B%E6%9C%AC%E8%B4%A8%E9%97%AE%E9%A2%98%E6%B2%A1%E6%9C%89%E8%A7%A3%E5%86%B3%EF%BC%9F"><span class="nav-number">1.</span> <span class="nav-text">或许得思考一下为什么RAG一直被人诟病？它的问题到底在哪里？GraphRAG，解决了RAG的哪些问题？还有哪些本质问题没有解决？</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8D%E5%A6%A8%E5%85%88%E4%BB%8E%E4%BC%A0%E7%BB%9FRAG%E5%BC%80%E5%A7%8B%E8%AF%B4%E8%B5%B7%E3%80%82%E9%82%A3%E5%AE%83%E7%9A%84%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E6%93%8D%E4%BD%9C%EF%BC%8C%E6%8A%8A%E6%96%87%E6%A1%A3%E8%BF%9B%E8%A1%8Cchunk%EF%BC%8C%E5%85%B6%E5%AE%9E%E5%B0%B1%E6%98%AF%E4%B8%80%E4%B8%AA%E6%9C%89%E5%BE%88%E5%A4%9A%E5%BC%8A%E7%AB%AF%E7%9A%84%E6%93%8D%E4%BD%9C%EF%BC%9A%E7%A1%AC%E6%80%A7%E5%88%87%E5%88%86%EF%BC%8C%E5%AF%BC%E8%87%B4%E5%86%85%E5%AE%B9%E5%8F%AF%E8%83%BD%E5%89%B2%E8%A3%82%EF%BC%88%E4%BE%8B%E5%A6%82%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E5%86%85%E5%AE%B9%E8%A2%AB%E5%88%87%E5%89%B2%E5%88%B0%E4%B8%A4%E4%B8%AA%EF%BC%8C%E4%B9%83%E8%87%B3%E5%A4%9A%E4%B8%AAchunk%E4%B8%AD%EF%BC%89"><span class="nav-number">1.1.</span> <span class="nav-text">不妨先从传统RAG开始说起。那它的最开始的操作，把文档进行chunk，其实就是一个有很多弊端的操作：硬性切分，导致内容可能割裂（例如一个完整的内容被切割到两个，乃至多个chunk中）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%98%E6%9C%89%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%8C%E7%8E%B0%E5%9C%A8%E7%9A%84RAG%E9%87%8C%E7%9A%84%E5%BE%88%E5%A4%9A%E6%8A%80%E6%9C%AF%EF%BC%8C%E6%88%96%E8%80%85%E8%AF%B4%E6%96%B9%E6%B3%95%EF%BC%8C%E6%84%9F%E8%A7%89%E9%83%BD%E5%8F%AF%E8%83%BD%E9%9A%8F%E7%9D%80%E5%9F%BA%E6%A8%A1%E7%9A%84%E5%8F%91%E5%B1%95%E8%80%8C%E5%8F%98%E5%BE%97%E6%97%A0%E7%94%A8%E3%80%82%E6%AF%94%E5%A6%82%EF%BC%8C%E6%88%91%E4%BB%AC%E6%8A%8A%E7%9F%A5%E8%AF%86%E5%BA%93%E7%BB%84%E7%BB%87%E6%88%90graph%E7%9A%84%E6%A0%BC%E5%BC%8F%EF%BC%8C%E8%BF%99%E6%98%AF%E4%B8%BA%E4%BA%86%E6%9B%B4%E5%A5%BD%E4%BD%93%E7%8E%B0data%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%E3%80%82%E5%85%B6%E5%AE%9E%E7%9B%B8%E5%BD%93%E4%BA%8E%E6%88%91%E4%BB%AC%E6%98%BE%E5%BC%8F%E5%9C%B0%E6%8A%8A%E8%BF%99%E4%BA%9B%E5%85%B3%E7%B3%BB%E7%BB%99%E6%8F%90%E7%82%BC%E5%87%BA%E6%9D%A5%EF%BC%8C%E4%BB%A5%E4%BE%BF%E6%A8%A1%E5%9E%8B%E8%83%BD%E6%8E%8C%E6%8F%A1%E5%88%B0%EF%BC%88%E6%88%96%E8%80%85%E8%AF%B4%EF%BC%8C%E6%98%AF%E6%88%91%E4%BB%AC%E5%9C%A8%E6%8B%85%E5%BF%83%EF%BC%8C%E5%A6%82%E6%9E%9C%E4%B8%8D%E6%8F%90%E7%82%BC%E5%87%BA%E6%9D%A5%EF%BC%8C%E9%82%A3%E6%A8%A1%E5%9E%8B%E5%B0%B1%E6%84%9F%E7%9F%A5%E4%B8%8D%E5%88%B0%E8%BF%99%E4%B8%AA%E5%85%B3%E7%B3%BB%EF%BC%89%E3%80%82%E4%BD%86%E5%81%87%E5%A6%82%EF%BC%8C%E5%9F%BA%E6%A8%A1%E4%B8%8D%E6%96%AD%E5%8F%91%E5%B1%95%EF%BC%8C%E5%AE%83%E7%9A%84%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E4%B9%9F%E4%B8%8D%E6%96%AD%E6%8F%90%E9%AB%98%EF%BC%8C%E6%9C%80%E7%BB%88%E6%88%91%E4%BB%AC%E5%8F%AA%E9%9C%80%E8%A6%81%E6%8A%8A%E6%A3%80%E7%B4%A2%E5%88%B0%E7%9A%84%E5%86%85%E5%AE%B9%E7%9B%B4%E6%8E%A5%E6%8B%BF%E7%BB%99%E5%AE%83%EF%BC%8C%E5%AE%83%E5%B0%B1%E8%83%BD%E6%8E%A8%E7%90%86%E5%87%BA%E8%BF%99%E4%BA%9B%E5%85%B3%E7%B3%BB%EF%BC%8C%E7%94%9A%E8%87%B3%E8%BF%98%E8%83%BD%E8%87%AA%E5%8F%91%E7%9A%84%E7%A0%94%E7%A9%B6%E6%9B%B4%E6%B7%B1%E5%B1%82%E7%9A%84%E5%85%B3%E7%B3%BB%EF%BC%8C%E9%82%A3%E4%B8%8D%E5%B0%B1%E6%B2%A1%E5%BF%85%E8%A6%81%E6%90%9Egraph%E4%BA%86%E5%90%97%EF%BC%9F"><span class="nav-number">1.2.</span> <span class="nav-text">还有一个问题，现在的RAG里的很多技术，或者说方法，感觉都可能随着基模的发展而变得无用。比如，我们把知识库组织成graph的格式，这是为了更好体现data之间的关系。其实相当于我们显式地把这些关系给提炼出来，以便模型能掌握到（或者说，是我们在担心，如果不提炼出来，那模型就感知不到这个关系）。但假如，基模不断发展，它的推理能力也不断提高，最终我们只需要把检索到的内容直接拿给它，它就能推理出这些关系，甚至还能自发的研究更深层的关系，那不就没必要搞graph了吗？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%A6%EF%BC%8CRAG%E9%87%8C%E5%BE%88%E5%A4%9A%E6%97%B6%E5%80%99%E9%83%BD%E6%98%AF%E5%9C%A8%E5%80%9F%E7%94%A8%E6%A8%A1%E5%9E%8B%E6%9C%AC%E8%BA%AB%E7%9A%84%E8%83%BD%E5%8A%9B%EF%BC%8C%E8%87%AA%E5%B7%B1%E5%81%9A%E7%9A%84%E5%AE%9E%E8%B4%A8%E5%B0%B1%E6%98%AF%E4%B8%80%E4%B8%AAprompt-engineer%EF%BC%8C%E8%BF%99%E5%B0%B1%E6%98%BE%E5%BE%97%E5%BE%88%E6%B2%A1%E6%9C%89%E6%8A%80%E6%9C%AF%E5%90%AB%E9%87%8F%E3%80%82%E4%BD%86%E6%88%96%E8%AE%B8%E4%B9%9F%E8%AF%A5%E6%8D%A2%E4%B8%AA%E8%A7%92%E5%BA%A6%E7%9C%8B%EF%BC%8C%E4%B8%8D%E7%AE%A1%E8%BF%99%E4%B8%AA%E4%BA%8B%E5%9C%A8%E5%88%AB%E4%BA%BA%E7%9C%8B%E6%9D%A5%E6%98%AF%E5%90%A6%E6%9C%89%E5%90%AB%E9%87%91%E9%87%8F%EF%BC%8C%E5%A6%82%E6%9E%9C%E5%AE%83%E7%A1%AE%E5%AE%9E%E6%9C%89%E6%95%88%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B8%8D%E5%A6%A8%E4%B9%9F%E8%83%BD%E7%A7%B0%E4%B8%8A%E4%B8%80%E5%8F%A5simple-and-effective"><span class="nav-number">1.3.</span> <span class="nav-text">另，RAG里很多时候都是在借用模型本身的能力，自己做的实质就是一个prompt engineer，这就显得很没有技术含量。但或许也该换个角度看，不管这个事在别人看来是否有含金量，如果它确实有效，我们不妨也能称上一句simple and effective</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RAG%E7%9A%84%E5%BB%B6%E8%BF%9F%EF%BC%8C%E5%BE%88%E4%B8%A5%E9%87%8D%E5%90%97%EF%BC%9F%E7%A1%AE%E5%AE%9E%EF%BC%8C%E7%B2%97%E7%AD%9B%E3%80%81rerank%E3%80%81%E7%B2%BE%E7%AD%9B%EF%BC%8C%E5%81%87%E5%A6%82%E8%BF%99%E4%B8%80%E5%A5%97%E6%B5%81%E7%A8%8B%E8%B5%B0%E4%B8%8B%E6%9D%A5%EF%BC%8C%E7%BB%99%E4%BA%BA%E6%84%9F%E8%A7%89%E6%AD%A5%E9%AA%A4%E5%BE%88%E5%A4%9A%EF%BC%8C%E8%80%8C%E4%B8%94%E5%9B%A0%E4%B8%BA%E6%98%AF%E7%BA%A7%E8%81%94%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%8C%E4%B8%8A%E4%B8%80%E6%AD%A5%E7%9A%84%E8%AF%AF%E5%B7%AE%E6%9C%89%E5%8F%AF%E8%83%BD%E5%BD%B1%E5%93%8D%E4%B8%8B%E4%B8%80%E6%AD%A5%E7%9A%84%E8%AF%AF%E5%B7%AE%EF%BC%88%E4%BD%86%E5%B0%B1%E6%B2%A1%E5%8F%AF%E8%83%BD%E6%98%AF%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B8%8B%E4%B8%80%E6%AD%A5%E6%98%AF%E5%9F%BA%E4%BA%8E%E4%B8%8A%E4%B8%80%E6%AD%A5%E7%9A%84%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E7%BA%A0%E6%AD%A3%E5%92%8C%E5%89%8D%E8%BF%9B%E5%90%97%EF%BC%9F%EF%BC%89%E3%80%82%E8%BF%99%E6%98%AF%E8%AE%B2%E6%95%85%E4%BA%8B%E8%BF%98%E6%98%AF%E7%A1%AE%E6%9C%89%E5%85%B6%E4%BA%8B%EF%BC%9F%E6%9C%89%E5%BF%85%E8%A6%81%E3%80%81%E6%9C%89%E5%8F%AF%E8%83%BD%E9%80%9A%E8%BF%87%E8%BD%BB%E9%87%8F%E5%8C%96%E7%AD%89%E6%8A%80%E6%9C%AF%E5%87%8F%E7%BC%93%E5%BB%B6%E8%BF%9F%EF%BC%8C%E4%BB%8E%E8%80%8C%E6%8F%90%E9%AB%98%E5%85%B6%E5%AE%9E%E7%94%A8%E6%80%A7%E5%90%97"><span class="nav-number">1.4.</span> <span class="nav-text">RAG的延迟，很严重吗？确实，粗筛、rerank、精筛，假如这一套流程走下来，给人感觉步骤很多，而且因为是级联的方式，上一步的误差有可能影响下一步的误差（但就没可能是，我们下一步是基于上一步的结果进行纠正和前进吗？）。这是讲故事还是确有其事？有必要、有可能通过轻量化等技术减缓延迟，从而提高其实用性吗</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%86%E4%B8%8D%E5%BE%97%E4%B8%8D%E8%AF%B4%EF%BC%8C%E5%8D%B3%E4%BD%BF%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AA%97%E5%8F%A3%E5%86%8D%E6%80%8E%E4%B9%88%E5%A2%9E%E9%95%BF%EF%BC%88%E4%B8%94%E4%B8%8D%E8%AF%B4%E5%AE%83%E6%8C%81%E7%BB%AD%E5%A2%9E%E9%95%BF%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8C%E6%80%A7%E8%83%BD%E6%98%AF%E5%90%A6%E8%83%BD%E5%92%8C%E7%9F%AD%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E6%97%B6%E5%80%99%E7%9A%84%E6%80%A7%E8%83%BD%E6%8C%81%E5%B9%B3%EF%BC%89%EF%BC%8C%E4%B9%9F%E4%B8%8D%E5%8F%AF%E8%83%BD%E6%8A%8A%E6%89%80%E6%9C%89%E7%9A%84%E8%B5%84%E6%96%99%E9%83%BD%E4%B8%80%E5%8F%A3%E6%B0%94%E5%90%83%E4%B8%8B%E5%8E%BB%E3%80%82%E4%B8%8D%E7%AE%A1%E6%98%AF%E5%A4%A7%E4%B8%80%E7%82%B9%E7%9A%84%E6%9C%AC%E5%9C%B0%E8%B5%84%E6%96%99%E5%BA%93%EF%BC%8C%E8%BF%98%E6%98%AF%E7%BD%91%E7%BB%9C%E4%B8%8A%E7%9A%84%E8%B5%84%E6%96%99%EF%BC%8C%E8%BF%99%E9%83%BD%E5%BA%94%E8%AF%A5%E6%B2%A1%E5%8F%AF%E8%83%BD%E5%85%A8%E9%83%A8%E5%90%83%E8%BF%9B%E5%8E%BB%E3%80%82%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%AF%B4%EF%BC%8C%E5%AF%B9%E6%9B%B4%E5%A4%A7%E8%8C%83%E5%9B%B4%E7%9A%84%E7%9F%A5%E8%AF%86%EF%BC%8C%E4%BB%A5%E5%8F%8A%E6%9C%80%E6%96%B0%E7%9F%A5%E8%AF%86%E7%9A%84%E8%8E%B7%E5%8F%96%EF%BC%8C%E5%A7%8B%E7%BB%88%E6%98%AF%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E4%B8%AA%E5%BF%85%E8%A6%81%E7%9A%84%E9%9C%80%E6%B1%82%E3%80%82%E8%87%B3%E4%BA%8E%E8%AF%B4%E6%9C%80%E7%BB%88%E6%89%8B%E6%AE%B5%E6%98%AF%E4%B8%8D%E6%98%AFRAG%EF%BC%8C%E6%88%96%E8%80%85%E8%AF%B4%E8%BF%99%E4%B8%AA%E6%89%8B%E6%AE%B5%E8%BF%98%E5%8F%AB%E4%B8%8D%E5%8F%ABRAG%EF%BC%8C%E9%82%A3%E6%84%9F%E8%A7%89%E6%B2%A1%E9%82%A3%E4%B9%88%E9%87%8D%E8%A6%81%E3%80%82%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%80%9F%E7%94%A8%E4%B8%80%E4%B8%8B%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83%E7%9A%84%E8%AF%9D%EF%BC%8C%E2%80%9CRAG-%E6%9C%AC%E8%BA%AB%E6%89%80%E4%BB%A3%E8%A1%A8%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%E2%80%94%E2%80%94%E4%B8%BA-LLM-%E6%8F%90%E4%BE%9B%E7%B2%BE%E5%87%86%E3%80%81%E5%8F%AF%E9%9D%A0%E7%9A%84%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AF%86%E2%80%94%E2%80%94%E7%9A%84%E9%9C%80%E6%B1%82%E6%98%AF%E6%B0%B8%E6%81%92%E7%9A%84%E2%80%9D"><span class="nav-number">2.</span> <span class="nav-text">但不得不说，即使模型的上下文窗口再怎么增长（且不说它持续增长的情况下，性能是否能和短上下文的时候的性能持平），也不可能把所有的资料都一口气吃下去。不管是大一点的本地资料库，还是网络上的资料，这都应该没可能全部吃进去。也就是说，对更大范围的知识，以及最新知识的获取，始终是模型的一个必要的需求。至于说最终手段是不是RAG，或者说这个手段还叫不叫RAG，那感觉没那么重要。简单来说，借用一下机器之心的话，“RAG 本身所代表的核心思想——为 LLM 提供精准、可靠的外部知识——的需求是永恒的”</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9D%A5%E7%9C%8B%E7%9C%8B%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83%E6%8E%A8%E6%96%87%E9%87%8C%E7%9A%84%E8%AF%B4%E6%B3%95%EF%BC%9A"><span class="nav-number">2.1.</span> <span class="nav-text">来看看机器之心推文里的说法：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AA%E6%9D%A5%E7%9A%84%E5%9B%BE%E6%99%AF%E6%9B%B4%E5%8F%AF%E8%83%BD%E6%98%AF%EF%BC%9A"><span class="nav-number">2.1.1.</span> <span class="nav-text">未来的图景更可能是：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RAG-%E7%9A%84%E8%A7%92%E8%89%B2%E8%BD%AC%E5%8F%98%EF%BC%9ARAG-%E4%B8%8D%E5%86%8D%E6%98%AF%E6%89%80%E6%9C%89%E5%BA%94%E7%94%A8%E7%9A%84%E9%BB%98%E8%AE%A4%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%EF%BC%8C%E8%80%8C%E6%98%AF%E8%A2%AB%E3%80%8C%E9%99%8D%E7%BA%A7%E3%80%8D%E4%B8%BA-Agent-%E5%B7%A5%E5%85%B7%E7%AE%B1%E4%B8%AD%E7%9A%84%E4%B8%80%E4%B8%AA%E5%BC%BA%E5%A4%A7%E7%BB%84%E4%BB%B6%E3%80%82%E5%AE%83%E5%B0%86%E4%B8%8E%E4%BB%A3%E7%A0%81%E8%A7%A3%E9%87%8A%E5%99%A8%E3%80%81API-%E8%B0%83%E7%94%A8%E3%80%81%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%93%8D%E4%BD%9C%E7%AD%89%E5%B7%A5%E5%85%B7%E5%B9%B3%E8%B5%B7%E5%B9%B3%E5%9D%90%E3%80%82"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">RAG 的角色转变：RAG 不再是所有应用的默认核心架构，而是被「降级」为 Agent 工具箱中的一个强大组件。它将与代码解释器、API 调用、文件系统操作等工具平起平坐。</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF%E5%86%B3%E5%AE%9A%E6%9E%B6%E6%9E%84%EF%BC%9A%E5%AF%B9%E4%BA%8E%E9%9C%80%E8%A6%81%E4%BB%8E%E6%B5%B7%E9%87%8F%E3%80%81%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%AB%E9%80%9F%E7%AD%9B%E9%80%89%E4%BF%A1%E6%81%AF%E7%9A%84%E5%9C%BA%E6%99%AF%EF%BC%88%E5%A6%82%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E3%80%81%E4%BC%81%E4%B8%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E5%88%9D%E7%AD%9B%EF%BC%89%EF%BC%8C%E7%94%B1-Agent-%E9%A9%B1%E5%8A%A8%E7%9A%84%E3%80%81%E9%AB%98%E5%BA%A6%E5%B7%A5%E7%A8%8B%E5%8C%96%E7%9A%84%E9%AB%98%E7%BA%A7-RAG-%E7%B3%BB%E7%BB%9F%E4%BB%8D%E6%98%AF%E6%9C%80%E4%BD%B3%E9%80%89%E6%8B%A9%E3%80%82"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">场景决定架构：对于需要从海量、非结构化数据中快速筛选信息的场景（如智能客服、企业知识库初筛），由 Agent 驱动的、高度工程化的高级 RAG 系统仍是最佳选择。</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E7%BB%9F%E6%B2%BB%E5%8A%9B%EF%BC%9A%E5%AF%B9%E4%BA%8E%E9%9C%80%E8%A6%81%E5%AF%B9%E5%B0%91%E9%87%8F%E3%80%81%E7%BB%93%E6%9E%84%E5%A4%8D%E6%9D%82%E7%9A%84%E6%96%87%E6%A1%A3%E8%BF%9B%E8%A1%8C%E6%B7%B1%E5%BA%A6%E6%8E%A8%E7%90%86%E5%92%8C%E5%88%86%E6%9E%90%E7%9A%84%E5%9C%BA%E6%99%AF%EF%BC%88%E5%A6%82%E8%B4%A2%E6%8A%A5%E5%88%86%E6%9E%90%E3%80%81%E6%B3%95%E5%BE%8B%E5%90%88%E5%90%8C%E5%AE%A1%E6%9F%A5%EF%BC%89%EF%BC%8C%E3%80%8C%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AA%97%E5%8F%A3-Agent-%E8%B0%83%E6%9F%A5%E3%80%8D%E7%9A%84%E8%8C%83%E5%BC%8F%E5%B0%86%E5%B1%95%E7%8E%B0%E5%87%BA%E7%A2%BE%E5%8E%8B%E6%80%A7%E7%9A%84%E4%BC%98%E5%8A%BF%E3%80%82"><span class="nav-number">2.1.1.3.</span> <span class="nav-text">长上下文的统治力：对于需要对少量、结构复杂的文档进行深度推理和分析的场景（如财报分析、法律合同审查），「长上下文窗口 + Agent 调查」的范式将展现出碾压性的优势。</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E4%BA%8E%E5%BC%80%E5%8F%91%E8%80%85%E8%80%8C%E8%A8%80%EF%BC%8C%E5%85%B3%E9%94%AE%E5%9C%A8%E4%BA%8E%E7%90%86%E8%A7%A3%E4%B8%8D%E5%90%8C%E6%8A%80%E6%9C%AF%E8%8C%83%E5%BC%8F%E7%9A%84%E4%BC%98%E5%8A%A3%EF%BC%8C%E5%B9%B6%E6%A0%B9%E6%8D%AE%E5%85%B7%E4%BD%93%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%8C%E7%81%B5%E6%B4%BB%E5%9C%B0%E5%B0%86%E5%AE%83%E4%BB%AC%E7%BB%84%E5%90%88%E6%88%90%E6%9C%80%E9%AB%98%E6%95%88%E3%80%81%E6%9C%80%E5%8F%AF%E9%9D%A0%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%82"><span class="nav-number">2.1.2.</span> <span class="nav-text">对于开发者而言，关键在于理解不同技术范式的优劣，并根据具体的应用场景，灵活地将它们组合成最高效、最可靠的解决方案。</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8B%EF%BC%8C%E5%B0%91%E9%87%8F%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8C%E8%BF%98%E7%9C%9F%E4%B8%8D%E5%A4%AA%E9%9C%80%E8%A6%81RAG%E4%BA%86%E3%80%82%E5%B0%A4%E5%85%B6%E6%98%AF%E9%9A%8F%E7%9D%80%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AA%97%E5%8F%A3%E7%9A%84%E5%A2%9E%E9%95%BF%EF%BC%8C%E2%80%9C%E5%B0%91%E9%87%8F%E2%80%9D%E7%9A%84%E5%AE%9A%E4%B9%89%E4%B9%9F%E5%B0%86%E4%B8%8D%E6%96%AD%E6%89%A9%E5%A4%A7%E3%80%82%E8%BF%99%E7%82%B9%E4%B8%8D%E5%8F%AF%E5%90%A6%E8%AE%A4%E3%80%82%E4%BD%86%E8%AF%9D%E5%8F%88%E8%AF%B4%E5%9B%9E%E6%9D%A5%EF%BC%8CRAG%E6%9C%AC%E6%9D%A5%E4%B9%9F%E4%B8%8D%E6%98%AF%E9%92%88%E5%AF%B9%E8%BF%99%E4%B8%AA%E5%9C%BA%E6%99%AF%E7%9A%84%E5%90%A7%E3%80%82%E5%9B%9E%E5%BF%86%E4%B8%80%E4%B8%8B%EF%BC%8C%E6%9C%80%E7%BB%8F%E5%85%B8%E7%9A%84RAG%E7%9A%84%E6%95%85%E4%BA%8B%EF%BC%8C%E6%98%AF%E8%AF%B4%E6%A8%A1%E5%9E%8B%E8%A6%81%E6%8E%A5%E8%A7%A6%E6%9C%80%E6%96%B0%E7%9A%84%E7%9F%A5%E8%AF%86%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%85%B6%E5%AE%83%E7%9A%84%E5%8F%AF%E8%83%BD%E6%9C%89%E7%94%A8%E7%9A%84%E7%9F%A5%E8%AF%86%E5%90%A7%E5%85%B3%E4%BA%8E%E7%AC%AC%E4%B8%80%E7%82%B9%EF%BC%8CRAG%E7%9A%84%E9%99%8D%E7%BA%A7%EF%BC%8C%E5%8F%AA%E8%83%BD%E8%AF%B4%EF%BC%8C%E6%B2%A1%E5%BD%BB%E5%BA%95%E6%AD%BB%E4%BA%86%E5%B0%B1%E6%98%AF%E5%A5%BD%E7%9A%84%E3%80%82%E5%8F%AFRAG%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E6%88%90%E4%BA%86%E5%BF%85%E9%A1%BB%E5%93%81%E4%BA%86%EF%BC%9F%E6%B2%A1%E6%84%9F%E8%A7%89%E8%BF%87%E5%95%8A%EF%BC%9F%E4%BD%86%E7%A1%AE%E5%AE%9E%EF%BC%8C%E6%8A%8A%E5%AE%83%E5%BD%93%E4%B8%80%E4%B8%AA%E5%B7%A5%E5%85%B7%E8%BF%98%E6%98%AF%E4%B8%8D%E9%94%99%E7%9A%84%E8%80%8C%E7%AC%AC%E4%BA%8C%E7%82%B9%EF%BC%8C%E7%A1%AE%E5%AE%9E%EF%BC%8C%E5%BD%93%E5%9C%BA%E6%99%AF%E9%9C%80%E8%A6%81%E4%BB%8E%E5%A4%A7%E9%87%8F%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E9%87%8C%E5%BF%AB%E9%80%9F%E7%AD%9B%E9%80%89%E4%BF%A1%E6%81%AF%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E4%BE%9D%E7%84%B6%E9%9C%80%E8%A6%81RAG%E6%8A%80%E6%9C%AF%E5%90%A7%EF%BC%8C%E5%8F%AA%E4%B8%8D%E8%BF%87%E5%8F%AF%E8%83%BD%E6%8E%A8%E7%90%86%E5%95%8A%EF%BC%8C%E6%A3%80%E7%B4%A2%E5%95%8A%E4%B9%8B%E7%B1%BB%E7%9A%84%EF%BC%8C%E7%BB%93%E5%90%88%E4%B8%80%E4%B8%8Bagent%EF%BC%8C%E6%95%88%E6%9E%9C%E5%BA%94%E8%AF%A5%E4%BC%9A%E6%9B%B4%E5%A5%BD"><span class="nav-number">2.2.</span> <span class="nav-text">总结一下，少量上下文的情况下，还真不太需要RAG了。尤其是随着上下文窗口的增长，“少量”的定义也将不断扩大。这点不可否认。但话又说回来，RAG本来也不是针对这个场景的吧。回忆一下，最经典的RAG的故事，是说模型要接触最新的知识，以及其它的可能有用的知识吧关于第一点，RAG的降级，只能说，没彻底死了就是好的。可RAG什么时候成了必须品了？没感觉过啊？但确实，把它当一个工具还是不错的而第二点，确实，当场景需要从大量非结构化数据里快速筛选信息的时候，依然需要RAG技术吧，只不过可能推理啊，检索啊之类的，结合一下agent，效果应该会更好</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%BF%98%E6%9C%89%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%8C%E9%9A%8F%E7%9D%80deepseek-OCR%E7%9A%84%E5%87%BA%E7%8E%B0%EF%BC%8C%E6%9C%89%E4%BA%BA%E8%AF%B4%EF%BC%8C%E4%BC%9A%E5%B8%A6%E6%9D%A5%E5%87%A0%E4%B8%AA%E5%BD%B1%E5%93%8D%EF%BC%9A"><span class="nav-number">3.</span> <span class="nav-text">还有个问题，随着deepseek OCR的出现，有人说，会带来几个影响：</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E6%96%87%E6%9C%ACembedding%E4%BC%9A%E8%A2%AB%E6%8A%9B%E5%BC%83%E3%80%82%E5%9B%A0%E4%B8%BA%E5%AE%83%E8%A7%89%E5%BE%97%EF%BC%8Cds-ocr%E8%83%BD%E5%81%9A%E5%88%B0%E9%AB%98%E6%95%88%E7%9A%84%E5%8E%8B%E7%BC%A9%E7%BC%96%E7%A0%81%EF%BC%8C%E7%9B%B8%E6%AF%94%E8%B5%B7%E4%BC%A0%E7%BB%9F%E7%9A%84%E8%AF%AD%E4%B9%89embedding%EF%BC%8C%E5%8E%8B%E7%BC%A9%E6%95%88%E7%8E%87%E9%AB%98%E5%A4%AA%E5%A4%9A%E4%BA%86%E3%80%82%E8%80%8C%E4%B8%94%E5%AE%83%E7%BB%93%E5%90%88%E7%8E%B0%E5%9C%A8%E5%A4%A7%E5%8E%82%EF%BC%88meta%EF%BC%8CGoogle%EF%BC%89%E5%BC%80%E5%A7%8B%E8%B6%8A%E6%9D%A5%E8%B6%8A%E5%A4%9A%E4%BD%BF%E7%94%A8grep-ripgrep%EF%BC%8C%E5%81%9A%E5%87%BA%E5%88%A4%E6%96%AD%EF%BC%8C%E5%AF%B9%E6%96%87%E6%9C%AC%EF%BC%8C%E5%85%B6%E5%AE%9E%E6%88%91%E4%BB%AC%E5%BA%94%E8%AF%A5%E8%80%83%E8%99%91%E7%9B%B4%E6%8E%A5%E5%8E%BB%E5%8C%B9%E9%85%8D%E5%8E%9F%E6%96%87%E3%80%82"><span class="nav-number">3.1.</span> <span class="nav-text">1. 文本embedding会被抛弃。因为它觉得，ds ocr能做到高效的压缩编码，相比起传统的语义embedding，压缩效率高太多了。而且它结合现在大厂（meta，Google）开始越来越多使用grep&#x2F;ripgrep，做出判断，对文本，其实我们应该考虑直接去匹配原文。</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%86%E8%BF%99%E5%BA%94%E8%AF%A5%E5%8F%AA%E6%98%AF%E7%BA%AF%E6%96%87%E6%9C%AC%E7%9A%84%E6%83%85%E5%86%B5%E5%90%A7%E3%80%82%E5%A4%9A%E6%A8%A1%E6%80%81RAG%E5%91%A2%EF%BC%9F%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9A%84%E4%B8%9C%E8%A5%BF%EF%BC%8C%E4%BD%A0%E6%80%BB%E5%BE%97%E7%94%A8embedding%E4%B9%8B%E7%B1%BB%E7%9A%84latent%E8%A1%A8%E7%A4%BA%E5%90%A7%EF%BC%8C%E9%82%A3%E8%BF%99%E6%A0%B7%EF%BC%8C%E4%B8%BA%E4%BA%86%E4%BF%9D%E6%8C%81%E8%81%94%E7%B3%BB%EF%BC%8C%E6%96%87%E6%9C%AC%E4%B8%8D%E5%BA%94%E8%AF%A5%E4%B9%9F%E7%94%A8embedding%E8%A1%A8%E7%A4%BA%EF%BC%9F%E6%88%96%E8%80%85%E5%A4%A7%E5%AE%B6%E9%83%BD%E7%94%A8ds-ocr%E9%82%A3%E6%A0%B7%E7%9A%84latent-representation%E8%A1%A8%E7%A4%BA%E5%A5%BD%E4%BA%86%E3%80%82%E8%B5%B7%E7%A0%81%E5%BE%97%E7%BB%9F%E4%B8%80"><span class="nav-number">3.1.1.</span> <span class="nav-text">但这应该只是纯文本的情况吧。多模态RAG呢？多模态的东西，你总得用embedding之类的latent表示吧，那这样，为了保持联系，文本不应该也用embedding表示？或者大家都用ds ocr那样的latent representation表示好了。起码得统一</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-chunk%E7%9A%84%E5%9B%B0%E5%A2%83%E4%BC%9A%E8%A2%AB%E7%A0%B4%E9%99%A4"><span class="nav-number">3.2.</span> <span class="nav-text">2. chunk的困境会被破除</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%AE%83%E8%AE%A4%E4%B8%BA%EF%BC%8C%E5%9B%A0%E4%B8%BAds-ocr%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%95%88%E7%8E%87%E5%BE%88%E9%AB%98%EF%BC%8C%E5%8F%AF%E8%83%BD%E4%B8%80%E4%B8%AA100%E9%A1%B5%E7%9A%84pdf%EF%BC%8C%E7%94%A8ds-ocr%E5%8E%8B%E7%BC%A9%E4%B9%8B%E5%90%8E%EF%BC%8C%E4%B9%9F%E8%83%BD%E8%BD%BB%E6%9D%BE%E6%94%BE%E5%88%B0%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AA%97%E5%8F%A3%E9%87%8C%E3%80%82%E6%AD%A4%E6%97%B6%E4%B8%80%E7%9C%8B%EF%BC%8C%E5%B0%B1%E6%B2%A1%E6%9C%89%E6%A3%80%E7%B4%A2%E5%88%86%E5%9D%97%E7%9A%84%E5%BF%85%E8%A6%81%E4%BA%86"><span class="nav-number">3.2.1.</span> <span class="nav-text">具体来说，它认为，因为ds ocr的压缩效率很高，可能一个100页的pdf，用ds ocr压缩之后，也能轻松放到上下文窗口里。此时一看，就没有检索分块的必要了</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%86%E8%BF%99%E4%B9%9F%E4%BB%85%E4%BB%85%E6%98%AF%E9%92%88%E5%AF%B9%E5%B0%91%E6%95%B0%E6%96%87%E6%A1%A3%E7%9A%84%E6%83%85%E5%86%B5%E5%90%A7%EF%BC%8C%E5%9B%A0%E4%B8%BA%E5%8E%8B%E7%BC%A9%E6%95%88%E7%8E%87%E5%BE%88%E9%AB%98%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%97%A0%E9%9C%80%E6%A3%80%E7%B4%A2%E3%80%82%E4%B8%80%E6%97%A6%E6%96%87%E6%A1%A3%E5%A4%9A%E4%BA%86%EF%BC%8C%E6%AF%94%E5%A6%82%E6%9C%89%E4%B8%80%E4%B8%AAdatabase%E7%9A%84%E6%83%85%E5%86%B5%EF%BC%8C%E8%AF%A5%E6%A3%80%E7%B4%A2%E8%BF%98%E6%98%AF%E5%BE%97%E6%A3%80%E7%B4%A2%E5%90%A7%EF%BC%8C%E5%8D%B3%E4%BD%BFds-ocr%E5%8E%8B%E7%BC%A9%E6%95%88%E7%8E%87%E5%BE%88%E9%AB%98%E3%80%82%E4%B8%8D%E8%BF%87%EF%BC%8C%E7%A1%AE%E5%AE%9E%E5%A5%BD%E5%83%8F%E8%BF%99%E4%B9%88%E4%B8%80%E7%9C%8B%EF%BC%8C%E6%AF%8F%E4%B8%AA%E6%96%87%E6%A1%A3%E6%88%91%E4%B9%9F%E4%B8%8D%E9%9C%80%E8%A6%81chunk%E4%BA%86%EF%BC%9F%E4%B8%8D%E8%BF%87%E8%BF%99%E6%A0%B7%E5%85%B7%E4%BD%93%E8%AF%A5%E6%80%8E%E4%B9%88%E6%A3%80%E7%B4%A2%E5%91%A2%EF%BC%9F%E6%AF%8F%E4%B8%AA%E6%96%87%E6%A1%A3%E7%BB%99%E5%8E%8B%E7%BC%A9%E6%88%90%E4%BA%86%E8%8B%A5%E5%B9%B2visual-token%EF%BC%8C%E4%B8%8D%E5%A5%BD%E8%BF%9B%E8%A1%8C%E8%AF%AD%E4%B9%89%E6%A3%80%E7%B4%A2%E4%BA%86%E5%90%A7%EF%BC%9F%E5%97%AF%EF%BC%8C%E6%88%96%E8%AE%B8embedding%E4%B9%9F%E4%B8%8D%E6%98%AF%E5%AE%8C%E5%85%A8%E7%9A%84%E4%B8%80%E6%97%A0%E6%98%AF%E5%A4%84%EF%BC%8C%E7%B2%97%E7%AD%9B%E4%B8%80%E4%B8%8B%E8%BF%98%E6%98%AF%E8%83%BD%E7%94%A8%E7%9A%84%E5%90%A7"><span class="nav-number">3.2.2.</span> <span class="nav-text">但这也仅仅是针对少数文档的情况吧，因为压缩效率很高，可以无需检索。一旦文档多了，比如有一个database的情况，该检索还是得检索吧，即使ds ocr压缩效率很高。不过，确实好像这么一看，每个文档我也不需要chunk了？不过这样具体该怎么检索呢？每个文档给压缩成了若干visual token，不好进行语义检索了吧？嗯，或许embedding也不是完全的一无是处，粗筛一下还是能用的吧</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#structure-R1%EF%BC%8C%E8%BF%99%E4%B8%AA%E6%9C%89%E7%82%B9%E5%83%8F%E6%98%AF%E6%8A%8A%E6%88%91%E6%83%B3%E5%81%9A%E7%9A%84%E7%BB%99%E5%81%9A%E4%BA%86%E3%80%82%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%AE%83%E6%98%AF%E6%8A%8ARAG%E6%A3%80%E7%B4%A2%E5%9B%9E%E6%9D%A5%E7%9A%84%E6%96%87%E6%A1%A3%E8%BD%AC%E5%8C%96%E6%88%90%E7%BB%93%E6%9E%84%E5%8C%96%E5%BD%A2%E5%BC%8F%EF%BC%88%E6%84%9F%E8%A7%89%E5%8F%AF%E4%BB%A5%E7%90%86%E8%A7%A3%E4%B8%BA%EF%BC%8C%E6%8A%8A%E7%BB%93%E6%9E%84%E4%BF%A1%E6%81%AF%E6%98%BE%E5%BC%8F%E5%8C%96%E4%BA%86%EF%BC%8C%E4%BB%A5%E4%BE%BFllm%E7%90%86%E8%A7%A3%EF%BC%89"><span class="nav-number">4.</span> <span class="nav-text">structure-R1，这个有点像是把我想做的给做了。具体来说，它是把RAG检索回来的文档转化成结构化形式（感觉可以理解为，把结构信息显式化了，以便llm理解）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%9A%E8%B7%B3RAG%EF%BC%8C%E6%84%9F%E8%A7%89%E5%AE%9E%E8%B4%A8%E4%B9%9F%E6%98%AF%E5%9C%A8%E4%B8%BAchunk%E5%92%8Cembedding%E5%B8%A6%E6%9D%A5%E7%9A%84%E4%BD%8E%E6%95%88%E6%A3%80%E7%B4%A2%E8%A1%A5%E7%AA%9F%E7%AA%BF%E3%80%82%E6%AD%A3%E6%98%AF%E5%9B%A0%E4%B8%BA%E8%AF%AD%E4%B9%89embedding%E7%9A%84%E6%A3%80%E7%B4%A2%E5%8F%AF%E8%83%BD%E6%A3%80%E7%B4%A2%E5%9B%9E%E6%9D%A5%E7%9A%84%E4%B8%9C%E8%A5%BF%E4%B8%8D%E5%AF%B9%EF%BC%8Cchunk%E5%8F%88%E6%8A%8A%E5%AE%8C%E6%95%B4%E5%86%85%E5%AE%B9%E7%BB%99%E5%88%92%E5%88%86%E5%BE%97%E5%A4%AA%E7%A2%8E%E4%BA%86%EF%BC%8C%E6%89%80%E4%BB%A5%E8%80%83%E8%99%91%E5%BC%95%E5%85%A5graph%E7%BB%93%E6%9E%84%EF%BC%8C%E5%B9%B6%E4%B8%94%E8%BF%9B%E8%A1%8C%E5%A4%9A%E8%B7%B3%E6%93%8D%E4%BD%9C%EF%BC%8C%E6%8A%8A%E5%8F%AF%E8%83%BD%E7%9A%84%E5%86%85%E5%AE%B9%E5%BC%A5%E8%A1%A5%E5%9B%9E%E6%9D%A5%EF%BC%88%E8%BF%99%E6%A0%B7%E7%9A%84%E8%AF%9D%EF%BC%8C%E7%B2%BE%E7%AD%9B-rerank%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E8%83%BD%E4%B8%8D%E8%83%BD%E6%9C%89%E4%BA%9B%E4%B8%8D%E4%B8%80%E6%A0%B7%E7%9A%84%E8%AF%84%E5%88%A4%E6%A0%87%E5%87%86%EF%BC%9F%EF%BC%89%E5%8F%A6%E5%A4%96%EF%BC%8C%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9A%84graph%E5%92%8C%E6%96%87%E6%9C%AC%E7%9A%84graph%E7%9B%B8%E6%AF%94%EF%BC%8C%E5%A4%9A%E8%B7%B3%E7%9A%84%E6%97%B6%E5%80%99%E6%9C%89%E4%BB%80%E4%B9%88%E4%B8%8D%E4%B8%80%E6%A0%B7%E5%90%97"><span class="nav-number">5.</span> <span class="nav-text">多跳RAG，感觉实质也是在为chunk和embedding带来的低效检索补窟窿。正是因为语义embedding的检索可能检索回来的东西不对，chunk又把完整内容给划分得太碎了，所以考虑引入graph结构，并且进行多跳操作，把可能的内容弥补回来（这样的话，精筛&#x2F;rerank的时候，能不能有些不一样的评判标准？）另外，多模态的graph和文本的graph相比，多跳的时候有什么不一样吗</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%BF%98%E6%9C%89%EF%BC%8Cagentic-RAG%E6%9C%89%E5%BF%85%E8%A6%81%E5%90%97%EF%BC%9F%E5%AE%83%E8%A7%A3%E5%86%B3%E4%BA%86%E5%93%AA%E4%BA%9BRAG%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9FRAG%E7%9C%9F%E7%9A%84%E5%AE%8C%E5%85%A8%E6%AD%BB%E4%BA%86%E5%90%97%EF%BC%9F"><span class="nav-number">6.</span> <span class="nav-text">还有，agentic RAG有必要吗？它解决了哪些RAG的问题？RAG真的完全死了吗？</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%B0%E5%9C%A8%E6%84%9F%E8%A7%89%EF%BC%8CRAG%E5%B9%B6%E6%B2%A1%E6%9C%89%E5%AE%8C%E5%85%A8%E6%AD%BB%E5%90%A7%E3%80%82%E6%AF%95%E7%AB%9F%E5%AE%83%E6%9C%80%E5%A4%A7%E7%9A%84%E9%97%AE%E9%A2%98%E6%98%AF%EF%BC%8C%E5%88%87chunk-%E8%AF%AD%E4%B9%89%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%87%B4%E7%9A%84%E6%A3%80%E7%B4%A2%E7%B2%BE%E5%BA%A6%E5%B7%AE%E4%BB%A5%E5%8F%8A%E4%B8%8A%E4%B8%8B%E6%96%87%E4%B8%8D%E8%BF%9E%E8%B4%AF%E3%80%82%E9%82%A3%E5%9C%A8%E7%9B%B8%E5%BD%93%E4%B8%80%E9%83%A8%E5%88%86%E5%9C%BA%E6%99%AF%E9%87%8C%E6%98%AF%E4%B8%8D%E5%A5%BD%E7%9A%84%E3%80%82%E4%BD%86%E7%94%A8%E5%AE%83%E6%9D%A5%E7%B2%97%E7%AD%9B%EF%BC%8C%E6%88%96%E8%80%85%E6%98%AF%E5%A6%82%E6%9E%9C%E6%88%91%E4%BB%AC%E8%BF%BD%E6%B1%82%E5%9C%A8%E5%A4%A7%E9%87%8F%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%A3%80%E7%B4%A2%EF%BC%8C%E4%B8%94%E4%B8%8D%E9%82%A3%E4%B9%88%E8%A6%81%E6%B1%82%E9%AB%98%E8%B4%A8%E9%87%8F%EF%BC%8C%E9%82%A3%E5%85%B6%E5%AE%9ERAG%E8%BF%98%E6%98%AF%E6%9C%89%E7%94%A8%E6%AD%A6%E4%B9%8B%E5%9C%B0%E7%9A%84%EF%BC%88%E5%8F%8D%E8%80%8C%E6%AD%A4%E6%97%B6agentic-RAG%E6%88%90%E6%9C%AC%E4%BC%9A%E6%AF%94%E8%BE%83%E9%AB%98%EF%BC%89"><span class="nav-number">6.1.</span> <span class="nav-text">现在感觉，RAG并没有完全死吧。毕竟它最大的问题是，切chunk+语义向量检索导致的检索精度差以及上下文不连贯。那在相当一部分场景里是不好的。但用它来粗筛，或者是如果我们追求在大量数据上进行检索，且不那么要求高质量，那其实RAG还是有用武之地的（反而此时agentic RAG成本会比较高）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%80%E8%BF%91%EF%BC%8C%E8%BF%9B%E4%B8%80%E6%AD%A5%E6%BF%80%E5%8F%91%E2%80%9CRAG%E5%B7%B2%E6%AD%BB%E2%80%9D%E8%A8%80%E8%AE%BA%E7%9A%84%EF%BC%8C%E6%98%AFclaude-code%E7%9A%84%E5%87%BA%E7%8E%B0%EF%BC%8C%E4%B8%8D%E4%BB%85%E6%95%88%E6%9E%9C%E6%AF%94cursor%E8%A6%81%E5%A5%BD%EF%BC%8C%E8%BF%98%E5%9B%A0%E4%B8%BA%E5%AE%83%E6%B2%A1%E6%9C%89%E7%94%A8RAG%EF%BC%8C%E6%89%80%E4%BB%A5%E6%B2%A1%E6%9C%89%E4%B8%80%E4%B8%AA%E5%BA%9E%E5%A4%A7%E7%9A%84%E5%90%91%E9%87%8F%E5%BA%93%E9%9C%80%E8%A6%81%E7%BB%B4%E6%8A%A4%EF%BC%8C%E5%9B%A0%E6%AD%A4%E4%B9%9F%E7%9C%81%E4%BA%86%E5%BE%88%E5%A4%9A%E7%A9%BA%E9%97%B4%E3%80%82%E8%80%8CClaude-code%E5%85%B6%E5%AE%9E%E6%98%AF%E7%94%A8%E5%9B%9E%E4%BA%86%E4%B8%83%E5%8D%81%E5%B9%B4%E4%BB%A3%E7%9A%84grep%E5%92%8Cglob%E8%BF%99%E4%BA%9B%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B7%A5%E5%85%B7%E3%80%82%E7%9C%8B%E8%B5%B7%E6%9D%A5%E5%BE%88%E8%BF%94%E7%92%9E%E5%BD%92%E7%9C%9F%EF%BC%8C%E5%86%8D%E8%81%94%E6%83%B3%E4%B8%80%E4%B8%8BRAG%E7%9A%84%E5%90%84%E7%A7%8D%E5%BC%8A%E7%AB%AF%EF%BC%8C%E4%BC%BC%E4%B9%8ERAG%E7%9C%9F%E7%9A%84%E5%BE%97%E8%A2%AB%E6%B7%98%E6%B1%B0%E4%BA%86%EF%BC%9F"><span class="nav-number">6.2.</span> <span class="nav-text">最近，进一步激发“RAG已死”言论的，是claude code的出现，不仅效果比cursor要好，还因为它没有用RAG，所以没有一个庞大的向量库需要维护，因此也省了很多空间。而Claude code其实是用回了七十年代的grep和glob这些文件系统工具。看起来很返璞归真，再联想一下RAG的各种弊端，似乎RAG真的得被淘汰了？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%86%EF%BC%8C%E8%BF%99%E5%8F%AA%E6%98%AF%E5%9B%A0%E4%B8%BAgrep%E5%92%8Cglob%E5%88%9A%E5%A5%BD%E5%9C%A8%E7%BC%96%E7%A8%8B%E8%BF%99%E4%B8%80%E5%9D%97%E5%BE%88%E5%AE%9E%E7%94%A8%E3%80%82%E6%AF%95%E7%AB%9F%E4%BB%A3%E7%A0%81%E6%9C%AC%E8%B4%A8%E4%B8%8A%E6%98%AF%E4%B8%80%E7%A7%8D%E9%9D%9E%E5%B8%B8%E8%A7%84%E8%8C%83%E7%9A%84%E6%96%87%E6%9C%AC%E3%80%82%E4%BD%86%E6%AF%94%E5%A6%82%E8%AF%B4%EF%BC%8C%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95%E4%B9%8B%E7%B1%BB%E7%9A%84%EF%BC%8C%E8%BF%99%E7%A7%8D%E5%B0%B1%E5%AE%8C%E5%85%A8%E4%B8%8D%E8%A7%84%E8%8C%83%E4%BA%86%EF%BC%8C%E9%82%A3%E8%BF%98%E7%94%A8grep%E3%80%81glob%E8%BF%99%E4%BA%9B%EF%BC%8C%E8%83%BD%E8%A1%8C%E5%90%97%EF%BC%9F%E5%B0%B1%E4%B8%8D%E5%A5%BD%E8%AF%B4%E4%BA%86%E5%90%A7%EF%BC%9F"><span class="nav-number">6.2.1.</span> <span class="nav-text">但，这只是因为grep和glob刚好在编程这一块很实用。毕竟代码本质上是一种非常规范的文本。但比如说，聊天记录之类的，这种就完全不规范了，那还用grep、glob这些，能行吗？就不好说了吧？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%B4%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%9A%84%EF%BC%8C%E8%BF%99%E4%BA%9B%E9%83%BD%E6%98%AF%E9%92%88%E5%AF%B9%E6%96%87%E6%9C%AC%E7%9A%84%EF%BC%8C%E5%BF%BD%E7%95%A5%E4%BA%86%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9A%84%E6%83%85%E5%86%B5%E5%95%8A%E3%80%82%E5%9B%BE%E5%83%8F%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E8%BF%98%E8%83%BDglob-grep%E5%90%97%EF%BC%9F%E6%98%BE%E7%84%B6%E4%B8%8D%E8%A1%8C%E5%90%A7%EF%BC%9F%E8%99%BD%E8%AF%B4%E6%96%87%E6%9C%AC%E4%BD%A0%E7%94%A8grep%E8%BF%99%E4%BA%9B%EF%BC%8C%E5%9B%BE%E5%83%8F%E5%86%8D%E5%8D%95%E7%8B%AC%E8%B5%B0%E5%8F%A6%E4%B8%80%E5%A5%97%E4%B9%9F%E4%B8%8D%E6%98%AF%E4%B8%8D%E8%A1%8C%E5%90%A7%E3%80%82%E4%BD%86%E6%9C%80%E8%B5%B7%E7%A0%81%EF%BC%8C%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9A%84RAG%EF%BC%8C%E5%AE%83%E8%BF%98%E6%98%AF%E6%9C%89%E7%94%A8%E7%9A%84%EF%BC%88%E8%AF%B4%E5%88%B0%E5%BA%95%EF%BC%8C%E6%88%91%E4%BB%AC%E5%AF%B9%E5%9B%BE%E5%83%8F%E7%9A%84%E5%A4%84%E7%90%86%EF%BC%8C%E5%9F%BA%E6%9C%AC%E4%B8%8A%E8%BF%98%E6%98%AF%E5%BE%97%E5%A4%84%E7%90%86%E6%88%90%E5%90%91%E9%87%8F%E5%90%A7%EF%BC%9F%EF%BC%89"><span class="nav-number">6.2.2.</span> <span class="nav-text">更进一步的，这些都是针对文本的，忽略了多模态的情况啊。图像怎么办？还能glob&#x2F;grep吗？显然不行吧？虽说文本你用grep这些，图像再单独走另一套也不是不行吧。但最起码，多模态的RAG，它还是有用的（说到底，我们对图像的处理，基本上还是得处理成向量吧？）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9C%8B%E7%9C%8B%E8%BF%99%E5%87%A0%E7%AF%87%E5%8D%9A%E6%96%87%E5%90%A7%EF%BC%8C%E6%84%9F%E8%A7%89%E9%83%BD%E6%8C%BA%E5%A5%BD%E7%9A%84%EF%BC%9A"><span class="nav-number">6.3.</span> <span class="nav-text">看看这几篇博文吧，感觉都挺好的：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RAG%E4%B8%8EContext-Engineer%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">6.3.1.</span> <span class="nav-text">RAG与Context Engineer的关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E7%AF%87%E7%96%91%E4%BC%BC%E5%AF%B9%E2%80%9CRAG%E5%B7%B2%E6%AD%BB%E2%80%9D%E7%9A%84%E7%BF%BB%E8%AF%91%E7%9A%84%E5%8D%9A%E6%96%87%EF%BC%8C%E4%B8%8D%E8%BF%87%E8%AF%BB%E8%B5%B7%E6%9D%A5%E8%BF%98%E6%98%AF%E5%8F%AF%E4%BB%A5%E7%9A%84"><span class="nav-number">6.3.2.</span> <span class="nav-text">一篇疑似对“RAG已死”的翻译的博文，不过读起来还是可以的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E7%9A%84RAG%E5%B7%B2%E6%AD%BB%EF%BC%8C%E6%88%96%E8%80%85%E8%AF%B4%E6%98%AFRAG%E7%9A%84%E8%AE%A3%E5%91%8A"><span class="nav-number">6.3.3.</span> <span class="nav-text">经典的RAG已死，或者说是RAG的讣告</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E7%AF%87%E9%9D%9E%E5%B8%B8%E5%8A%A1%E5%AE%9E%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E5%85%B3%E4%BA%8ERAG%E4%B8%8Eagentic-RAG%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">6.3.4.</span> <span class="nav-text">一篇非常务实的回答，关于RAG与agentic RAG的优缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%99%E4%B8%AA%E6%98%AF%E5%85%B3%E4%BA%8Eagentic-RL%E7%9A%84%E6%95%B4%E7%90%86%E3%80%82%E6%84%9F%E8%A7%89%E5%AE%83%E5%8F%AF%E4%BB%A5%E6%8B%93%E5%AE%BD%E7%9C%BC%E7%95%8C%EF%BC%8C%E4%BB%8E%E8%80%8C%E8%83%BD%E6%9B%B4%E5%8A%A0%E4%BA%86%E8%A7%A3agentic-RAG%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%AE%83%E7%9A%84%E5%8F%AF%E8%83%BD%E7%9A%84%E7%94%A8%E9%80%94"><span class="nav-number">6.3.5.</span> <span class="nav-text">这个是关于agentic RL的整理。感觉它可以拓宽眼界，从而能更加了解agentic RAG的必要性，以及它的可能的用途</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%98%E6%9C%89%E4%B8%80%E4%B8%AA%E5%BE%88%E5%85%B3%E9%94%AE%E7%9A%84%E9%97%AE%E9%A2%98%E3%80%82%E4%B8%8A%E8%BF%B0%E5%85%B3%E4%BA%8ERAG%E5%B7%B2%E6%AD%BB%E7%9A%84%E8%A8%80%E8%AE%BA%EF%BC%8C%E4%BC%BC%E4%B9%8E%E9%83%BD%E6%98%AF%E9%BB%98%E8%AE%A4%E5%9C%A8%E6%96%87%E6%9C%AC%E6%A8%A1%E6%80%81%E4%B8%8B%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%90%A7%EF%BC%9F%E4%B8%80%E6%97%A6%E5%BC%95%E5%85%A5%E4%BA%86%E5%9B%BE%E5%83%8F%E3%80%81%E9%9F%B3%E9%A2%91%E3%80%81%E8%A7%86%E9%A2%91%E4%B9%8B%E7%B1%BB%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%EF%BC%8C%E9%99%A4%E4%BA%86%E7%BC%96%E7%A0%81%E6%88%90%E5%90%91%E9%87%8F%EF%BC%8C%E8%BF%98%E8%83%BD%E6%80%8E%E6%A0%B7%EF%BC%9F%E6%80%BB%E4%B8%8D%E8%83%BD%E5%83%8F%E6%96%87%E6%9C%AC%E9%82%A3%E6%A0%B7%E5%8F%AF%E4%BB%A5grep%E4%BA%86%E5%90%A7%EF%BC%9F%E5%A6%82%E6%9E%9C%E8%A6%81%E5%9C%A8%E8%BF%99%E6%96%B9%E9%9D%A2%E5%81%9A%E6%94%B9%E8%BF%9B%EF%BC%8C%E6%84%9F%E8%A7%89%E7%A1%AE%E5%AE%9E%E5%BE%97%E5%9C%A8%E6%A3%80%E7%B4%A2%E6%96%B9%E9%9D%A2%E4%B8%8B%E4%B8%80%E4%BA%9B%E5%8A%9F%E5%A4%AB%E4%BA%86%EF%BC%8C%E8%BF%99%E4%B8%AA%E5%B0%B1%E6%AF%94%E8%BE%83%E5%BA%95%E5%B1%82%EF%BC%8C%E5%BA%94%E8%AF%A5%E4%B9%9F%E6%AF%94%E8%BE%83%E9%9A%BE%E5%90%A7"><span class="nav-number">6.4.</span> <span class="nav-text">还有一个很关键的问题。上述关于RAG已死的言论，似乎都是默认在文本模态下工作的吧？一旦引入了图像、音频、视频之类的多模态，除了编码成向量，还能怎样？总不能像文本那样可以grep了吧？如果要在这方面做改进，感觉确实得在检索方面下一些功夫了，这个就比较底层，应该也比较难吧</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#agentic-RAG%EF%BC%8C%E5%AE%83%E7%9A%84%E4%B8%80%E5%A4%A7%E4%BC%98%E7%82%B9%EF%BC%8C%E5%B0%B1%E6%98%AF%E2%80%9C%E8%83%BD%E5%8A%A8%E6%80%A7%E2%80%9D%EF%BC%8C%E5%8F%AF%E4%BB%A5%E8%87%AA%E4%B8%BB%E5%9C%B0%E6%A0%B9%E6%8D%AE%E5%9C%BA%E5%90%88%E5%81%9A%E5%86%B3%E5%AE%9A%EF%BC%8C%E8%80%8C%E4%B8%8D%E9%9C%80%E8%A6%81%E4%BE%9D%E8%B5%96%E6%88%91%E4%BB%AC%E4%BA%8B%E5%85%88%E5%AE%9A%E4%B9%89%E5%A5%BD%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E3%80%82%E4%B9%9F%E5%B0%B1%E6%98%AF%EF%BC%8C%E5%9C%A8%E5%BD%93%E5%89%8D%E5%9C%BA%E5%90%88%E4%B8%8B%EF%BC%8C%E5%AE%83%E4%BC%9A%E8%87%AA%E5%8A%A8%E9%87%87%E5%8F%96%E4%B8%80%E4%B8%AA%E5%8A%A8%E4%BD%9C%E3%80%82%E4%BD%86%E8%BF%99%E4%B8%AA%E5%8A%A8%E4%BD%9C%E5%85%B7%E4%BD%93%E6%80%8E%E4%B9%88%E6%89%A7%E8%A1%8C%EF%BC%8C%E9%80%9A%E5%B8%B8%E8%BF%98%E6%98%AF%E4%BA%BA%E6%9D%A5%E8%A7%84%E5%AE%9A%E7%9A%84%E3%80%82%E8%BF%99%E4%B8%80%E7%82%B9%E5%A5%BD%E4%B8%8D%E5%A5%BD%EF%BC%9F%E9%95%BF%E8%BF%9C%E6%9D%A5%E8%AF%B4%E5%8F%AF%E8%83%BD%E4%B8%8D%E5%A5%BD%E5%90%A7%EF%BC%8C%E6%88%91%E4%BB%AC%E5%BD%93%E7%84%B6%E5%B8%8C%E6%9C%9Bagent%E8%83%BD%E5%AE%8C%E5%85%A8%E8%87%AA%E4%B8%BB%E3%80%82%E4%BD%86%E8%BF%99%E4%B8%AA%E8%BF%98%E6%98%AF%E6%9C%89%E7%82%B9%E8%BF%9C%E7%9A%84%E5%90%A7%EF%BC%9F%E8%87%B3%E5%B0%91%E7%8E%B0%E5%9C%A8%EF%BC%8C%E5%B0%B1%E8%BF%99%E4%B9%88%E4%BA%9B%E8%A7%84%E5%AE%9A%E5%A5%BD%E7%9A%84%E5%8A%A8%E4%BD%9C%EF%BC%8C%E8%AE%A9agent%E5%AD%A6%E4%BC%9A%E8%87%AA%E4%B8%BB%E9%80%89%E6%8B%A9%EF%BC%8C%E9%83%BD%E8%BF%98%E6%8C%BA%E9%9A%BE%E7%9A%84%EF%BC%8C%E8%B5%84%E6%BA%90%E5%BC%80%E9%94%80%E4%B9%9F%E4%B8%8D%E5%B0%8F%E4%BA%86%E3%80%82%E5%85%B3%E4%BA%8E%E5%8A%A8%E4%BD%9C%E5%86%85%E5%AE%B9%E7%9A%84%E8%87%AA%E4%B8%BB%E5%8C%96%EF%BC%8C%E5%8F%AF%E8%83%BD%E4%B9%9F%E6%98%AF%E4%B8%80%E4%B8%AA%E6%9C%AA%E6%9D%A5%E7%9A%84%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E5%90%A7"><span class="nav-number">6.5.</span> <span class="nav-text">agentic RAG，它的一大优点，就是“能动性”，可以自主地根据场合做决定，而不需要依赖我们事先定义好的工作流。也就是，在当前场合下，它会自动采取一个动作。但这个动作具体怎么执行，通常还是人来规定的。这一点好不好？长远来说可能不好吧，我们当然希望agent能完全自主。但这个还是有点远的吧？至少现在，就这么些规定好的动作，让agent学会自主选择，都还挺难的，资源开销也不小了。关于动作内容的自主化，可能也是一个未来的研究方向吧</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%88%91%E4%BB%AC%E5%A6%82%E6%9E%9C%E5%81%9Aagentic-mmgraphrag%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%90%97%EF%BC%9F%E5%AE%83%E7%9A%84%E7%A1%AE%E6%98%AF%E6%B2%A1%E4%BB%80%E4%B9%88%E4%BA%BA%E5%81%9A%EF%BC%8C%E4%BD%86%E6%98%AF%E4%BB%B7%E5%80%BC%E5%9C%A8%E5%93%AA%E5%91%A2%EF%BC%9F%E4%BB%A5%E5%8F%8A%E8%83%BD%E4%B8%8D%E8%83%BD%E5%92%8C%E7%8E%B0%E6%9C%89%E7%9A%84%E5%A4%A7%E5%8E%82%E5%81%9A%E5%87%BA%E6%9D%A5%E7%9A%84agent%E8%BF%9B%E8%A1%8C%E8%9E%8D%E5%85%A5%EF%BC%88%E5%B0%B1%E6%98%AF%E4%BD%9C%E4%B8%BA%E6%8F%92%E4%BB%B6%E5%8A%A0%E5%85%A5%E5%88%B0%E5%AE%83%E4%BB%AC%E9%82%A3%E8%BE%B9%EF%BC%89%EF%BC%9F%E5%A6%82%E6%9E%9C%E4%B8%8D%E8%A1%8C%EF%BC%8C%E9%82%A3%E6%88%91%E4%BB%AC%E6%98%AF%E5%90%A6%E9%9C%80%E8%A6%81%E6%8D%A2%E4%B8%80%E4%B8%AA%E5%85%B3%E6%B3%A8%E7%82%B9%EF%BC%8C%E6%AF%94%E5%A6%82%E5%AE%83%E4%BB%AC%E7%9A%84agent%E5%BC%80%E9%94%80%E6%AF%94%E8%BE%83%E5%A4%A7%EF%BC%88%E6%A8%A1%E5%9E%8B%E5%A4%A7-api%E8%B0%83%E7%94%A8%E8%8A%B1%E8%B4%B9%E5%A4%9A%EF%BC%89%EF%BC%8C%E8%80%8C%E6%88%91%E4%BB%AC%E5%B0%B1%E4%B8%93%E6%B3%A8%E5%9C%A8%E5%B0%8F%E6%A8%A1%E5%9E%8B%E4%B8%8A%EF%BC%8C%E8%BF%99%E6%A0%B7%E5%AF%B9%E6%AF%94%E4%B9%9F%E5%8F%AA%E9%9C%80%E8%A6%81%E8%B7%9F%E5%B0%8F%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94%EF%BC%8C%E8%80%8C%E4%B8%94%E8%AE%AD%E7%BB%83%E4%B9%9F%E5%8F%AA%E9%9C%80%E8%A6%81%E8%AE%AD%E7%BB%83%E5%B0%8F%E6%A8%A1%E5%9E%8B%EF%BC%8C%E6%88%96%E8%AE%B8%E4%BC%9A%E5%A5%BD%E4%B8%80%E4%BA%9B"><span class="nav-number">7.</span> <span class="nav-text">我们如果做agentic mmgraphrag，可以吗？它的确是没什么人做，但是价值在哪呢？以及能不能和现有的大厂做出来的agent进行融入（就是作为插件加入到它们那边）？如果不行，那我们是否需要换一个关注点，比如它们的agent开销比较大（模型大&#x2F;api调用花费多），而我们就专注在小模型上，这样对比也只需要跟小模型的方法对比，而且训练也只需要训练小模型，或许会好一些</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RAG%E9%87%8C%E7%A1%AE%E5%AE%9E%E5%9F%BA%E6%9C%AC%E5%81%87%E8%AE%BE%E6%98%AF%E9%9D%99%E6%80%81%E7%9A%84%E7%9F%A5%E8%AF%86%E5%BA%93%E3%80%82%E9%81%87%E5%88%B0%E6%96%B0%E7%9A%84%E7%9F%A5%E8%AF%86%E6%9D%A5%E4%BA%86%E5%91%A2"><span class="nav-number">8.</span> <span class="nav-text">RAG里确实基本假设是静态的知识库。遇到新的知识来了呢</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8D%E6%96%AD%E6%9C%89%E6%96%B0%E7%9F%A5%E8%AF%86%E5%87%BA%E7%8E%B0%EF%BC%8C%E8%BF%99%E5%B9%B6%E4%B8%8D%E6%98%AF%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E7%94%B1%E4%B8%8A%E7%BD%91%E6%A3%80%E7%B4%A2%E5%B0%B1%E8%83%BD%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%8C%E5%9B%A0%E4%B8%BA%E6%96%B0%E7%9F%A5%E8%AF%86%E5%87%BA%E7%8E%B0%E7%9A%84%E5%9C%B0%E6%96%B9%E4%B9%9F%E4%B8%8D%E6%AD%A2%E6%98%AF%E7%BD%91%E4%B8%8A%E3%80%82%E5%BE%88%E5%A4%9A%E4%BC%81%E4%B8%9A%E5%BA%94%E8%AF%A5%E9%83%BD%E4%BC%9A%E6%9C%89%E5%A4%A7%E9%87%8F%E7%9A%84%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%EF%BC%8C%E8%BF%99%E4%BA%9B%E6%95%B0%E6%8D%AE%E6%98%BE%E7%84%B6%E4%B8%8D%E5%8F%AF%E8%83%BD%E5%85%AC%E5%BC%80%EF%BC%8C%E6%89%80%E4%BB%A5%E4%BC%9A%E6%9C%89%E7%A7%81%E6%9C%89%E5%A2%9E%E9%87%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E6%83%85%E5%86%B5%E3%80%82%E6%AD%A4%E6%97%B6%EF%BC%8C%E5%B0%B1%E9%9C%80%E8%A6%81%E6%9B%B4%E6%96%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E4%BA%86"><span class="nav-number">8.1.</span> <span class="nav-text">不断有新知识出现，这并不是一个可以直接由上网检索就能解决的问题，因为新知识出现的地方也不止是网上。很多企业应该都会有大量的业务数据，这些数据显然不可能公开，所以会有私有增量数据的情况。此时，就需要更新知识库了</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%B4%E6%96%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E7%9A%84%E6%97%B6%E5%80%99%E4%B9%9F%E4%BC%9A%E6%9C%89%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%EF%BC%8C%E6%AF%94%E5%A6%82%EF%BC%8C%E6%96%B0%E6%97%A7%E7%9F%A5%E8%AF%86%E4%B9%8B%E9%97%B4%E7%9A%84%E8%9E%8D%E5%90%88%EF%BC%9F%E5%90%88%E5%B9%B6%EF%BC%9F%E6%88%96%E8%80%85%E5%A6%82%E6%9E%9C%E5%AE%83%E4%BB%AC%E5%87%BA%E7%8E%B0%E4%BA%86%E5%86%B2%E7%AA%81%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E5%8F%88%E6%88%96%E8%80%85%E6%9C%89%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E9%9C%80%E8%A6%81%E8%B7%A8%E5%BA%A6%E6%AF%94%E8%BE%83%E5%A4%A7%E7%9A%84%E6%96%B0%E6%97%A7%E7%9F%A5%E8%AF%86%EF%BC%8C%E4%B8%80%E8%B5%B7%E6%9D%A5%E5%88%86%E6%9E%90%EF%BC%8C%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E6%97%A7%E7%9A%84%E7%9F%A5%E8%AF%86%E5%A5%BD%E5%83%8F%E4%B8%8D%E5%BA%94%E8%AF%A5%E4%B8%80%E5%91%B3%E5%9C%B0%E4%B8%A2%E5%BC%83%E5%90%A7%EF%BC%9F%EF%BC%88%E5%83%8F%E4%B9%8B%E5%89%8D%E8%AF%BB%E5%88%B0%E8%BF%87%E7%9A%84VersionRAG%EF%BC%8C%E5%85%B6%E5%AE%9E%E5%B0%B1%E6%98%AF%E5%85%B3%E6%B3%A8%E4%BA%86%E4%B8%80%E4%B8%AA%E7%9B%B8%E5%BD%93%E5%B0%8F%E7%9A%84%E6%96%B9%E9%9D%A2%E3%80%82%E4%B8%80%E4%B8%AA%E5%A5%BD%E4%B8%80%E7%82%B9%E7%9A%84%E5%B7%A5%E4%BD%9C%EF%BC%8C%E5%BA%94%E8%AF%A5%E8%83%BD%E5%AE%8C%E5%85%A8%E5%9B%8A%E6%8B%AC%E5%AE%83%E5%90%A7%EF%BC%89"><span class="nav-number">8.1.1.</span> <span class="nav-text">更新知识库的时候也会有一些问题，比如，新旧知识之间的融合？合并？或者如果它们出现了冲突怎么办？又或者有一些问题需要跨度比较大的新旧知识，一起来分析，怎么办？旧的知识好像不应该一味地丢弃吧？（像之前读到过的VersionRAG，其实就是关注了一个相当小的方面。一个好一点的工作，应该能完全囊括它吧）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E5%AE%9E%EF%BC%8CRAG%E7%9A%84%E4%B8%80%E4%B8%AA%E9%87%8D%E8%A6%81%E5%BA%94%E7%94%A8%E9%A2%86%E5%9F%9F%E5%B0%B1%E6%98%AF%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8A%E7%9A%84%E6%A3%80%E7%B4%A2%E3%80%82%E5%8D%B3%E4%BD%BFllm%E7%BB%A7%E7%BB%AD%E5%8F%91%E5%B1%95%EF%BC%8C%E5%AE%83%E8%B0%83%E7%94%A8%E7%BD%91%E7%BB%9C%E6%A3%80%E7%B4%A2%E5%B7%A5%E5%85%B7%E7%9A%84%E8%83%BD%E5%8A%9B%E6%9B%B4%E5%8A%A0%E6%8F%90%E9%AB%98%E4%BA%86%EF%BC%8C%E5%AF%B9%E4%BA%8E%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%B2%A1%E6%9C%89%E8%8E%B7%E5%8F%96%E6%9D%83%E9%99%90%E4%B9%9F%E6%B2%A1%E5%8A%9E%E6%B3%95%E3%80%82%E5%8F%AA%E6%9C%89%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE%E7%9A%84%E6%8B%A5%E6%9C%89%E8%80%85%E5%8F%AF%E4%BB%A5%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%B9%B6%E6%9E%84%E5%BB%BARAG%E8%BF%9B%E8%A1%8C%E6%A3%80%E7%B4%A2%EF%BC%88%E6%88%96%E8%80%85%E8%AF%B4%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B9%9F%E4%B8%8D%E9%9C%80%E8%A6%81%E4%B8%80%E7%9B%B4%E5%BC%BA%E8%B0%83RAG%E3%80%82%E4%BD%86%E6%98%AF%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE%E7%9A%84%E7%A1%AE%E9%9C%80%E8%A6%81%E8%A2%AB%E6%A3%80%E7%B4%A2%EF%BC%8C%E8%BF%99%E7%82%B9%E6%98%AF%E7%9C%9F%E7%9A%84%EF%BC%89%EF%BC%88%E4%B8%8D%E8%BF%87%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%98%AF%E8%BF%99%E6%A0%B7%EF%BC%8C%E9%82%A3%E5%85%B6%E5%AE%9E%E5%8F%8D%E6%AD%A3%E6%98%AF%E8%A6%81%E9%83%A8%E7%BD%B2%E5%9C%A8%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE%E4%B8%8A%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E7%94%A8agentic-rag%E5%91%A2%EF%BC%9F%E8%BF%99%E9%87%8C%E5%8F%AF%E8%83%BD%E5%B0%B1%E4%BC%9A%E6%B6%89%E5%8F%8A%E5%88%B0rag-routing%E4%BA%86%EF%BC%9F%EF%BC%89%EF%BC%88%E8%BF%99%E6%A0%B7%E4%B8%80%E6%83%B3%EF%BC%8C%E5%80%92%E6%98%AF%E6%98%8E%E7%A1%AE%E4%BA%86%EF%BC%8Cagentic-rag%E7%9A%84efficiency%E8%82%AF%E5%AE%9A%E4%B9%9F%E6%98%AF%E4%B8%80%E4%B8%AA%E5%80%BC%E5%BE%97%E7%A0%94%E7%A9%B6%E7%9A%84%E4%B8%9C%E8%A5%BF%EF%BC%89"><span class="nav-number">8.2.</span> <span class="nav-text">其实，RAG的一个重要应用领域就是私有数据库上的检索。即使llm继续发展，它调用网络检索工具的能力更加提高了，对于私有数据，没有获取权限也没办法。只有私有数据的拥有者可以部署模型，并构建RAG进行检索（或者说，我们也不需要一直强调RAG。但是私有数据的确需要被检索，这点是真的）（不过，如果是这样，那其实反正是要部署在私有数据上，为什么不用agentic rag呢？这里可能就会涉及到rag routing了？）（这样一想，倒是明确了，agentic rag的efficiency肯定也是一个值得研究的东西）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%93%A6%E5%AF%B9%EF%BC%8C%E8%80%8C%E4%B8%94%E4%B9%8B%E6%89%80%E4%BB%A5%E8%AF%B4%E5%9C%A8%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8A%E8%A6%81%E8%BF%9B%E8%A1%8C%E6%A3%80%E7%B4%A2%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B%E5%96%82%E7%BB%99%E6%A8%A1%E5%9E%8B%E7%9F%A5%E8%AF%86%EF%BC%8C%E4%B9%9F%E6%98%AF%E5%9B%A0%E4%B8%BA%E5%BE%AE%E8%B0%83%E5%BE%88%E9%BA%BB%E7%83%A6%EF%BC%8C%E8%B5%84%E6%BA%90%E9%9C%80%E6%B1%82%E5%A4%A7%E5%90%A7%EF%BC%8C%E8%BF%98%E5%8F%AF%E8%83%BD%E6%9C%89%E9%81%97%E5%BF%98%E5%85%B6%E5%AE%83%E7%9F%A5%E8%AF%86%E7%9A%84%E9%A3%8E%E9%99%A9%E3%80%82RAG%E5%B0%B1%E6%98%AF%E4%B8%80%E7%A7%8D%E5%85%8D%E8%AE%AD%E7%BB%83%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88In-Context-Learning%E5%9B%BA%E7%84%B6%E4%B9%9F%E6%98%AF%E4%B8%80%E7%A7%8D%E6%96%B9%E6%B3%95%EF%BC%8C%E4%BD%86%E6%98%AF%E7%9B%B4%E8%A7%82%E4%B8%8A%EF%BC%8C%E5%AE%83%E5%8F%AA%E8%83%BD%E5%9C%A8%E4%B8%80%E4%BA%9B%E7%9B%B8%E5%AF%B9%E7%AE%80%E5%8D%95%E7%9A%84%E4%BB%BB%E5%8A%A1%E4%B8%8A%EF%BC%8C%E9%80%9A%E8%BF%87%E6%8F%90%E4%BE%9B%E4%B8%80%E4%BA%9B%E4%BE%8B%E5%AD%90%E5%B8%AE%E5%8A%A9llm%E7%90%86%E8%A7%A3%E3%80%82%E8%80%8C%E4%B8%94%E4%B8%8D%E6%98%AF%E6%9C%89%E7%A0%94%E7%A9%B6%E8%AF%B4%EF%BC%8Cicl%E7%9A%84%E8%AF%9D%EF%BC%8C%E6%8F%90%E4%BE%9B%E8%BF%87%E5%A4%9A%E7%9A%84%E4%BE%8B%E5%AD%90%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%85%B6%E5%AE%9E%E6%B2%A1%E5%A4%AA%E5%A4%9A%E6%8F%90%E5%8D%87%E5%90%97%EF%BC%89"><span class="nav-number">8.3.</span> <span class="nav-text">哦对，而且之所以说在私有数据库上要进行检索，而不是微调模型喂给模型知识，也是因为微调很麻烦，资源需求大吧，还可能有遗忘其它知识的风险。RAG就是一种免训练的方法（In-Context Learning固然也是一种方法，但是直观上，它只能在一些相对简单的任务上，通过提供一些例子帮助llm理解。而且不是有研究说，icl的话，提供过多的例子的时候，其实没太多提升吗）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%9D%E8%AF%B4%EF%BC%8Crag%E7%9A%84%E6%8F%90%E5%87%BA%E5%8A%A8%E6%9C%BA%E4%B9%8B%E4%B8%80%EF%BC%8C%E6%98%AF%E4%BD%9C%E4%B8%BAllm%E7%9A%84%E5%A4%96%E6%8C%82%E8%AE%B0%E5%BF%86%E3%80%82%E8%BF%99%E5%B0%B1%E6%B6%89%E5%8F%8A%E5%88%B0%E9%95%BF%E6%9C%9F%E8%AE%B0%E5%BF%86%E8%BF%99%E4%B8%AA%E4%B8%9C%E8%A5%BF%E4%BA%86%E3%80%82%E6%9C%80%E8%BF%91%E7%A0%94%E7%A9%B6%E5%BE%97%E6%9C%89%E7%82%B9%E5%A4%9A%E3%80%82%E6%88%96%E8%AE%B8%E5%8F%AF%E4%BB%A5%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8B%E6%9C%80%E8%BF%91%E7%9C%8B%E5%88%B0%E7%9A%84memory%E6%96%B9%E9%9D%A2%E7%9A%84paper%EF%BC%8C%E7%9C%8B%E7%9C%8B%E5%AE%83%E4%BB%AC%E5%88%B0%E5%BA%95%E7%9B%B8%E6%AF%94%E4%BA%8Erag%E6%9C%89%E4%BB%80%E4%B9%88%E6%94%B9%E5%8F%98%EF%BC%8C%E4%B8%BA%E4%BD%95%E6%80%A5%E4%B8%8D%E5%8F%AF%E8%80%90%E5%9C%B0%E6%8A%A8%E5%87%BB%E5%92%8C%E6%8A%9B%E5%BC%83rag"><span class="nav-number">9.</span> <span class="nav-text">话说，rag的提出动机之一，是作为llm的外挂记忆。这就涉及到长期记忆这个东西了。最近研究得有点多。或许可以总结一下最近看到的memory方面的paper，看看它们到底相比于rag有什么改变，为何急不可耐地抨击和抛弃rag</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">bluemouse</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">256</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">83</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">104</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bluemouse</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
