{
	"nodes":[
		{"id":"585d8e3de99ea7ca","type":"text","text":"general challenge-insight tree","x":-120,"y":-40,"width":340,"height":60},
		{"id":"ccabbf0395b3b12a","type":"text","text":"insight：直接利用llm的zero-shot的能力进行评估","x":740,"y":40,"width":250,"height":90},
		{"id":"7db2bb009ed68003","type":"text","text":"例如，考虑利用llm的能力。我们当然可以直接把这个属性给出几个等级，然后让llm直接给出它的判断","x":1120,"y":85,"width":320,"height":95},
		{"id":"4b984bd4c9b2b7c4","type":"text","text":"insight：利用llm的内部表征进行一些定量计算","x":740,"y":180,"width":250,"height":90},
		{"id":"448215cf1b749751","type":"text","text":"（其实有点像启发式方法，因为指标怎么计算还是我们来定。只不过输入是llm的内部表征）\n举个例子，我们要衡量相关性分数，那么，我们可以设计一套prompt，让llm判断是否相关并输出yes/no。此时我们可以得到二者的输出概率。由此就可以进行各种的设计（例如，二者的比值，就表征了相关性的大小。比值越大，可以认为相关性越大）（这个方法其实挺常见的。而且emnlp 23有paper可以说专门就是做这个的，Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback）","x":1120,"y":225,"width":320,"height":245},
		{"id":"cb72e0fce873857f","type":"text","text":"cha：需要对某个属性进行定量化描述","x":340,"y":73,"width":293,"height":60},
		{"id":"90a1c301f3cd27a9","type":"text","text":"insight：生成并改进graph embedding","x":740,"y":640,"width":250,"height":56},
		{"id":"d1c333d290e8bbcf","type":"text","text":"graph embedding毕竟是整体性的信息，应该会包含一些结构上的信息","x":1120,"y":640,"width":320,"height":108},
		{"id":"6bccffeff9c87556","type":"text","text":"insight：显式提取结构信息并拿去编码","x":740,"y":766,"width":250,"height":60},
		{"id":"5b50111606b0d51c","type":"text","text":"考虑把结构上相关的东西一起拿给模型，让它进行编码（比如我们要追求局部结构信息的获取，把一个anchor node和它周围的1-hop邻居都拿给模型进行编码；\n又比如，在KG里，我们把一个三元组（head-relation-tail）拿给模型编码。如果是要全局信息，那譬如考虑，把一条路径上的所有节点和边都拿给模型）\n（这其实也是一个非常粗浅的idea。本质上结构的体现就是在输入上，至于特征如何提取，则还是全权交给模型自己学了。没有一个任务/指标是来明确衡量学到了多少结构信息的）","x":1120,"y":796,"width":320,"height":292},
		{"id":"d025c133faecdb60","type":"text","text":"cha：graph相关的任务里，缺少对结构信息的感知","x":340,"y":666,"width":313,"height":60},
		{"id":"4f3238c3597fb1b2","type":"text","text":"缺点：肯定不够细粒度，graph embedding一般还是更多针对整体的语义信息（除非提取graph embedding的模型有经过结构方面的预训练）","x":1520,"y":654,"width":320,"height":84},
		{"id":"b8fd4149c7041aa5","type":"text","text":"insight：加入特定token并进行微调","x":740,"y":470,"width":250,"height":60},
		{"id":"f3a42fe508210f79","type":"text","text":"这有点像是上面那个方法的升级版。上面我们还是靠prompt engineering来获得特定输出的概率。如果我们把这个特定的输出，用特定的新token表示，并在训练数据中加以应用，然后微调llm，让它掌握这些新token的含义，并知道用这些token进行隐形的评估，我们就能根据这些token的输出概率得到置信度了（这个方法也有论文做过了，ICML 25的，Learning to Route LLMs with Confidence Tokens）","x":1120,"y":500,"width":320,"height":100},
		{"id":"c1af485da37092c2","type":"text","text":"吐槽：这类用llm内部表征进行计算的真不少。而用llm的输出概率计算置信度的，更是多……一窝蜂地水","x":372,"y":293,"width":250,"height":110},
		{"id":"999995acf11fccbf","type":"text","text":"本质是通过offline的计算，实现复用，进而减少时间开销","x":1520,"y":1250,"width":320,"height":80},
		{"id":"d14c80be5fe14b5a","type":"text","text":"输入多，计算时间就多。这几乎是必定成立的事情。关键在于怎么减少输入","x":1513,"y":1410,"width":327,"height":78},
		{"id":"e6a7188fffa58095","type":"text","text":"例如llm推理中的kv cache技术，就是一种复用","x":1900,"y":1253,"width":320,"height":74},
		{"id":"49a35e14060a9f86","type":"text","text":"挑重要的输入。rag其实就是一种代表性技术。本质上，我们正是因为无法将各种各样的资料库一次拿给模型，所以才用rag这个技术，检索重要的部分给模型","x":1900,"y":1360,"width":320,"height":100},
		{"id":"94c30dc1d610f108","type":"text","text":"压缩上下文","x":1900,"y":1530,"width":320,"height":60},
		{"id":"359ca60970e5bb56","type":"text","text":"以rag场景下的文档压缩为例。方法就考虑以MHA-RAG的方法为例。它是把输入的N个sample（也就是检索到的N个文档）分别输入到k个注意力头上（每个头的输出都是一个向量，从而起到压缩的作用）。每个注意力头都是用全注意力，因此输出不受顺序影响。此时每个注意力头的输出就不受输入顺序影响。最终再把每个注意力头的输出按顺序concat，则最终输出也不受输入顺序影响（最后的输出是k个向量，相比于原本的N个文档的自然文本的展开，是有所压缩的）","x":2291,"y":1628,"width":329,"height":102},
		{"id":"7138c69a9aab4721","type":"text","text":"相应的，当offline算好的东西越来越多的时候，存储就成了一个问题。此时就可能需要精简这些cache（compression/eviction……）","x":2300,"y":1240,"width":320,"height":100},
		{"id":"454bfbddbfcc9e60","type":"text","text":"通常需要权衡压缩率和质量","x":2300,"y":1440,"width":320,"height":50},
		{"id":"cdc78b173ec7ecf7","type":"text","text":"压缩之余，可能还需要考虑上下文的顺序（顺序或许会影响性能）","x":2300,"y":1530,"width":320,"height":60},
		{"id":"fde701da24d6d87f","type":"text","text":"insight：有没有重复性的内容？能不能进行复用？","x":1120,"y":1250,"width":320,"height":80},
		{"id":"b9c1297bc113eb4e","type":"text","text":"insight：输入是否过多了？能不能减少？","x":1120,"y":1410,"width":320,"height":80},
		{"id":"6a651202c8c50f3a","type":"text","text":"首要的一点是，发现目前系统里哪一步可能导致了“慢”。虽然要具体问题具体分析，但也有一些通用的/常见的切入角度","x":740,"y":1410,"width":250,"height":60},
		{"id":"f808989dce3bf4a0","type":"text","text":"cha：需要提高效率（包括但不限于时间上的，算力上的……）","x":340,"y":1388,"width":293,"height":100},
		{"id":"e0691f97358988da","type":"text","text":"缺点：很依赖llm的性能，这样一般要求用大的模型。但如果本地部署，多次调用llm就慢；调api，多次调用llm就开销大、花钱多","x":1580,"y":92,"width":320,"height":76},
		{"id":"a674611508efcd0f","type":"text","text":"延伸：当我们把某个属性给离散化成了几个等级之后，也可以考虑进一步的，给每个等级都学一个embedding。这是工程上处理类别特征的一种常用trick","x":2000,"y":-21,"width":288,"height":123},
		{"id":"85c0d134647151c5","x":2291,"y":1840,"width":385,"height":159,"type":"text","text":"压缩上下文是类似于把每个表征的精度压缩一下，但是表征的数量不变。而剪枝，就是每个表征的精度不变，但我们只保留那些重要的表征，剔除掉一些不那么重要的表征"},
		{"id":"a396eba41fcff354","x":1900,"y":1890,"width":250,"height":60,"type":"text","text":"剪枝"},
		{"id":"5489e0d8a0eaf66b","type":"text","text":"streaming设置（streaming是一个极为常用的技术，不限领域。它的本质可以认为是，仅保留最重要的信息，同时动态进行信息的更新，从而尽可能提高效果；但因为限定了窗口大小，所以保证了开销不会过大）","x":1131,"y":-1540,"width":320,"height":260},
		{"id":"626f4e552641916a","type":"text","text":"缺点：或许少了一些全局性的信息？","x":1511,"y":-1442,"width":320,"height":65},
		{"id":"1f9d5eb00c49418c","type":"text","text":"这个技术，常见于我们有两个（更多也行吧）变量需要优化。比较好的方法可能是我们同时优化二者（尤其是当二者需要协同工作的时候，显然一起优化会比较对齐）\n但如果一起优化开销会比较大，我们或许可以考虑，固定一个，优化一个，然后反过来；如此迭代交替上若干轮次，最后的效果也未必会差了","x":1131,"y":-1195,"width":320,"height":255},
		{"id":"28e300827995637d","type":"text","text":"但肉眼可见，这个是对性能的妥协。当性能充足的时候，一般还是考虑每个step/epoch都要更新的（不过如果对特定的模型有需要，比如对辅助的模型，我们希望它能尽量“缓慢”更新，在局部看来是“不动”的，那这个trick其实是很合适的（Moco里就有）","x":1511,"y":-868,"width":320,"height":100},
		{"id":"cd88eb9fa4b725e0","type":"text","text":"比如，隔几个step/epoch再进行更新，而不是每一个step/epoch都更新","x":1133,"y":-860,"width":318,"height":92},
		{"id":"c4452d28701e45a5","type":"text","text":"比如，当我们想优化llm和它的对应prompt的时候，最好的情况当然是llm和prompt一起微调。但显然llm的微调开销是很大的。所以可以考虑，采用迭代交替式优化（先固定llm，优化prompt几轮；之后用这个优化后的prompt，固定，并拿去优化llm……）","x":1551,"y":-1111,"width":320,"height":93},
		{"id":"3d2e407ba6d73f98","type":"text","text":"insight：streaming技术","x":751,"y":-1385,"width":250,"height":60},
		{"id":"d3ca8f2ccd70ec67","type":"text","text":"insight：迭代交替式优化","x":751,"y":-1100,"width":250,"height":60},
		{"id":"41018fdf4b4ec353","type":"text","text":"cha：时间和效率需要权衡","x":351,"y":-1068,"width":293,"height":50},
		{"id":"e8fb915b6c557930","type":"text","text":"insight：lazy update","x":751,"y":-868,"width":250,"height":60},
		{"id":"87a1069f6d9f3c89","type":"text","text":"缺点：效果可能不够好（平均未必反应真实情况，自适应权重需要想办法求出尽量准确的权重）","x":1500,"y":-637,"width":320,"height":105},
		{"id":"5e994151735173d0","type":"text","text":"本质是加权求和。且一般权重是一样的。权重一样的话，代表着每个方案的贡献值是一样的，这其实是一个假设，且未必在现实里成立","x":1120,"y":-630,"width":320,"height":90},
		{"id":"abe55c0d39382fbb","type":"text","text":"让每个solution轮流成为一次anchor，其余的solution成为reference，用于优化anchor，那么也可以起到整合和优化的作用。更重要的是可以在整合的同时，保留多样性","x":1120,"y":-508,"width":320,"height":208},
		{"id":"2b810838b380d871","type":"text","text":"insight：anchor-reference机制","x":740,"y":-480,"width":250,"height":60},
		{"id":"82f0b5d359a3286e","type":"text","text":"缺点：计算量上是比较大的，尤其是当solution比较多的时候","x":1500,"y":-451,"width":320,"height":94},
		{"id":"f2f5ae852623d3dc","type":"text","text":"cha：多个solution需要进行整合和取舍","x":340,"y":-540,"width":293,"height":60},
		{"id":"bcff64e61b82d65f","type":"text","text":"insight：voting（最朴素、最容易想到的）","x":740,"y":-660,"width":250,"height":60},
		{"id":"cef0e8c99186aab7","x":1120,"y":-243,"width":320,"height":103,"type":"text","text":"这个方法其实通常是根据候选者的若干个属性/特征/评估结果来衡量重要性。一个候选者，如果它处在pareto optimal上，我们可以认为它在某种程度上是好的，因而可以考虑保留（这个技术可能用在剪枝上会更自然一点。毕竟本来就是从一篇剪枝的论文上看到的）（所谓pareto最优，可以直观理解为，没有一个其它候选者是能在全方面胜过它的。类似于，比我高的没我壮，比我壮的没我高这样）"},
		{"id":"a83745b02a5ce3f4","x":720,"y":-221,"width":250,"height":60,"type":"text","text":"insight：pareto selection"}
	],
	"edges":[
		{"id":"16a8b692f5a607d3","fromNode":"585d8e3de99ea7ca","fromSide":"right","toNode":"41018fdf4b4ec353","toSide":"left"},
		{"id":"730c6b7186bb83a8","fromNode":"41018fdf4b4ec353","fromSide":"right","toNode":"3d2e407ba6d73f98","toSide":"left"},
		{"id":"5c71fd88ddba816d","fromNode":"3d2e407ba6d73f98","fromSide":"right","toNode":"5489e0d8a0eaf66b","toSide":"left"},
		{"id":"1be2743a56abd5cb","fromNode":"f2f5ae852623d3dc","fromSide":"right","toNode":"bcff64e61b82d65f","toSide":"left"},
		{"id":"8a6502fb6261c294","fromNode":"f2f5ae852623d3dc","fromSide":"right","toNode":"2b810838b380d871","toSide":"left"},
		{"id":"5bb2f589693da5c7","fromNode":"2b810838b380d871","fromSide":"right","toNode":"abe55c0d39382fbb","toSide":"left"},
		{"id":"db90420c1a819a37","fromNode":"585d8e3de99ea7ca","fromSide":"right","toNode":"f2f5ae852623d3dc","toSide":"left"},
		{"id":"24ad9bb8ecc73c5b","fromNode":"585d8e3de99ea7ca","fromSide":"right","toNode":"cb72e0fce873857f","toSide":"left"},
		{"id":"e68589b25d3a22ef","fromNode":"cb72e0fce873857f","fromSide":"right","toNode":"ccabbf0395b3b12a","toSide":"left"},
		{"id":"f2c909aaeecda8d0","fromNode":"cb72e0fce873857f","fromSide":"right","toNode":"4b984bd4c9b2b7c4","toSide":"left"},
		{"id":"6a9df85df888123c","fromNode":"4b984bd4c9b2b7c4","fromSide":"right","toNode":"448215cf1b749751","toSide":"left"},
		{"id":"532ecab5b248c0e3","fromNode":"ccabbf0395b3b12a","fromSide":"right","toNode":"7db2bb009ed68003","toSide":"left"},
		{"id":"a6409ed74896726e","fromNode":"d025c133faecdb60","fromSide":"right","toNode":"90a1c301f3cd27a9","toSide":"left"},
		{"id":"484961cedb10fee7","fromNode":"90a1c301f3cd27a9","fromSide":"right","toNode":"d1c333d290e8bbcf","toSide":"left"},
		{"id":"92dc8d2a4861c52d","fromNode":"585d8e3de99ea7ca","fromSide":"right","toNode":"d025c133faecdb60","toSide":"left"},
		{"id":"4ce0ed87d6c37157","fromNode":"d025c133faecdb60","fromSide":"right","toNode":"6bccffeff9c87556","toSide":"left"},
		{"id":"a78e6d2c3a0a3e75","fromNode":"6bccffeff9c87556","fromSide":"right","toNode":"5b50111606b0d51c","toSide":"left"},
		{"id":"f98672fb4b250dcc","fromNode":"abe55c0d39382fbb","fromSide":"right","toNode":"82f0b5d359a3286e","toSide":"left"},
		{"id":"fd717833109b4c46","fromNode":"5e994151735173d0","fromSide":"right","toNode":"87a1069f6d9f3c89","toSide":"left"},
		{"id":"03b2cfbd4e06d967","fromNode":"d1c333d290e8bbcf","fromSide":"right","toNode":"4f3238c3597fb1b2","toSide":"left"},
		{"id":"648ac316c8de898a","fromNode":"7db2bb009ed68003","fromSide":"right","toNode":"e0691f97358988da","toSide":"left"},
		{"id":"c32f17c76f8c1827","fromNode":"5489e0d8a0eaf66b","fromSide":"right","toNode":"626f4e552641916a","toSide":"left"},
		{"id":"70d2048d7f4a12ca","fromNode":"fde701da24d6d87f","fromSide":"right","toNode":"999995acf11fccbf","toSide":"left"},
		{"id":"d2d71622eae5fb5d","fromNode":"999995acf11fccbf","fromSide":"right","toNode":"e6a7188fffa58095","toSide":"left"},
		{"id":"151dcd0a89eb82f4","fromNode":"e6a7188fffa58095","fromSide":"right","toNode":"7138c69a9aab4721","toSide":"left"},
		{"id":"c5234a9aa61da2d7","fromNode":"6a651202c8c50f3a","fromSide":"right","toNode":"fde701da24d6d87f","toSide":"left"},
		{"id":"4c1c14a9aa6f55bc","fromNode":"f808989dce3bf4a0","fromSide":"right","toNode":"6a651202c8c50f3a","toSide":"left"},
		{"id":"c3cb39b7342c0513","fromNode":"d14c80be5fe14b5a","fromSide":"right","toNode":"49a35e14060a9f86","toSide":"left"},
		{"id":"35a360b9dd290b4e","fromNode":"d14c80be5fe14b5a","fromSide":"right","toNode":"94c30dc1d610f108","toSide":"left"},
		{"id":"b60b30e9f68302c3","fromNode":"94c30dc1d610f108","fromSide":"right","toNode":"454bfbddbfcc9e60","toSide":"left"},
		{"id":"b3b9ddf7d3051af4","fromNode":"94c30dc1d610f108","fromSide":"right","toNode":"cdc78b173ec7ecf7","toSide":"left"},
		{"id":"a3aaf6db8a233153","fromNode":"94c30dc1d610f108","fromSide":"right","toNode":"359ca60970e5bb56","toSide":"left"},
		{"id":"3ed4202e5062fe09","fromNode":"b9c1297bc113eb4e","fromSide":"right","toNode":"d14c80be5fe14b5a","toSide":"left"},
		{"id":"6146deda169b4841","fromNode":"6a651202c8c50f3a","fromSide":"right","toNode":"b9c1297bc113eb4e","toSide":"left"},
		{"id":"26a71520206d6dba","fromNode":"585d8e3de99ea7ca","fromSide":"right","toNode":"f808989dce3bf4a0","toSide":"left"},
		{"id":"248b3463a8f24de8","fromNode":"41018fdf4b4ec353","fromSide":"right","toNode":"d3ca8f2ccd70ec67","toSide":"left"},
		{"id":"4bc24099834ee928","fromNode":"d3ca8f2ccd70ec67","fromSide":"right","toNode":"1f9d5eb00c49418c","toSide":"left"},
		{"id":"6d98f8ec3631588f","fromNode":"1f9d5eb00c49418c","fromSide":"right","toNode":"c4452d28701e45a5","toSide":"left"},
		{"id":"7d72b446dcd3f3ed","fromNode":"e8fb915b6c557930","fromSide":"right","toNode":"cd88eb9fa4b725e0","toSide":"left"},
		{"id":"e98daad6ec571438","fromNode":"41018fdf4b4ec353","fromSide":"right","toNode":"e8fb915b6c557930","toSide":"left"},
		{"id":"f9283d783b9feb85","fromNode":"cd88eb9fa4b725e0","fromSide":"right","toNode":"28e300827995637d","toSide":"left"},
		{"id":"a73368365e7b6ff3","fromNode":"cb72e0fce873857f","fromSide":"right","toNode":"b8fd4149c7041aa5","toSide":"left"},
		{"id":"ab30fd693cea15a6","fromNode":"4b984bd4c9b2b7c4","fromSide":"bottom","toNode":"b8fd4149c7041aa5","toSide":"top","label":"升级"},
		{"id":"6d8b7bb80997b073","fromNode":"b8fd4149c7041aa5","fromSide":"right","toNode":"f3a42fe508210f79","toSide":"left"},
		{"id":"013fcc4818eb9cec","fromNode":"4b984bd4c9b2b7c4","fromSide":"bottom","toNode":"c1af485da37092c2","toSide":"right"},
		{"id":"6fb2f8f2977d29b0","fromNode":"7db2bb009ed68003","fromSide":"top","toNode":"a674611508efcd0f","toSide":"left"},
		{"id":"bb40801b2b0b1a4a","fromNode":"a396eba41fcff354","fromSide":"right","toNode":"85c0d134647151c5","toSide":"left"},
		{"id":"239baf537d5cd2d5","fromNode":"d14c80be5fe14b5a","fromSide":"right","toNode":"a396eba41fcff354","toSide":"left"},
		{"id":"717a6e1d01bf416c","fromNode":"a83745b02a5ce3f4","fromSide":"right","toNode":"cef0e8c99186aab7","toSide":"left"},
		{"id":"337518be527ea842","fromNode":"f2f5ae852623d3dc","fromSide":"right","toNode":"a83745b02a5ce3f4","toSide":"left"}
	]
}