<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueeemouse.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="abstract 现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进">
<meta property="og:type" content="article">
<meta property="og:title" content="Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models">
<meta property="og:url" content="https://blueeemouse.github.io/2025/06/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/Hybrid-Level%20Instruction%20Injection%20for%20Video%20Token%20Compression%20in%20Multi-modal%20Large%20Language%20Models/index.html">
<meta property="og:site_name" content="bluemouse&#39;s blog">
<meta property="og:description" content="abstract 现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-06-11T15:50:00.000Z">
<meta property="article:modified_time" content="2025-06-12T02:23:18.121Z">
<meta property="article:author" content="bluemouse">
<meta property="article:tag" content="MLLM">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueeemouse.github.io/2025/06/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/Hybrid-Level%20Instruction%20Injection%20for%20Video%20Token%20Compression%20in%20Multi-modal%20Large%20Language%20Models/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models | bluemouse's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">bluemouse's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/06/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/Hybrid-Level%20Instruction%20Injection%20for%20Video%20Token%20Compression%20in%20Multi-modal%20Large%20Language%20Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-06-11 23:50:00" itemprop="dateCreated datePublished" datetime="2025-06-11T23:50:00+08:00">2025-06-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-06-12 10:23:18" itemprop="dateModified" datetime="2025-06-12T10:23:18+08:00">2025-06-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="abstract">abstract</h1>
<h2 id="现在的mllms在处理视频输入的时候遇到的一个问题是计算开销大因为视频是多帧的通常mllms需要把它当成图像序列来处理因此会产生很多visual-tokens为了解决这个问题一个常见的策略是进行压缩但压缩又带来另一个问题现在常见的压缩方法忽视了视频内容与指令之间的关系导致压缩之后对视频内容的理解有缺失换句话说现在的问题是信息质量和计算开销之间需要进行权衡无法同时做得比较好">现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual
tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进行权衡，无法同时做得比较好）</h2>
<h2 id="为了解决这个问题论文是从压缩策略上入手其大体思路是把用户的指令作为条件进行条件压缩这样既能对视频内容进行压缩减少计算开销同时又因为用了指令作为条件则会对重要的视频内容做更多保留因此视频信息的损失会更少">为了解决这个问题，论文是从压缩策略上入手。其大体思路是：把用户的指令作为条件，进行条件压缩。这样，既能对视频内容进行压缩，减少计算开销；同时又因为用了指令作为条件，则会对重要的视频内容做更多保留，因此视频信息的损失会更少</h2>
<span id="more"></span>
<h1 id="method">method</h1>
<h2 id="主要是三个部件或者说三个技巧local-level-compressionglobal-level-compressioninstruction-condition-injection最后论文在训练的范式上也作出创新增加了一个stage即conditional-pre-training-stage">主要是三个部件，或者说三个技巧：Local-Level
Compression，Global-Level Compression，Instruction Condition
Injection。最后，论文在训练的范式上也作出创新，增加了一个stage，即Conditional
Pre-training Stage</h2>
<h2 id="local-level-compression它是把视频输入给分成若干个group在每个group里用注意力机制提取细节信息包括了指令信息的注入而条件压缩就体现在会把每个group压缩到一个token且这个token是通过注意力机制得到的这个过程中注入了指令条件">Local-Level
Compression，它是把视频输入给分成若干个group，在每个group里用注意力机制提取细节信息（包括了指令信息的注入）。而条件压缩就体现在会把每个group压缩到一个token，且这个token是通过注意力机制得到的，这个过程中，注入了指令条件</h2>
<h2 id="global-level-compression它则是作为和local-level-compression互补的部分出现的local-level-compression是在组内进行压缩和注意力机制此时只能得到零散的局部信息因为都是在组内的操作我们希望全局也可以压缩并且还要尽可能遵从指令所以论文会预设一组learnable-tokens-lin-rn_ltimes-d-我们会往它里面注入条件指令信息之后它会和视频进行交互用注意力机制最终输出的结果的token数也是n_l而这是一个超参数由我们指定所以可以定得相对小一些从而实现压缩效果">Global-Level
Compression，它则是作为和Local-Level
Compression互补的部分出现的。Local-Level
Compression是在组内进行压缩和注意力机制，此时只能得到零散的局部信息（因为都是在组内的操作）。我们希望全局也可以压缩，并且还要尽可能遵从指令。所以，论文会预设一组learnable
tokens <span class="math inline">\(L\in R^{N_{L}\times D}\)</span>
，我们会往它里面注入条件指令信息，之后它会和视频进行交互（用注意力机制），最终输出的结果的token数也是<span class="math inline">\(N_{L}\)</span>，而这是一个超参数，由我们指定，所以可以定得相对小一些，从而实现压缩效果</h2>
<h2 id="instruction-condition-injection论文里提出分三种direct-injectioncoarse-injectionfine-injection大体上感觉计算的细节并不是特别新颖也很难说有特别扎实的理论支撑似乎都是比较常见眼熟的操作论文亮点应该并不在于这里的技术细节而是在于发现了问题视频处理计算开销大---压缩效果又不够好---可以提出新的条件压缩来解决以及它提出的条件压缩的解决思路">Instruction
Condition Injection，论文里提出分三种，direct injection，coarse
injection，fine
injection。大体上，感觉计算的细节并不是特别新颖，也很难说有特别扎实的理论支撑，似乎都是比较常见/眼熟的操作。论文亮点应该并不在于这里的技术细节，而是在于发现了问题（视频处理计算开销大---&gt;压缩效果又不够好---&gt;可以提出新的条件压缩来解决），以及它提出的条件压缩的解决思路</h2>
<h2 id="conditional-pre-training-stage是mllms训练范式中新增加的一个stage传统的mllms训练依次是两个stagealignment-stageinstruction-tuning-stage而论文则提出在中间加入一个stageconditions-pre-training-stage这样可以让训练更加流畅">Conditional
Pre-training
Stage，是MLLMs训练范式中新增加的一个stage。传统的MLLMs训练依次是两个stage：Alignment
Stage、Instruction Tuning
Stage，而论文则提出在中间加入一个stage，Conditions Pre-training
Stage，这样可以让训练更加流畅</h2>
<h2 id="下面讲一下技术细节吧">下面讲一下技术细节吧：</h2>
<h3 id="local-level-compression">Local-Level Compression</h3>
<h4 id="这里首先涉及到具体是怎么分组的又得谈到视频输入处理后的形状一般是thwd其中t代表时间帧数htimes-w是空间尺寸d是特征维度视频其实是被视为图像序列来处理的这样看t其实可以认为是图像的数量-压缩时有个压缩比alpha_talpha_halpha_w可以从下标看出来分别代表了thw维度上的压缩比具体的我们会在t维度上进行划分分成fractalpha_tn_t-块在h和w维度也是类似计算最终可以得到n_ttimes-n_htimes-n_w个组分好组后我们的压缩会把一个组里的所有token可以算出有alpha_ttimes-alpha_htimes-alpha_w-个token压缩成一个token此时我们再来看这个分组的方式它沿着时间维度t和空间维度hw都有分组因此一定程度上保留了原来输入的时空结构">这里首先涉及到具体是怎么分组的。又得谈到视频输入处理后的形状，一般是<span class="math inline">\((T,H,W,D)\)</span>，其中T代表时间帧数，<span class="math inline">\(H\times
W\)</span>是空间尺寸，D是特征维度（视频其实是被视为图像序列来处理的。这样看，T其实可以认为是图像的数量）=<br>压缩时，有个压缩比<span class="math inline">\((\alpha_{T},\alpha_{H},\alpha_{W})\)</span>，可以从下标看出来分别代表了T、H、W维度上的压缩比。具体的，我们会在T维度上进行划分，分成<span class="math inline">\(\frac{T}{\alpha_{T}}=N_{T}\)</span>
块，在H和W维度也是类似计算。最终可以得到<span class="math inline">\(N_{T}\times N_{H}\times
N_{W}\)</span>个组。分好组后，我们的压缩会把一个组里的所有token（可以算出，有<span class="math inline">\(\alpha_{T}\times \alpha_{H}\times
\alpha_{W}\)</span>
个token）压缩成一个token。此时我们再来看这个分组的方式，它沿着时间维度（T）和空间维度（H、W）都有分组，因此一定程度上保留了原来输入的时空结构</h4>
<h3 id="global-level-compression">Global-Level Compression</h3>
<h3 id="instruction-condition-injection">Instruction Condition
Injection</h3>
<h4 id="direct-injection它就是直接把文本指令的pooling后的token记为c_p也就是单个token用一个mlp直接映射到视频特征的空间也即injacmlpc这里可能容易造成困惑的点在于看起来这里就没用到a也即可学习的token了事实上也是可以的某些场景下因为我们注入指令本质就是希望把指令作为条件加入到信息提取的过程中从而让结果更加符合指令不管是local还是global-compression最终都是用一个注意力机制来交互提取信息query部分只要有包含指令条件就行这里理论上说query里没有视频信息也是可以的毕竟query是要和key交互的而key里是有视频信息的以及最后和value进行加权得到结果value也是视频信息只不过容易想到这个direct-injection对视频信息的利用还是不够粒度应该是三种injection中最粗糙的">direct
injection，它就是直接把文本指令的pooling后的token，记为<span class="math inline">\(C_{p}\)</span>（也就是单个token），用一个MLP直接映射到视频特征的空间。也即，<span class="math inline">\(Inj(A,C)=MLP(C)\)</span>（这里可能容易造成困惑的点在于，看起来这里就没用到A（也即可学习的token）了。事实上也是可以的（某些场景下）。因为我们注入指令，本质就是希望把指令作为条件，加入到信息提取的过程中，从而让结果更加符合指令。不管是local还是global
compression，最终都是用一个注意力机制来交互提取信息。query部分只要有包含指令条件就行（这里理论上说，query里没有视频信息也是可以的，毕竟query是要和key交互的，而key里是有视频信息的；以及最后和value进行加权得到结果，value也是视频信息。只不过容易想到，这个direct
injection对视频信息的利用还是不够。粒度应该是三种injection中最粗糙的）</h4>
<h4 id="至于coarse和fine-injection简单说它们一个类似于adain一个基本就是用了cross-attention而已嗯跟一开始猜的八九不离十吧">至于coarse和fine
injection，简单说，它们一个类似于adaIn，一个基本就是用了cross
attention而已。嗯。跟一开始猜的八九不离十吧。</h4>
<h4 id="coarse-injection它是先对视频特征进行一个ln之后要对它scale并shift而scale和shift的量则是由单个的指令token-c_p-通过一个mlp回归得到似乎可以认为是类似于常见的想法把mean和std视为内容风格的一种表征这里通过由指令来影响视频token的mean和std从而影响了视频内容做到让指令控制视频内容也就是指令注入">coarse
injection，它是先对视频特征进行一个LN，之后要对它scale并shift。而scale和shift的量则是由单个的指令token
<span class="math inline">\(C_{p}\)</span>
通过一个MLP回归得到（似乎可以认为，是类似于常见的想法，把mean和std视为内容风格的一种表征。这里通过由指令来影响视频token的mean和std，从而影响了视频内容，做到让指令控制视频内容，也就是指令注入）</h4>
<h4 id="fine-injection它拿到的条件不是指令经过pooling后的一个token而是原来的token序列c_fin-rltimes-d这里把指令条件注入到视频中的方法是通过注意力机制具体来说是injacattnlnac_fc_f">fine
injection，它拿到的条件不是指令经过pooling后的一个token，而是原来的token序列<span class="math inline">\(C_{f}\in R^{L\times
D}\)</span>。这里把指令条件注入到视频中的方法是通过注意力机制，具体来说是<span class="math inline">\(Inj(A,C)=Attn(LN(A),C_{f},C_{f})\)</span></h4>
<h3 id="conditional-pre-training-stage">Conditional Pre-training
Stage</h3>
<h4 id="首先alignment-stage它类似于llm的pre-training阶段可以认为目的是让mllms具有初步的基础的能力这个阶段会使用图像-文本对数据来训练模型从而让视觉编码器输出的特征可以被语言模型理解为的是让视觉token和语言token在同一个空间里建立跨模态的统一表示也因此数据里是不包含显式指令的故此时的mllms对指令的理解和遵从还不够好需要进一步的instruction-tuning-stage">首先，Alignment
Stage，它类似于llm的pre-training阶段，可以认为目的是让MLLMs具有初步的、基础的能力。这个阶段会使用图像-文本对数据来训练模型，从而让视觉编码器输出的特征可以被语言模型理解，为的是让视觉token和语言token在同一个空间里，建立跨模态的统一表示。也因此，数据里是不包含显式指令的（故此时的MLLMs对指令的理解和遵从还不够好，需要进一步的Instruction
Tuning Stage）</h4>
<h4 id="而instruction-tuning-stage它的目的就是让模型学会遵循用户指令完成具体任务比如视频问答推理此时用到的数据就是指令-回答对数据">而Instruction
Tuning
Stage，它的目的就是让模型学会遵循用户指令，完成具体任务（比如视频问答、推理）。此时用到的数据就是指令-回答对数据</h4>
<h4 id="但关于论文里提到的加入conditional-pre-training-stage的原因个人理解是这样的传统范式里是两个阶段而论文此前提出的技术主要是为了压缩视频的内容简单说就是把视频对应的token数量减少其余地方是不变的但因为压缩的时候是条件压缩会把指令给当作条件注入其中如果模型此时的指令遵循能力还不够好那么把指令注入之后效果可能并不好这一点推测可能是实验中发现了这个现象而后归纳出这个原因然而一般的流程里为了解决模型指令遵循效果不好的问题就会进行instruction-tuning所以现在有点卡在这了正常的alignment-stage结束后需要进行instruction-tuning来增强模型的指令遵循能力但因为论文的方法是条件压缩对指令遵循有更高的要求所以alignment后直接进行instruction-tuning在压缩的时候效果会不好为此我们需要提高指令遵循能力但提高指令遵循能力传统方案又是进行instruction-tuning-所以论文直接跳出来在instruction-tuning前增加一个前置stage先稍微把条件压缩时的指令遵循能力提高一些这里不像instruction-tuning-stage会对llm也进行微调这个阶段我们只微调条件压缩相关的部分提高那些模块里指令注入的效果这样后面到了instruction-tuning-stage时条件压缩也能做得比较好了不用担心模型的指令遵循能力过差导致的条件压缩效果不好">但关于论文里提到的，加入Conditional
Pre-training
Stage的原因，个人理解是这样的：传统范式里是两个阶段。而论文此前提出的技术，主要是为了压缩视频的内容，简单说就是把视频对应的token数量减少。其余地方是不变的。但因为压缩的时候是条件压缩，会把指令给当作条件注入其中，如果模型此时的指令遵循能力还不够好，那么把指令注入之后，效果可能并不好（这一点推测可能是实验中发现了这个现象，而后归纳出这个原因）。然而一般的流程里，为了解决模型指令遵循效果不好的问题，就会进行Instruction
Tuning。所以现在有点卡在这了：正常的Alignment
Stage结束后，需要进行Instruction
Tuning来增强模型的指令遵循能力；但因为论文的方法是条件压缩，对指令遵循有更高的要求，所以Alignment后直接进行Instruction
Tuning，在压缩的时候效果会不好；为此我们需要提高指令遵循能力，但提高指令遵循能力，传统方案又是进行Instruction
Tuning……<br>所以，论文直接跳出来，在Instruction
Tuning前增加一个前置stage，先稍微把条件压缩时的指令遵循能力提高一些（这里不像Instruction
Tuning
Stage，会对llm也进行微调；这个阶段我们只微调条件压缩相关的部分，提高那些模块里指令注入的效果。这样，后面到了Instruction
Tuning
Stage时，条件压缩也能做得比较好了，不用担心模型的指令遵循能力过差导致的条件压缩效果不好）</h4>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/MLLM/" rel="tag"># MLLM</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/06/11/algo/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/%E4%B8%8D%E5%AE%9A%E9%95%BF%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/%E5%92%8C%E7%9B%B8%E5%90%8C%E7%9A%84%E4%BA%8C%E5%85%83%E5%AD%90%E6%95%B0%E7%BB%84/" rel="prev" title="和相同的二元子数组">
      <i class="fa fa-chevron-left"></i> 和相同的二元子数组
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/06/12/algo/Leetcode-hot100/%E7%9F%A9%E9%98%B5/%E7%9F%A9%E9%98%B5%E7%BD%AE%E9%9B%B6/%E7%9F%A9%E9%98%B5%E7%BD%AE%E9%9B%B6/" rel="next" title="矩阵置零">
      矩阵置零 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#abstract"><span class="nav-number">1.</span> <span class="nav-text">abstract</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%B0%E5%9C%A8%E7%9A%84mllms%E5%9C%A8%E5%A4%84%E7%90%86%E8%A7%86%E9%A2%91%E8%BE%93%E5%85%A5%E7%9A%84%E6%97%B6%E5%80%99%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%E6%98%AF%E8%AE%A1%E7%AE%97%E5%BC%80%E9%94%80%E5%A4%A7%E5%9B%A0%E4%B8%BA%E8%A7%86%E9%A2%91%E6%98%AF%E5%A4%9A%E5%B8%A7%E7%9A%84%E9%80%9A%E5%B8%B8mllms%E9%9C%80%E8%A6%81%E6%8A%8A%E5%AE%83%E5%BD%93%E6%88%90%E5%9B%BE%E5%83%8F%E5%BA%8F%E5%88%97%E6%9D%A5%E5%A4%84%E7%90%86%E5%9B%A0%E6%AD%A4%E4%BC%9A%E4%BA%A7%E7%94%9F%E5%BE%88%E5%A4%9Avisual-tokens%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%E4%B8%80%E4%B8%AA%E5%B8%B8%E8%A7%81%E7%9A%84%E7%AD%96%E7%95%A5%E6%98%AF%E8%BF%9B%E8%A1%8C%E5%8E%8B%E7%BC%A9%E4%BD%86%E5%8E%8B%E7%BC%A9%E5%8F%88%E5%B8%A6%E6%9D%A5%E5%8F%A6%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%E7%8E%B0%E5%9C%A8%E5%B8%B8%E8%A7%81%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E5%BF%BD%E8%A7%86%E4%BA%86%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E4%B8%8E%E6%8C%87%E4%BB%A4%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%E5%AF%BC%E8%87%B4%E5%8E%8B%E7%BC%A9%E4%B9%8B%E5%90%8E%E5%AF%B9%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E7%9A%84%E7%90%86%E8%A7%A3%E6%9C%89%E7%BC%BA%E5%A4%B1%E6%8D%A2%E5%8F%A5%E8%AF%9D%E8%AF%B4%E7%8E%B0%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98%E6%98%AF%E4%BF%A1%E6%81%AF%E8%B4%A8%E9%87%8F%E5%92%8C%E8%AE%A1%E7%AE%97%E5%BC%80%E9%94%80%E4%B9%8B%E9%97%B4%E9%9C%80%E8%A6%81%E8%BF%9B%E8%A1%8C%E6%9D%83%E8%A1%A1%E6%97%A0%E6%B3%95%E5%90%8C%E6%97%B6%E5%81%9A%E5%BE%97%E6%AF%94%E8%BE%83%E5%A5%BD"><span class="nav-number">1.1.</span> <span class="nav-text">现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual
tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进行权衡，无法同时做得比较好）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%E8%AE%BA%E6%96%87%E6%98%AF%E4%BB%8E%E5%8E%8B%E7%BC%A9%E7%AD%96%E7%95%A5%E4%B8%8A%E5%85%A5%E6%89%8B%E5%85%B6%E5%A4%A7%E4%BD%93%E6%80%9D%E8%B7%AF%E6%98%AF%E6%8A%8A%E7%94%A8%E6%88%B7%E7%9A%84%E6%8C%87%E4%BB%A4%E4%BD%9C%E4%B8%BA%E6%9D%A1%E4%BB%B6%E8%BF%9B%E8%A1%8C%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E8%BF%99%E6%A0%B7%E6%97%A2%E8%83%BD%E5%AF%B9%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E8%BF%9B%E8%A1%8C%E5%8E%8B%E7%BC%A9%E5%87%8F%E5%B0%91%E8%AE%A1%E7%AE%97%E5%BC%80%E9%94%80%E5%90%8C%E6%97%B6%E5%8F%88%E5%9B%A0%E4%B8%BA%E7%94%A8%E4%BA%86%E6%8C%87%E4%BB%A4%E4%BD%9C%E4%B8%BA%E6%9D%A1%E4%BB%B6%E5%88%99%E4%BC%9A%E5%AF%B9%E9%87%8D%E8%A6%81%E7%9A%84%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E5%81%9A%E6%9B%B4%E5%A4%9A%E4%BF%9D%E7%95%99%E5%9B%A0%E6%AD%A4%E8%A7%86%E9%A2%91%E4%BF%A1%E6%81%AF%E7%9A%84%E6%8D%9F%E5%A4%B1%E4%BC%9A%E6%9B%B4%E5%B0%91"><span class="nav-number">1.2.</span> <span class="nav-text">为了解决这个问题，论文是从压缩策略上入手。其大体思路是：把用户的指令作为条件，进行条件压缩。这样，既能对视频内容进行压缩，减少计算开销；同时又因为用了指令作为条件，则会对重要的视频内容做更多保留，因此视频信息的损失会更少</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#method"><span class="nav-number">2.</span> <span class="nav-text">method</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E6%98%AF%E4%B8%89%E4%B8%AA%E9%83%A8%E4%BB%B6%E6%88%96%E8%80%85%E8%AF%B4%E4%B8%89%E4%B8%AA%E6%8A%80%E5%B7%A7local-level-compressionglobal-level-compressioninstruction-condition-injection%E6%9C%80%E5%90%8E%E8%AE%BA%E6%96%87%E5%9C%A8%E8%AE%AD%E7%BB%83%E7%9A%84%E8%8C%83%E5%BC%8F%E4%B8%8A%E4%B9%9F%E4%BD%9C%E5%87%BA%E5%88%9B%E6%96%B0%E5%A2%9E%E5%8A%A0%E4%BA%86%E4%B8%80%E4%B8%AAstage%E5%8D%B3conditional-pre-training-stage"><span class="nav-number">2.1.</span> <span class="nav-text">主要是三个部件，或者说三个技巧：Local-Level
Compression，Global-Level Compression，Instruction Condition
Injection。最后，论文在训练的范式上也作出创新，增加了一个stage，即Conditional
Pre-training Stage</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#local-level-compression%E5%AE%83%E6%98%AF%E6%8A%8A%E8%A7%86%E9%A2%91%E8%BE%93%E5%85%A5%E7%BB%99%E5%88%86%E6%88%90%E8%8B%A5%E5%B9%B2%E4%B8%AAgroup%E5%9C%A8%E6%AF%8F%E4%B8%AAgroup%E9%87%8C%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%8F%90%E5%8F%96%E7%BB%86%E8%8A%82%E4%BF%A1%E6%81%AF%E5%8C%85%E6%8B%AC%E4%BA%86%E6%8C%87%E4%BB%A4%E4%BF%A1%E6%81%AF%E7%9A%84%E6%B3%A8%E5%85%A5%E8%80%8C%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E5%B0%B1%E4%BD%93%E7%8E%B0%E5%9C%A8%E4%BC%9A%E6%8A%8A%E6%AF%8F%E4%B8%AAgroup%E5%8E%8B%E7%BC%A9%E5%88%B0%E4%B8%80%E4%B8%AAtoken%E4%B8%94%E8%BF%99%E4%B8%AAtoken%E6%98%AF%E9%80%9A%E8%BF%87%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%BE%97%E5%88%B0%E7%9A%84%E8%BF%99%E4%B8%AA%E8%BF%87%E7%A8%8B%E4%B8%AD%E6%B3%A8%E5%85%A5%E4%BA%86%E6%8C%87%E4%BB%A4%E6%9D%A1%E4%BB%B6"><span class="nav-number">2.2.</span> <span class="nav-text">Local-Level
Compression，它是把视频输入给分成若干个group，在每个group里用注意力机制提取细节信息（包括了指令信息的注入）。而条件压缩就体现在会把每个group压缩到一个token，且这个token是通过注意力机制得到的，这个过程中，注入了指令条件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#global-level-compression%E5%AE%83%E5%88%99%E6%98%AF%E4%BD%9C%E4%B8%BA%E5%92%8Clocal-level-compression%E4%BA%92%E8%A1%A5%E7%9A%84%E9%83%A8%E5%88%86%E5%87%BA%E7%8E%B0%E7%9A%84local-level-compression%E6%98%AF%E5%9C%A8%E7%BB%84%E5%86%85%E8%BF%9B%E8%A1%8C%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%AD%A4%E6%97%B6%E5%8F%AA%E8%83%BD%E5%BE%97%E5%88%B0%E9%9B%B6%E6%95%A3%E7%9A%84%E5%B1%80%E9%83%A8%E4%BF%A1%E6%81%AF%E5%9B%A0%E4%B8%BA%E9%83%BD%E6%98%AF%E5%9C%A8%E7%BB%84%E5%86%85%E7%9A%84%E6%93%8D%E4%BD%9C%E6%88%91%E4%BB%AC%E5%B8%8C%E6%9C%9B%E5%85%A8%E5%B1%80%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%8E%8B%E7%BC%A9%E5%B9%B6%E4%B8%94%E8%BF%98%E8%A6%81%E5%B0%BD%E5%8F%AF%E8%83%BD%E9%81%B5%E4%BB%8E%E6%8C%87%E4%BB%A4%E6%89%80%E4%BB%A5%E8%AE%BA%E6%96%87%E4%BC%9A%E9%A2%84%E8%AE%BE%E4%B8%80%E7%BB%84learnable-tokens-lin-rn_ltimes-d-%E6%88%91%E4%BB%AC%E4%BC%9A%E5%BE%80%E5%AE%83%E9%87%8C%E9%9D%A2%E6%B3%A8%E5%85%A5%E6%9D%A1%E4%BB%B6%E6%8C%87%E4%BB%A4%E4%BF%A1%E6%81%AF%E4%B9%8B%E5%90%8E%E5%AE%83%E4%BC%9A%E5%92%8C%E8%A7%86%E9%A2%91%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%9C%80%E7%BB%88%E8%BE%93%E5%87%BA%E7%9A%84%E7%BB%93%E6%9E%9C%E7%9A%84token%E6%95%B0%E4%B9%9F%E6%98%AFn_l%E8%80%8C%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E8%B6%85%E5%8F%82%E6%95%B0%E7%94%B1%E6%88%91%E4%BB%AC%E6%8C%87%E5%AE%9A%E6%89%80%E4%BB%A5%E5%8F%AF%E4%BB%A5%E5%AE%9A%E5%BE%97%E7%9B%B8%E5%AF%B9%E5%B0%8F%E4%B8%80%E4%BA%9B%E4%BB%8E%E8%80%8C%E5%AE%9E%E7%8E%B0%E5%8E%8B%E7%BC%A9%E6%95%88%E6%9E%9C"><span class="nav-number">2.3.</span> <span class="nav-text">Global-Level
Compression，它则是作为和Local-Level
Compression互补的部分出现的。Local-Level
Compression是在组内进行压缩和注意力机制，此时只能得到零散的局部信息（因为都是在组内的操作）。我们希望全局也可以压缩，并且还要尽可能遵从指令。所以，论文会预设一组learnable
tokens \(L\in R^{N_{L}\times D}\)
，我们会往它里面注入条件指令信息，之后它会和视频进行交互（用注意力机制），最终输出的结果的token数也是\(N_{L}\)，而这是一个超参数，由我们指定，所以可以定得相对小一些，从而实现压缩效果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#instruction-condition-injection%E8%AE%BA%E6%96%87%E9%87%8C%E6%8F%90%E5%87%BA%E5%88%86%E4%B8%89%E7%A7%8Ddirect-injectioncoarse-injectionfine-injection%E5%A4%A7%E4%BD%93%E4%B8%8A%E6%84%9F%E8%A7%89%E8%AE%A1%E7%AE%97%E7%9A%84%E7%BB%86%E8%8A%82%E5%B9%B6%E4%B8%8D%E6%98%AF%E7%89%B9%E5%88%AB%E6%96%B0%E9%A2%96%E4%B9%9F%E5%BE%88%E9%9A%BE%E8%AF%B4%E6%9C%89%E7%89%B9%E5%88%AB%E6%89%8E%E5%AE%9E%E7%9A%84%E7%90%86%E8%AE%BA%E6%94%AF%E6%92%91%E4%BC%BC%E4%B9%8E%E9%83%BD%E6%98%AF%E6%AF%94%E8%BE%83%E5%B8%B8%E8%A7%81%E7%9C%BC%E7%86%9F%E7%9A%84%E6%93%8D%E4%BD%9C%E8%AE%BA%E6%96%87%E4%BA%AE%E7%82%B9%E5%BA%94%E8%AF%A5%E5%B9%B6%E4%B8%8D%E5%9C%A8%E4%BA%8E%E8%BF%99%E9%87%8C%E7%9A%84%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82%E8%80%8C%E6%98%AF%E5%9C%A8%E4%BA%8E%E5%8F%91%E7%8E%B0%E4%BA%86%E9%97%AE%E9%A2%98%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E8%AE%A1%E7%AE%97%E5%BC%80%E9%94%80%E5%A4%A7---%E5%8E%8B%E7%BC%A9%E6%95%88%E6%9E%9C%E5%8F%88%E4%B8%8D%E5%A4%9F%E5%A5%BD---%E5%8F%AF%E4%BB%A5%E6%8F%90%E5%87%BA%E6%96%B0%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E6%9D%A5%E8%A7%A3%E5%86%B3%E4%BB%A5%E5%8F%8A%E5%AE%83%E6%8F%90%E5%87%BA%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E7%9A%84%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF"><span class="nav-number">2.4.</span> <span class="nav-text">Instruction
Condition Injection，论文里提出分三种，direct injection，coarse
injection，fine
injection。大体上，感觉计算的细节并不是特别新颖，也很难说有特别扎实的理论支撑，似乎都是比较常见&#x2F;眼熟的操作。论文亮点应该并不在于这里的技术细节，而是在于发现了问题（视频处理计算开销大---&gt;压缩效果又不够好---&gt;可以提出新的条件压缩来解决），以及它提出的条件压缩的解决思路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conditional-pre-training-stage%E6%98%AFmllms%E8%AE%AD%E7%BB%83%E8%8C%83%E5%BC%8F%E4%B8%AD%E6%96%B0%E5%A2%9E%E5%8A%A0%E7%9A%84%E4%B8%80%E4%B8%AAstage%E4%BC%A0%E7%BB%9F%E7%9A%84mllms%E8%AE%AD%E7%BB%83%E4%BE%9D%E6%AC%A1%E6%98%AF%E4%B8%A4%E4%B8%AAstagealignment-stageinstruction-tuning-stage%E8%80%8C%E8%AE%BA%E6%96%87%E5%88%99%E6%8F%90%E5%87%BA%E5%9C%A8%E4%B8%AD%E9%97%B4%E5%8A%A0%E5%85%A5%E4%B8%80%E4%B8%AAstageconditions-pre-training-stage%E8%BF%99%E6%A0%B7%E5%8F%AF%E4%BB%A5%E8%AE%A9%E8%AE%AD%E7%BB%83%E6%9B%B4%E5%8A%A0%E6%B5%81%E7%95%85"><span class="nav-number">2.5.</span> <span class="nav-text">Conditional
Pre-training
Stage，是MLLMs训练范式中新增加的一个stage。传统的MLLMs训练依次是两个stage：Alignment
Stage、Instruction Tuning
Stage，而论文则提出在中间加入一个stage，Conditions Pre-training
Stage，这样可以让训练更加流畅</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8B%E9%9D%A2%E8%AE%B2%E4%B8%80%E4%B8%8B%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82%E5%90%A7"><span class="nav-number">2.6.</span> <span class="nav-text">下面讲一下技术细节吧：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#local-level-compression"><span class="nav-number">2.6.1.</span> <span class="nav-text">Local-Level Compression</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%99%E9%87%8C%E9%A6%96%E5%85%88%E6%B6%89%E5%8F%8A%E5%88%B0%E5%85%B7%E4%BD%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%88%86%E7%BB%84%E7%9A%84%E5%8F%88%E5%BE%97%E8%B0%88%E5%88%B0%E8%A7%86%E9%A2%91%E8%BE%93%E5%85%A5%E5%A4%84%E7%90%86%E5%90%8E%E7%9A%84%E5%BD%A2%E7%8A%B6%E4%B8%80%E8%88%AC%E6%98%AFthwd%E5%85%B6%E4%B8%ADt%E4%BB%A3%E8%A1%A8%E6%97%B6%E9%97%B4%E5%B8%A7%E6%95%B0htimes-w%E6%98%AF%E7%A9%BA%E9%97%B4%E5%B0%BA%E5%AF%B8d%E6%98%AF%E7%89%B9%E5%BE%81%E7%BB%B4%E5%BA%A6%E8%A7%86%E9%A2%91%E5%85%B6%E5%AE%9E%E6%98%AF%E8%A2%AB%E8%A7%86%E4%B8%BA%E5%9B%BE%E5%83%8F%E5%BA%8F%E5%88%97%E6%9D%A5%E5%A4%84%E7%90%86%E7%9A%84%E8%BF%99%E6%A0%B7%E7%9C%8Bt%E5%85%B6%E5%AE%9E%E5%8F%AF%E4%BB%A5%E8%AE%A4%E4%B8%BA%E6%98%AF%E5%9B%BE%E5%83%8F%E7%9A%84%E6%95%B0%E9%87%8F-%E5%8E%8B%E7%BC%A9%E6%97%B6%E6%9C%89%E4%B8%AA%E5%8E%8B%E7%BC%A9%E6%AF%94alpha_talpha_halpha_w%E5%8F%AF%E4%BB%A5%E4%BB%8E%E4%B8%8B%E6%A0%87%E7%9C%8B%E5%87%BA%E6%9D%A5%E5%88%86%E5%88%AB%E4%BB%A3%E8%A1%A8%E4%BA%86thw%E7%BB%B4%E5%BA%A6%E4%B8%8A%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%AF%94%E5%85%B7%E4%BD%93%E7%9A%84%E6%88%91%E4%BB%AC%E4%BC%9A%E5%9C%A8t%E7%BB%B4%E5%BA%A6%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%88%92%E5%88%86%E5%88%86%E6%88%90fractalpha_tn_t-%E5%9D%97%E5%9C%A8h%E5%92%8Cw%E7%BB%B4%E5%BA%A6%E4%B9%9F%E6%98%AF%E7%B1%BB%E4%BC%BC%E8%AE%A1%E7%AE%97%E6%9C%80%E7%BB%88%E5%8F%AF%E4%BB%A5%E5%BE%97%E5%88%B0n_ttimes-n_htimes-n_w%E4%B8%AA%E7%BB%84%E5%88%86%E5%A5%BD%E7%BB%84%E5%90%8E%E6%88%91%E4%BB%AC%E7%9A%84%E5%8E%8B%E7%BC%A9%E4%BC%9A%E6%8A%8A%E4%B8%80%E4%B8%AA%E7%BB%84%E9%87%8C%E7%9A%84%E6%89%80%E6%9C%89token%E5%8F%AF%E4%BB%A5%E7%AE%97%E5%87%BA%E6%9C%89alpha_ttimes-alpha_htimes-alpha_w-%E4%B8%AAtoken%E5%8E%8B%E7%BC%A9%E6%88%90%E4%B8%80%E4%B8%AAtoken%E6%AD%A4%E6%97%B6%E6%88%91%E4%BB%AC%E5%86%8D%E6%9D%A5%E7%9C%8B%E8%BF%99%E4%B8%AA%E5%88%86%E7%BB%84%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%83%E6%B2%BF%E7%9D%80%E6%97%B6%E9%97%B4%E7%BB%B4%E5%BA%A6t%E5%92%8C%E7%A9%BA%E9%97%B4%E7%BB%B4%E5%BA%A6hw%E9%83%BD%E6%9C%89%E5%88%86%E7%BB%84%E5%9B%A0%E6%AD%A4%E4%B8%80%E5%AE%9A%E7%A8%8B%E5%BA%A6%E4%B8%8A%E4%BF%9D%E7%95%99%E4%BA%86%E5%8E%9F%E6%9D%A5%E8%BE%93%E5%85%A5%E7%9A%84%E6%97%B6%E7%A9%BA%E7%BB%93%E6%9E%84"><span class="nav-number">2.6.1.1.</span> <span class="nav-text">这里首先涉及到具体是怎么分组的。又得谈到视频输入处理后的形状，一般是\((T,H,W,D)\)，其中T代表时间帧数，\(H\times
W\)是空间尺寸，D是特征维度（视频其实是被视为图像序列来处理的。这样看，T其实可以认为是图像的数量）&#x3D;压缩时，有个压缩比\((\alpha_{T},\alpha_{H},\alpha_{W})\)，可以从下标看出来分别代表了T、H、W维度上的压缩比。具体的，我们会在T维度上进行划分，分成\(\frac{T}{\alpha_{T}}&#x3D;N_{T}\)
块，在H和W维度也是类似计算。最终可以得到\(N_{T}\times N_{H}\times
N_{W}\)个组。分好组后，我们的压缩会把一个组里的所有token（可以算出，有\(\alpha_{T}\times \alpha_{H}\times
\alpha_{W}\)
个token）压缩成一个token。此时我们再来看这个分组的方式，它沿着时间维度（T）和空间维度（H、W）都有分组，因此一定程度上保留了原来输入的时空结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#global-level-compression"><span class="nav-number">2.6.2.</span> <span class="nav-text">Global-Level Compression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#instruction-condition-injection"><span class="nav-number">2.6.3.</span> <span class="nav-text">Instruction Condition
Injection</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#direct-injection%E5%AE%83%E5%B0%B1%E6%98%AF%E7%9B%B4%E6%8E%A5%E6%8A%8A%E6%96%87%E6%9C%AC%E6%8C%87%E4%BB%A4%E7%9A%84pooling%E5%90%8E%E7%9A%84token%E8%AE%B0%E4%B8%BAc_p%E4%B9%9F%E5%B0%B1%E6%98%AF%E5%8D%95%E4%B8%AAtoken%E7%94%A8%E4%B8%80%E4%B8%AAmlp%E7%9B%B4%E6%8E%A5%E6%98%A0%E5%B0%84%E5%88%B0%E8%A7%86%E9%A2%91%E7%89%B9%E5%BE%81%E7%9A%84%E7%A9%BA%E9%97%B4%E4%B9%9F%E5%8D%B3injacmlpc%E8%BF%99%E9%87%8C%E5%8F%AF%E8%83%BD%E5%AE%B9%E6%98%93%E9%80%A0%E6%88%90%E5%9B%B0%E6%83%91%E7%9A%84%E7%82%B9%E5%9C%A8%E4%BA%8E%E7%9C%8B%E8%B5%B7%E6%9D%A5%E8%BF%99%E9%87%8C%E5%B0%B1%E6%B2%A1%E7%94%A8%E5%88%B0a%E4%B9%9F%E5%8D%B3%E5%8F%AF%E5%AD%A6%E4%B9%A0%E7%9A%84token%E4%BA%86%E4%BA%8B%E5%AE%9E%E4%B8%8A%E4%B9%9F%E6%98%AF%E5%8F%AF%E4%BB%A5%E7%9A%84%E6%9F%90%E4%BA%9B%E5%9C%BA%E6%99%AF%E4%B8%8B%E5%9B%A0%E4%B8%BA%E6%88%91%E4%BB%AC%E6%B3%A8%E5%85%A5%E6%8C%87%E4%BB%A4%E6%9C%AC%E8%B4%A8%E5%B0%B1%E6%98%AF%E5%B8%8C%E6%9C%9B%E6%8A%8A%E6%8C%87%E4%BB%A4%E4%BD%9C%E4%B8%BA%E6%9D%A1%E4%BB%B6%E5%8A%A0%E5%85%A5%E5%88%B0%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%E4%BB%8E%E8%80%8C%E8%AE%A9%E7%BB%93%E6%9E%9C%E6%9B%B4%E5%8A%A0%E7%AC%A6%E5%90%88%E6%8C%87%E4%BB%A4%E4%B8%8D%E7%AE%A1%E6%98%AFlocal%E8%BF%98%E6%98%AFglobal-compression%E6%9C%80%E7%BB%88%E9%83%BD%E6%98%AF%E7%94%A8%E4%B8%80%E4%B8%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%9D%A5%E4%BA%A4%E4%BA%92%E6%8F%90%E5%8F%96%E4%BF%A1%E6%81%AFquery%E9%83%A8%E5%88%86%E5%8F%AA%E8%A6%81%E6%9C%89%E5%8C%85%E5%90%AB%E6%8C%87%E4%BB%A4%E6%9D%A1%E4%BB%B6%E5%B0%B1%E8%A1%8C%E8%BF%99%E9%87%8C%E7%90%86%E8%AE%BA%E4%B8%8A%E8%AF%B4query%E9%87%8C%E6%B2%A1%E6%9C%89%E8%A7%86%E9%A2%91%E4%BF%A1%E6%81%AF%E4%B9%9F%E6%98%AF%E5%8F%AF%E4%BB%A5%E7%9A%84%E6%AF%95%E7%AB%9Fquery%E6%98%AF%E8%A6%81%E5%92%8Ckey%E4%BA%A4%E4%BA%92%E7%9A%84%E8%80%8Ckey%E9%87%8C%E6%98%AF%E6%9C%89%E8%A7%86%E9%A2%91%E4%BF%A1%E6%81%AF%E7%9A%84%E4%BB%A5%E5%8F%8A%E6%9C%80%E5%90%8E%E5%92%8Cvalue%E8%BF%9B%E8%A1%8C%E5%8A%A0%E6%9D%83%E5%BE%97%E5%88%B0%E7%BB%93%E6%9E%9Cvalue%E4%B9%9F%E6%98%AF%E8%A7%86%E9%A2%91%E4%BF%A1%E6%81%AF%E5%8F%AA%E4%B8%8D%E8%BF%87%E5%AE%B9%E6%98%93%E6%83%B3%E5%88%B0%E8%BF%99%E4%B8%AAdirect-injection%E5%AF%B9%E8%A7%86%E9%A2%91%E4%BF%A1%E6%81%AF%E7%9A%84%E5%88%A9%E7%94%A8%E8%BF%98%E6%98%AF%E4%B8%8D%E5%A4%9F%E7%B2%92%E5%BA%A6%E5%BA%94%E8%AF%A5%E6%98%AF%E4%B8%89%E7%A7%8Dinjection%E4%B8%AD%E6%9C%80%E7%B2%97%E7%B3%99%E7%9A%84"><span class="nav-number">2.6.3.1.</span> <span class="nav-text">direct
injection，它就是直接把文本指令的pooling后的token，记为\(C_{p}\)（也就是单个token），用一个MLP直接映射到视频特征的空间。也即，\(Inj(A,C)&#x3D;MLP(C)\)（这里可能容易造成困惑的点在于，看起来这里就没用到A（也即可学习的token）了。事实上也是可以的（某些场景下）。因为我们注入指令，本质就是希望把指令作为条件，加入到信息提取的过程中，从而让结果更加符合指令。不管是local还是global
compression，最终都是用一个注意力机制来交互提取信息。query部分只要有包含指令条件就行（这里理论上说，query里没有视频信息也是可以的，毕竟query是要和key交互的，而key里是有视频信息的；以及最后和value进行加权得到结果，value也是视频信息。只不过容易想到，这个direct
injection对视频信息的利用还是不够。粒度应该是三种injection中最粗糙的）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%B3%E4%BA%8Ecoarse%E5%92%8Cfine-injection%E7%AE%80%E5%8D%95%E8%AF%B4%E5%AE%83%E4%BB%AC%E4%B8%80%E4%B8%AA%E7%B1%BB%E4%BC%BC%E4%BA%8Eadain%E4%B8%80%E4%B8%AA%E5%9F%BA%E6%9C%AC%E5%B0%B1%E6%98%AF%E7%94%A8%E4%BA%86cross-attention%E8%80%8C%E5%B7%B2%E5%97%AF%E8%B7%9F%E4%B8%80%E5%BC%80%E5%A7%8B%E7%8C%9C%E7%9A%84%E5%85%AB%E4%B9%9D%E4%B8%8D%E7%A6%BB%E5%8D%81%E5%90%A7"><span class="nav-number">2.6.3.2.</span> <span class="nav-text">至于coarse和fine
injection，简单说，它们一个类似于adaIn，一个基本就是用了cross
attention而已。嗯。跟一开始猜的八九不离十吧。</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#coarse-injection%E5%AE%83%E6%98%AF%E5%85%88%E5%AF%B9%E8%A7%86%E9%A2%91%E7%89%B9%E5%BE%81%E8%BF%9B%E8%A1%8C%E4%B8%80%E4%B8%AAln%E4%B9%8B%E5%90%8E%E8%A6%81%E5%AF%B9%E5%AE%83scale%E5%B9%B6shift%E8%80%8Cscale%E5%92%8Cshift%E7%9A%84%E9%87%8F%E5%88%99%E6%98%AF%E7%94%B1%E5%8D%95%E4%B8%AA%E7%9A%84%E6%8C%87%E4%BB%A4token-c_p-%E9%80%9A%E8%BF%87%E4%B8%80%E4%B8%AAmlp%E5%9B%9E%E5%BD%92%E5%BE%97%E5%88%B0%E4%BC%BC%E4%B9%8E%E5%8F%AF%E4%BB%A5%E8%AE%A4%E4%B8%BA%E6%98%AF%E7%B1%BB%E4%BC%BC%E4%BA%8E%E5%B8%B8%E8%A7%81%E7%9A%84%E6%83%B3%E6%B3%95%E6%8A%8Amean%E5%92%8Cstd%E8%A7%86%E4%B8%BA%E5%86%85%E5%AE%B9%E9%A3%8E%E6%A0%BC%E7%9A%84%E4%B8%80%E7%A7%8D%E8%A1%A8%E5%BE%81%E8%BF%99%E9%87%8C%E9%80%9A%E8%BF%87%E7%94%B1%E6%8C%87%E4%BB%A4%E6%9D%A5%E5%BD%B1%E5%93%8D%E8%A7%86%E9%A2%91token%E7%9A%84mean%E5%92%8Cstd%E4%BB%8E%E8%80%8C%E5%BD%B1%E5%93%8D%E4%BA%86%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E5%81%9A%E5%88%B0%E8%AE%A9%E6%8C%87%E4%BB%A4%E6%8E%A7%E5%88%B6%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E4%B9%9F%E5%B0%B1%E6%98%AF%E6%8C%87%E4%BB%A4%E6%B3%A8%E5%85%A5"><span class="nav-number">2.6.3.3.</span> <span class="nav-text">coarse
injection，它是先对视频特征进行一个LN，之后要对它scale并shift。而scale和shift的量则是由单个的指令token
\(C_{p}\)
通过一个MLP回归得到（似乎可以认为，是类似于常见的想法，把mean和std视为内容风格的一种表征。这里通过由指令来影响视频token的mean和std，从而影响了视频内容，做到让指令控制视频内容，也就是指令注入）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fine-injection%E5%AE%83%E6%8B%BF%E5%88%B0%E7%9A%84%E6%9D%A1%E4%BB%B6%E4%B8%8D%E6%98%AF%E6%8C%87%E4%BB%A4%E7%BB%8F%E8%BF%87pooling%E5%90%8E%E7%9A%84%E4%B8%80%E4%B8%AAtoken%E8%80%8C%E6%98%AF%E5%8E%9F%E6%9D%A5%E7%9A%84token%E5%BA%8F%E5%88%97c_fin-rltimes-d%E8%BF%99%E9%87%8C%E6%8A%8A%E6%8C%87%E4%BB%A4%E6%9D%A1%E4%BB%B6%E6%B3%A8%E5%85%A5%E5%88%B0%E8%A7%86%E9%A2%91%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%E6%98%AF%E9%80%9A%E8%BF%87%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%E6%98%AFinjacattnlnac_fc_f"><span class="nav-number">2.6.3.4.</span> <span class="nav-text">fine
injection，它拿到的条件不是指令经过pooling后的一个token，而是原来的token序列\(C_{f}\in R^{L\times
D}\)。这里把指令条件注入到视频中的方法是通过注意力机制，具体来说是\(Inj(A,C)&#x3D;Attn(LN(A),C_{f},C_{f})\)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#conditional-pre-training-stage"><span class="nav-number">2.6.4.</span> <span class="nav-text">Conditional Pre-training
Stage</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A6%96%E5%85%88alignment-stage%E5%AE%83%E7%B1%BB%E4%BC%BC%E4%BA%8Ellm%E7%9A%84pre-training%E9%98%B6%E6%AE%B5%E5%8F%AF%E4%BB%A5%E8%AE%A4%E4%B8%BA%E7%9B%AE%E7%9A%84%E6%98%AF%E8%AE%A9mllms%E5%85%B7%E6%9C%89%E5%88%9D%E6%AD%A5%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9A%84%E8%83%BD%E5%8A%9B%E8%BF%99%E4%B8%AA%E9%98%B6%E6%AE%B5%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%9B%BE%E5%83%8F-%E6%96%87%E6%9C%AC%E5%AF%B9%E6%95%B0%E6%8D%AE%E6%9D%A5%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8E%E8%80%8C%E8%AE%A9%E8%A7%86%E8%A7%89%E7%BC%96%E7%A0%81%E5%99%A8%E8%BE%93%E5%87%BA%E7%9A%84%E7%89%B9%E5%BE%81%E5%8F%AF%E4%BB%A5%E8%A2%AB%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%90%86%E8%A7%A3%E4%B8%BA%E7%9A%84%E6%98%AF%E8%AE%A9%E8%A7%86%E8%A7%89token%E5%92%8C%E8%AF%AD%E8%A8%80token%E5%9C%A8%E5%90%8C%E4%B8%80%E4%B8%AA%E7%A9%BA%E9%97%B4%E9%87%8C%E5%BB%BA%E7%AB%8B%E8%B7%A8%E6%A8%A1%E6%80%81%E7%9A%84%E7%BB%9F%E4%B8%80%E8%A1%A8%E7%A4%BA%E4%B9%9F%E5%9B%A0%E6%AD%A4%E6%95%B0%E6%8D%AE%E9%87%8C%E6%98%AF%E4%B8%8D%E5%8C%85%E5%90%AB%E6%98%BE%E5%BC%8F%E6%8C%87%E4%BB%A4%E7%9A%84%E6%95%85%E6%AD%A4%E6%97%B6%E7%9A%84mllms%E5%AF%B9%E6%8C%87%E4%BB%A4%E7%9A%84%E7%90%86%E8%A7%A3%E5%92%8C%E9%81%B5%E4%BB%8E%E8%BF%98%E4%B8%8D%E5%A4%9F%E5%A5%BD%E9%9C%80%E8%A6%81%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%9A%84instruction-tuning-stage"><span class="nav-number">2.6.4.1.</span> <span class="nav-text">首先，Alignment
Stage，它类似于llm的pre-training阶段，可以认为目的是让MLLMs具有初步的、基础的能力。这个阶段会使用图像-文本对数据来训练模型，从而让视觉编码器输出的特征可以被语言模型理解，为的是让视觉token和语言token在同一个空间里，建立跨模态的统一表示。也因此，数据里是不包含显式指令的（故此时的MLLMs对指令的理解和遵从还不够好，需要进一步的Instruction
Tuning Stage）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%80%8Cinstruction-tuning-stage%E5%AE%83%E7%9A%84%E7%9B%AE%E7%9A%84%E5%B0%B1%E6%98%AF%E8%AE%A9%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%BC%9A%E9%81%B5%E5%BE%AA%E7%94%A8%E6%88%B7%E6%8C%87%E4%BB%A4%E5%AE%8C%E6%88%90%E5%85%B7%E4%BD%93%E4%BB%BB%E5%8A%A1%E6%AF%94%E5%A6%82%E8%A7%86%E9%A2%91%E9%97%AE%E7%AD%94%E6%8E%A8%E7%90%86%E6%AD%A4%E6%97%B6%E7%94%A8%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E5%B0%B1%E6%98%AF%E6%8C%87%E4%BB%A4-%E5%9B%9E%E7%AD%94%E5%AF%B9%E6%95%B0%E6%8D%AE"><span class="nav-number">2.6.4.2.</span> <span class="nav-text">而Instruction
Tuning
Stage，它的目的就是让模型学会遵循用户指令，完成具体任务（比如视频问答、推理）。此时用到的数据就是指令-回答对数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%86%E5%85%B3%E4%BA%8E%E8%AE%BA%E6%96%87%E9%87%8C%E6%8F%90%E5%88%B0%E7%9A%84%E5%8A%A0%E5%85%A5conditional-pre-training-stage%E7%9A%84%E5%8E%9F%E5%9B%A0%E4%B8%AA%E4%BA%BA%E7%90%86%E8%A7%A3%E6%98%AF%E8%BF%99%E6%A0%B7%E7%9A%84%E4%BC%A0%E7%BB%9F%E8%8C%83%E5%BC%8F%E9%87%8C%E6%98%AF%E4%B8%A4%E4%B8%AA%E9%98%B6%E6%AE%B5%E8%80%8C%E8%AE%BA%E6%96%87%E6%AD%A4%E5%89%8D%E6%8F%90%E5%87%BA%E7%9A%84%E6%8A%80%E6%9C%AF%E4%B8%BB%E8%A6%81%E6%98%AF%E4%B8%BA%E4%BA%86%E5%8E%8B%E7%BC%A9%E8%A7%86%E9%A2%91%E7%9A%84%E5%86%85%E5%AE%B9%E7%AE%80%E5%8D%95%E8%AF%B4%E5%B0%B1%E6%98%AF%E6%8A%8A%E8%A7%86%E9%A2%91%E5%AF%B9%E5%BA%94%E7%9A%84token%E6%95%B0%E9%87%8F%E5%87%8F%E5%B0%91%E5%85%B6%E4%BD%99%E5%9C%B0%E6%96%B9%E6%98%AF%E4%B8%8D%E5%8F%98%E7%9A%84%E4%BD%86%E5%9B%A0%E4%B8%BA%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%97%B6%E5%80%99%E6%98%AF%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E4%BC%9A%E6%8A%8A%E6%8C%87%E4%BB%A4%E7%BB%99%E5%BD%93%E4%BD%9C%E6%9D%A1%E4%BB%B6%E6%B3%A8%E5%85%A5%E5%85%B6%E4%B8%AD%E5%A6%82%E6%9E%9C%E6%A8%A1%E5%9E%8B%E6%AD%A4%E6%97%B6%E7%9A%84%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%E8%BF%98%E4%B8%8D%E5%A4%9F%E5%A5%BD%E9%82%A3%E4%B9%88%E6%8A%8A%E6%8C%87%E4%BB%A4%E6%B3%A8%E5%85%A5%E4%B9%8B%E5%90%8E%E6%95%88%E6%9E%9C%E5%8F%AF%E8%83%BD%E5%B9%B6%E4%B8%8D%E5%A5%BD%E8%BF%99%E4%B8%80%E7%82%B9%E6%8E%A8%E6%B5%8B%E5%8F%AF%E8%83%BD%E6%98%AF%E5%AE%9E%E9%AA%8C%E4%B8%AD%E5%8F%91%E7%8E%B0%E4%BA%86%E8%BF%99%E4%B8%AA%E7%8E%B0%E8%B1%A1%E8%80%8C%E5%90%8E%E5%BD%92%E7%BA%B3%E5%87%BA%E8%BF%99%E4%B8%AA%E5%8E%9F%E5%9B%A0%E7%84%B6%E8%80%8C%E4%B8%80%E8%88%AC%E7%9A%84%E6%B5%81%E7%A8%8B%E9%87%8C%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%E6%A8%A1%E5%9E%8B%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E6%95%88%E6%9E%9C%E4%B8%8D%E5%A5%BD%E7%9A%84%E9%97%AE%E9%A2%98%E5%B0%B1%E4%BC%9A%E8%BF%9B%E8%A1%8Cinstruction-tuning%E6%89%80%E4%BB%A5%E7%8E%B0%E5%9C%A8%E6%9C%89%E7%82%B9%E5%8D%A1%E5%9C%A8%E8%BF%99%E4%BA%86%E6%AD%A3%E5%B8%B8%E7%9A%84alignment-stage%E7%BB%93%E6%9D%9F%E5%90%8E%E9%9C%80%E8%A6%81%E8%BF%9B%E8%A1%8Cinstruction-tuning%E6%9D%A5%E5%A2%9E%E5%BC%BA%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%E4%BD%86%E5%9B%A0%E4%B8%BA%E8%AE%BA%E6%96%87%E7%9A%84%E6%96%B9%E6%B3%95%E6%98%AF%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E5%AF%B9%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E6%9C%89%E6%9B%B4%E9%AB%98%E7%9A%84%E8%A6%81%E6%B1%82%E6%89%80%E4%BB%A5alignment%E5%90%8E%E7%9B%B4%E6%8E%A5%E8%BF%9B%E8%A1%8Cinstruction-tuning%E5%9C%A8%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%97%B6%E5%80%99%E6%95%88%E6%9E%9C%E4%BC%9A%E4%B8%8D%E5%A5%BD%E4%B8%BA%E6%AD%A4%E6%88%91%E4%BB%AC%E9%9C%80%E8%A6%81%E6%8F%90%E9%AB%98%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%E4%BD%86%E6%8F%90%E9%AB%98%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%A1%88%E5%8F%88%E6%98%AF%E8%BF%9B%E8%A1%8Cinstruction-tuning-%E6%89%80%E4%BB%A5%E8%AE%BA%E6%96%87%E7%9B%B4%E6%8E%A5%E8%B7%B3%E5%87%BA%E6%9D%A5%E5%9C%A8instruction-tuning%E5%89%8D%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E5%89%8D%E7%BD%AEstage%E5%85%88%E7%A8%8D%E5%BE%AE%E6%8A%8A%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E6%97%B6%E7%9A%84%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%E6%8F%90%E9%AB%98%E4%B8%80%E4%BA%9B%E8%BF%99%E9%87%8C%E4%B8%8D%E5%83%8Finstruction-tuning-stage%E4%BC%9A%E5%AF%B9llm%E4%B9%9F%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83%E8%BF%99%E4%B8%AA%E9%98%B6%E6%AE%B5%E6%88%91%E4%BB%AC%E5%8F%AA%E5%BE%AE%E8%B0%83%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E7%9B%B8%E5%85%B3%E7%9A%84%E9%83%A8%E5%88%86%E6%8F%90%E9%AB%98%E9%82%A3%E4%BA%9B%E6%A8%A1%E5%9D%97%E9%87%8C%E6%8C%87%E4%BB%A4%E6%B3%A8%E5%85%A5%E7%9A%84%E6%95%88%E6%9E%9C%E8%BF%99%E6%A0%B7%E5%90%8E%E9%9D%A2%E5%88%B0%E4%BA%86instruction-tuning-stage%E6%97%B6%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E4%B9%9F%E8%83%BD%E5%81%9A%E5%BE%97%E6%AF%94%E8%BE%83%E5%A5%BD%E4%BA%86%E4%B8%8D%E7%94%A8%E6%8B%85%E5%BF%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%E8%BF%87%E5%B7%AE%E5%AF%BC%E8%87%B4%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E6%95%88%E6%9E%9C%E4%B8%8D%E5%A5%BD"><span class="nav-number">2.6.4.3.</span> <span class="nav-text">但关于论文里提到的，加入Conditional
Pre-training
Stage的原因，个人理解是这样的：传统范式里是两个阶段。而论文此前提出的技术，主要是为了压缩视频的内容，简单说就是把视频对应的token数量减少。其余地方是不变的。但因为压缩的时候是条件压缩，会把指令给当作条件注入其中，如果模型此时的指令遵循能力还不够好，那么把指令注入之后，效果可能并不好（这一点推测可能是实验中发现了这个现象，而后归纳出这个原因）。然而一般的流程里，为了解决模型指令遵循效果不好的问题，就会进行Instruction
Tuning。所以现在有点卡在这了：正常的Alignment
Stage结束后，需要进行Instruction
Tuning来增强模型的指令遵循能力；但因为论文的方法是条件压缩，对指令遵循有更高的要求，所以Alignment后直接进行Instruction
Tuning，在压缩的时候效果会不好；为此我们需要提高指令遵循能力，但提高指令遵循能力，传统方案又是进行Instruction
Tuning……所以，论文直接跳出来，在Instruction
Tuning前增加一个前置stage，先稍微把条件压缩时的指令遵循能力提高一些（这里不像Instruction
Tuning
Stage，会对llm也进行微调；这个阶段我们只微调条件压缩相关的部分，提高那些模块里指令注入的效果。这样，后面到了Instruction
Tuning
Stage时，条件压缩也能做得比较好了，不用担心模型的指令遵循能力过差导致的条件压缩效果不好）</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">bluemouse</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">182</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">53</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">100</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bluemouse</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
