<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueeemouse.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="abstract现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进行权衡">
<meta property="og:type" content="article">
<meta property="og:title" content="Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models">
<meta property="og:url" content="https://blueeemouse.github.io/2025/06/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/Hybrid-Level%20Instruction%20Injection%20for%20Video%20Token%20Compression%20in%20Multi-modal%20Large%20Language%20Models/index.html">
<meta property="og:site_name" content="bluemouse&#39;s blog">
<meta property="og:description" content="abstract现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进行权衡">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-06-11T15:50:00.000Z">
<meta property="article:modified_time" content="2025-06-12T02:23:18.121Z">
<meta property="article:author" content="bluemouse">
<meta property="article:tag" content="MLLM">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueeemouse.github.io/2025/06/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/Hybrid-Level%20Instruction%20Injection%20for%20Video%20Token%20Compression%20in%20Multi-modal%20Large%20Language%20Models/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models | bluemouse's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">bluemouse's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/06/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/Hybrid-Level%20Instruction%20Injection%20for%20Video%20Token%20Compression%20in%20Multi-modal%20Large%20Language%20Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-06-11 23:50:00" itemprop="dateCreated datePublished" datetime="2025-06-11T23:50:00+08:00">2025-06-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-06-12 10:23:18" itemprop="dateModified" datetime="2025-06-12T10:23:18+08:00">2025-06-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h1><h2 id="现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual-tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进行权衡，无法同时做得比较好）"><a href="#现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual-tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进行权衡，无法同时做得比较好）" class="headerlink" title="现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进行权衡，无法同时做得比较好）"></a>现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进行权衡，无法同时做得比较好）</h2><h2 id="为了解决这个问题，论文是从压缩策略上入手。其大体思路是：把用户的指令作为条件，进行条件压缩。这样，既能对视频内容进行压缩，减少计算开销；同时又因为用了指令作为条件，则会对重要的视频内容做更多保留，因此视频信息的损失会更少"><a href="#为了解决这个问题，论文是从压缩策略上入手。其大体思路是：把用户的指令作为条件，进行条件压缩。这样，既能对视频内容进行压缩，减少计算开销；同时又因为用了指令作为条件，则会对重要的视频内容做更多保留，因此视频信息的损失会更少" class="headerlink" title="为了解决这个问题，论文是从压缩策略上入手。其大体思路是：把用户的指令作为条件，进行条件压缩。这样，既能对视频内容进行压缩，减少计算开销；同时又因为用了指令作为条件，则会对重要的视频内容做更多保留，因此视频信息的损失会更少"></a>为了解决这个问题，论文是从压缩策略上入手。其大体思路是：把用户的指令作为条件，进行条件压缩。这样，既能对视频内容进行压缩，减少计算开销；同时又因为用了指令作为条件，则会对重要的视频内容做更多保留，因此视频信息的损失会更少</h2><span id="more"></span>
<h1 id="method"><a href="#method" class="headerlink" title="method"></a>method</h1><h2 id="主要是三个部件，或者说三个技巧：Local-Level-Compression，Global-Level-Compression，Instruction-Condition-Injection。最后，论文在训练的范式上也作出创新，增加了一个stage，即Conditional-Pre-training-Stage"><a href="#主要是三个部件，或者说三个技巧：Local-Level-Compression，Global-Level-Compression，Instruction-Condition-Injection。最后，论文在训练的范式上也作出创新，增加了一个stage，即Conditional-Pre-training-Stage" class="headerlink" title="主要是三个部件，或者说三个技巧：Local-Level Compression，Global-Level Compression，Instruction Condition Injection。最后，论文在训练的范式上也作出创新，增加了一个stage，即Conditional Pre-training Stage"></a>主要是三个部件，或者说三个技巧：Local-Level Compression，Global-Level Compression，Instruction Condition Injection。最后，论文在训练的范式上也作出创新，增加了一个stage，即Conditional Pre-training Stage</h2><h2 id="Local-Level-Compression，它是把视频输入给分成若干个group，在每个group里用注意力机制提取细节信息（包括了指令信息的注入）。而条件压缩就体现在会把每个group压缩到一个token，且这个token是通过注意力机制得到的，这个过程中，注入了指令条件"><a href="#Local-Level-Compression，它是把视频输入给分成若干个group，在每个group里用注意力机制提取细节信息（包括了指令信息的注入）。而条件压缩就体现在会把每个group压缩到一个token，且这个token是通过注意力机制得到的，这个过程中，注入了指令条件" class="headerlink" title="Local-Level Compression，它是把视频输入给分成若干个group，在每个group里用注意力机制提取细节信息（包括了指令信息的注入）。而条件压缩就体现在会把每个group压缩到一个token，且这个token是通过注意力机制得到的，这个过程中，注入了指令条件"></a>Local-Level Compression，它是把视频输入给分成若干个group，在每个group里用注意力机制提取细节信息（包括了指令信息的注入）。而条件压缩就体现在会把每个group压缩到一个token，且这个token是通过注意力机制得到的，这个过程中，注入了指令条件</h2><h2 id="Global-Level-Compression，它则是作为和Local-Level-Compression互补的部分出现的。Local-Level-Compression是在组内进行压缩和注意力机制，此时只能得到零散的局部信息（因为都是在组内的操作）。我们希望全局也可以压缩，并且还要尽可能遵从指令。所以，论文会预设一组learnable-tokens-L-in-R-N-L-times-D-，我们会往它里面注入条件指令信息，之后它会和视频进行交互（用注意力机制），最终输出的结果的token数也是-N-L-，而这是一个超参数，由我们指定，所以可以定得相对小一些，从而实现压缩效果"><a href="#Global-Level-Compression，它则是作为和Local-Level-Compression互补的部分出现的。Local-Level-Compression是在组内进行压缩和注意力机制，此时只能得到零散的局部信息（因为都是在组内的操作）。我们希望全局也可以压缩，并且还要尽可能遵从指令。所以，论文会预设一组learnable-tokens-L-in-R-N-L-times-D-，我们会往它里面注入条件指令信息，之后它会和视频进行交互（用注意力机制），最终输出的结果的token数也是-N-L-，而这是一个超参数，由我们指定，所以可以定得相对小一些，从而实现压缩效果" class="headerlink" title="Global-Level Compression，它则是作为和Local-Level Compression互补的部分出现的。Local-Level Compression是在组内进行压缩和注意力机制，此时只能得到零散的局部信息（因为都是在组内的操作）。我们希望全局也可以压缩，并且还要尽可能遵从指令。所以，论文会预设一组learnable tokens $L\in R^{N_{L}\times D}$ ，我们会往它里面注入条件指令信息，之后它会和视频进行交互（用注意力机制），最终输出的结果的token数也是$N_{L}$，而这是一个超参数，由我们指定，所以可以定得相对小一些，从而实现压缩效果"></a>Global-Level Compression，它则是作为和Local-Level Compression互补的部分出现的。Local-Level Compression是在组内进行压缩和注意力机制，此时只能得到零散的局部信息（因为都是在组内的操作）。我们希望全局也可以压缩，并且还要尽可能遵从指令。所以，论文会预设一组learnable tokens $L\in R^{N_{L}\times D}$ ，我们会往它里面注入条件指令信息，之后它会和视频进行交互（用注意力机制），最终输出的结果的token数也是$N_{L}$，而这是一个超参数，由我们指定，所以可以定得相对小一些，从而实现压缩效果</h2><h2 id="Instruction-Condition-Injection，论文里提出分三种，direct-injection，coarse-injection，fine-injection。大体上，感觉计算的细节并不是特别新颖，也很难说有特别扎实的理论支撑，似乎都是比较常见-眼熟的操作。论文亮点应该并不在于这里的技术细节，而是在于发现了问题（视频处理计算开销大—-压缩效果又不够好—-可以提出新的条件压缩来解决），以及它提出的条件压缩的解决思路"><a href="#Instruction-Condition-Injection，论文里提出分三种，direct-injection，coarse-injection，fine-injection。大体上，感觉计算的细节并不是特别新颖，也很难说有特别扎实的理论支撑，似乎都是比较常见-眼熟的操作。论文亮点应该并不在于这里的技术细节，而是在于发现了问题（视频处理计算开销大—-压缩效果又不够好—-可以提出新的条件压缩来解决），以及它提出的条件压缩的解决思路" class="headerlink" title="Instruction Condition Injection，论文里提出分三种，direct injection，coarse injection，fine injection。大体上，感觉计算的细节并不是特别新颖，也很难说有特别扎实的理论支撑，似乎都是比较常见&#x2F;眼熟的操作。论文亮点应该并不在于这里的技术细节，而是在于发现了问题（视频处理计算开销大—&gt;压缩效果又不够好—&gt;可以提出新的条件压缩来解决），以及它提出的条件压缩的解决思路"></a>Instruction Condition Injection，论文里提出分三种，direct injection，coarse injection，fine injection。大体上，感觉计算的细节并不是特别新颖，也很难说有特别扎实的理论支撑，似乎都是比较常见&#x2F;眼熟的操作。论文亮点应该并不在于这里的技术细节，而是在于发现了问题（视频处理计算开销大—&gt;压缩效果又不够好—&gt;可以提出新的条件压缩来解决），以及它提出的条件压缩的解决思路</h2><h2 id="Conditional-Pre-training-Stage，是MLLMs训练范式中新增加的一个stage。传统的MLLMs训练依次是两个stage：Alignment-Stage、Instruction-Tuning-Stage，而论文则提出在中间加入一个stage，Conditions-Pre-training-Stage，这样可以让训练更加流畅"><a href="#Conditional-Pre-training-Stage，是MLLMs训练范式中新增加的一个stage。传统的MLLMs训练依次是两个stage：Alignment-Stage、Instruction-Tuning-Stage，而论文则提出在中间加入一个stage，Conditions-Pre-training-Stage，这样可以让训练更加流畅" class="headerlink" title="Conditional Pre-training Stage，是MLLMs训练范式中新增加的一个stage。传统的MLLMs训练依次是两个stage：Alignment Stage、Instruction Tuning Stage，而论文则提出在中间加入一个stage，Conditions Pre-training Stage，这样可以让训练更加流畅"></a>Conditional Pre-training Stage，是MLLMs训练范式中新增加的一个stage。传统的MLLMs训练依次是两个stage：Alignment Stage、Instruction Tuning Stage，而论文则提出在中间加入一个stage，Conditions Pre-training Stage，这样可以让训练更加流畅</h2><h2 id="下面讲一下技术细节吧："><a href="#下面讲一下技术细节吧：" class="headerlink" title="下面讲一下技术细节吧："></a>下面讲一下技术细节吧：</h2><h3 id="Local-Level-Compression"><a href="#Local-Level-Compression" class="headerlink" title="Local-Level Compression"></a>Local-Level Compression</h3><h4 id="这里首先涉及到具体是怎么分组的。又得谈到视频输入处理后的形状，一般是-T-H-W-D-，其中T代表时间帧数，-H-times-W-是空间尺寸，D是特征维度（视频其实是被视为图像序列来处理的。这样看，T其实可以认为是图像的数量）-压缩时，有个压缩比-alpha-T-alpha-H-alpha-W-，可以从下标看出来分别代表了T、H、W维度上的压缩比。具体的，我们会在T维度上进行划分，分成-frac-T-alpha-T-N-T-块，在H和W维度也是类似计算。最终可以得到-N-T-times-N-H-times-N-W-个组。分好组后，我们的压缩会把一个组里的所有token（可以算出，有-alpha-T-times-alpha-H-times-alpha-W-个token）压缩成一个token。此时我们再来看这个分组的方式，它沿着时间维度（T）和空间维度（H、W）都有分组，因此一定程度上保留了原来输入的时空结构"><a href="#这里首先涉及到具体是怎么分组的。又得谈到视频输入处理后的形状，一般是-T-H-W-D-，其中T代表时间帧数，-H-times-W-是空间尺寸，D是特征维度（视频其实是被视为图像序列来处理的。这样看，T其实可以认为是图像的数量）-压缩时，有个压缩比-alpha-T-alpha-H-alpha-W-，可以从下标看出来分别代表了T、H、W维度上的压缩比。具体的，我们会在T维度上进行划分，分成-frac-T-alpha-T-N-T-块，在H和W维度也是类似计算。最终可以得到-N-T-times-N-H-times-N-W-个组。分好组后，我们的压缩会把一个组里的所有token（可以算出，有-alpha-T-times-alpha-H-times-alpha-W-个token）压缩成一个token。此时我们再来看这个分组的方式，它沿着时间维度（T）和空间维度（H、W）都有分组，因此一定程度上保留了原来输入的时空结构" class="headerlink" title="这里首先涉及到具体是怎么分组的。又得谈到视频输入处理后的形状，一般是$(T,H,W,D)$，其中T代表时间帧数，$H\times W$是空间尺寸，D是特征维度（视频其实是被视为图像序列来处理的。这样看，T其实可以认为是图像的数量）&#x3D;压缩时，有个压缩比$(\alpha_{T},\alpha_{H},\alpha_{W})$，可以从下标看出来分别代表了T、H、W维度上的压缩比。具体的，我们会在T维度上进行划分，分成$\frac{T}{\alpha_{T}}&#x3D;N_{T}$ 块，在H和W维度也是类似计算。最终可以得到$N_{T}\times N_{H}\times N_{W}$个组。分好组后，我们的压缩会把一个组里的所有token（可以算出，有$\alpha_{T}\times \alpha_{H}\times \alpha_{W}$ 个token）压缩成一个token。此时我们再来看这个分组的方式，它沿着时间维度（T）和空间维度（H、W）都有分组，因此一定程度上保留了原来输入的时空结构"></a>这里首先涉及到具体是怎么分组的。又得谈到视频输入处理后的形状，一般是$(T,H,W,D)$，其中T代表时间帧数，$H\times W$是空间尺寸，D是特征维度（视频其实是被视为图像序列来处理的。这样看，T其实可以认为是图像的数量）&#x3D;<br>压缩时，有个压缩比$(\alpha_{T},\alpha_{H},\alpha_{W})$，可以从下标看出来分别代表了T、H、W维度上的压缩比。具体的，我们会在T维度上进行划分，分成$\frac{T}{\alpha_{T}}&#x3D;N_{T}$ 块，在H和W维度也是类似计算。最终可以得到$N_{T}\times N_{H}\times N_{W}$个组。分好组后，我们的压缩会把一个组里的所有token（可以算出，有$\alpha_{T}\times \alpha_{H}\times \alpha_{W}$ 个token）压缩成一个token。此时我们再来看这个分组的方式，它沿着时间维度（T）和空间维度（H、W）都有分组，因此一定程度上保留了原来输入的时空结构</h4><h3 id="Global-Level-Compression"><a href="#Global-Level-Compression" class="headerlink" title="Global-Level Compression"></a>Global-Level Compression</h3><h3 id="Instruction-Condition-Injection"><a href="#Instruction-Condition-Injection" class="headerlink" title="Instruction Condition Injection"></a>Instruction Condition Injection</h3><h4 id="direct-injection，它就是直接把文本指令的pooling后的token，记为-C-p-（也就是单个token），用一个MLP直接映射到视频特征的空间。也即，-Inj-A-C-MLP-C-（这里可能容易造成困惑的点在于，看起来这里就没用到A（也即可学习的token）了。事实上也是可以的（某些场景下）。因为我们注入指令，本质就是希望把指令作为条件，加入到信息提取的过程中，从而让结果更加符合指令。不管是local还是global-compression，最终都是用一个注意力机制来交互提取信息。query部分只要有包含指令条件就行（这里理论上说，query里没有视频信息也是可以的，毕竟query是要和key交互的，而key里是有视频信息的；以及最后和value进行加权得到结果，value也是视频信息。只不过容易想到，这个direct-injection对视频信息的利用还是不够。粒度应该是三种injection中最粗糙的）"><a href="#direct-injection，它就是直接把文本指令的pooling后的token，记为-C-p-（也就是单个token），用一个MLP直接映射到视频特征的空间。也即，-Inj-A-C-MLP-C-（这里可能容易造成困惑的点在于，看起来这里就没用到A（也即可学习的token）了。事实上也是可以的（某些场景下）。因为我们注入指令，本质就是希望把指令作为条件，加入到信息提取的过程中，从而让结果更加符合指令。不管是local还是global-compression，最终都是用一个注意力机制来交互提取信息。query部分只要有包含指令条件就行（这里理论上说，query里没有视频信息也是可以的，毕竟query是要和key交互的，而key里是有视频信息的；以及最后和value进行加权得到结果，value也是视频信息。只不过容易想到，这个direct-injection对视频信息的利用还是不够。粒度应该是三种injection中最粗糙的）" class="headerlink" title="direct injection，它就是直接把文本指令的pooling后的token，记为$C_{p}$（也就是单个token），用一个MLP直接映射到视频特征的空间。也即，$Inj(A,C)&#x3D;MLP(C)$（这里可能容易造成困惑的点在于，看起来这里就没用到A（也即可学习的token）了。事实上也是可以的（某些场景下）。因为我们注入指令，本质就是希望把指令作为条件，加入到信息提取的过程中，从而让结果更加符合指令。不管是local还是global compression，最终都是用一个注意力机制来交互提取信息。query部分只要有包含指令条件就行（这里理论上说，query里没有视频信息也是可以的，毕竟query是要和key交互的，而key里是有视频信息的；以及最后和value进行加权得到结果，value也是视频信息。只不过容易想到，这个direct injection对视频信息的利用还是不够。粒度应该是三种injection中最粗糙的）"></a>direct injection，它就是直接把文本指令的pooling后的token，记为$C_{p}$（也就是单个token），用一个MLP直接映射到视频特征的空间。也即，$Inj(A,C)&#x3D;MLP(C)$（这里可能容易造成困惑的点在于，看起来这里就没用到A（也即可学习的token）了。事实上也是可以的（某些场景下）。因为我们注入指令，本质就是希望把指令作为条件，加入到信息提取的过程中，从而让结果更加符合指令。不管是local还是global compression，最终都是用一个注意力机制来交互提取信息。query部分只要有包含指令条件就行（这里理论上说，query里没有视频信息也是可以的，毕竟query是要和key交互的，而key里是有视频信息的；以及最后和value进行加权得到结果，value也是视频信息。只不过容易想到，这个direct injection对视频信息的利用还是不够。粒度应该是三种injection中最粗糙的）</h4><h4 id="至于coarse和fine-injection，简单说，它们一个类似于adaIn，一个基本就是用了cross-attention而已。嗯。跟一开始猜的八九不离十吧。"><a href="#至于coarse和fine-injection，简单说，它们一个类似于adaIn，一个基本就是用了cross-attention而已。嗯。跟一开始猜的八九不离十吧。" class="headerlink" title="至于coarse和fine injection，简单说，它们一个类似于adaIn，一个基本就是用了cross attention而已。嗯。跟一开始猜的八九不离十吧。"></a>至于coarse和fine injection，简单说，它们一个类似于adaIn，一个基本就是用了cross attention而已。嗯。跟一开始猜的八九不离十吧。</h4><h4 id="coarse-injection，它是先对视频特征进行一个LN，之后要对它scale并shift。而scale和shift的量则是由单个的指令token-C-p-通过一个MLP回归得到（似乎可以认为，是类似于常见的想法，把mean和std视为内容风格的一种表征。这里通过由指令来影响视频token的mean和std，从而影响了视频内容，做到让指令控制视频内容，也就是指令注入）"><a href="#coarse-injection，它是先对视频特征进行一个LN，之后要对它scale并shift。而scale和shift的量则是由单个的指令token-C-p-通过一个MLP回归得到（似乎可以认为，是类似于常见的想法，把mean和std视为内容风格的一种表征。这里通过由指令来影响视频token的mean和std，从而影响了视频内容，做到让指令控制视频内容，也就是指令注入）" class="headerlink" title="coarse injection，它是先对视频特征进行一个LN，之后要对它scale并shift。而scale和shift的量则是由单个的指令token $C_{p}$ 通过一个MLP回归得到（似乎可以认为，是类似于常见的想法，把mean和std视为内容风格的一种表征。这里通过由指令来影响视频token的mean和std，从而影响了视频内容，做到让指令控制视频内容，也就是指令注入）"></a>coarse injection，它是先对视频特征进行一个LN，之后要对它scale并shift。而scale和shift的量则是由单个的指令token $C_{p}$ 通过一个MLP回归得到（似乎可以认为，是类似于常见的想法，把mean和std视为内容风格的一种表征。这里通过由指令来影响视频token的mean和std，从而影响了视频内容，做到让指令控制视频内容，也就是指令注入）</h4><h4 id="fine-injection，它拿到的条件不是指令经过pooling后的一个token，而是原来的token序列-C-f-in-R-L-times-D-。这里把指令条件注入到视频中的方法是通过注意力机制，具体来说是-Inj-A-C-Attn-LN-A-C-f-C-f"><a href="#fine-injection，它拿到的条件不是指令经过pooling后的一个token，而是原来的token序列-C-f-in-R-L-times-D-。这里把指令条件注入到视频中的方法是通过注意力机制，具体来说是-Inj-A-C-Attn-LN-A-C-f-C-f" class="headerlink" title="fine injection，它拿到的条件不是指令经过pooling后的一个token，而是原来的token序列$C_{f}\in R^{L\times D}$。这里把指令条件注入到视频中的方法是通过注意力机制，具体来说是$Inj(A,C)&#x3D;Attn(LN(A),C_{f},C_{f})$"></a>fine injection，它拿到的条件不是指令经过pooling后的一个token，而是原来的token序列$C_{f}\in R^{L\times D}$。这里把指令条件注入到视频中的方法是通过注意力机制，具体来说是$Inj(A,C)&#x3D;Attn(LN(A),C_{f},C_{f})$</h4><h3 id="Conditional-Pre-training-Stage"><a href="#Conditional-Pre-training-Stage" class="headerlink" title="Conditional Pre-training Stage"></a>Conditional Pre-training Stage</h3><h4 id="首先，Alignment-Stage，它类似于llm的pre-training阶段，可以认为目的是让MLLMs具有初步的、基础的能力。这个阶段会使用图像-文本对数据来训练模型，从而让视觉编码器输出的特征可以被语言模型理解，为的是让视觉token和语言token在同一个空间里，建立跨模态的统一表示。也因此，数据里是不包含显式指令的（故此时的MLLMs对指令的理解和遵从还不够好，需要进一步的Instruction-Tuning-Stage）"><a href="#首先，Alignment-Stage，它类似于llm的pre-training阶段，可以认为目的是让MLLMs具有初步的、基础的能力。这个阶段会使用图像-文本对数据来训练模型，从而让视觉编码器输出的特征可以被语言模型理解，为的是让视觉token和语言token在同一个空间里，建立跨模态的统一表示。也因此，数据里是不包含显式指令的（故此时的MLLMs对指令的理解和遵从还不够好，需要进一步的Instruction-Tuning-Stage）" class="headerlink" title="首先，Alignment Stage，它类似于llm的pre-training阶段，可以认为目的是让MLLMs具有初步的、基础的能力。这个阶段会使用图像-文本对数据来训练模型，从而让视觉编码器输出的特征可以被语言模型理解，为的是让视觉token和语言token在同一个空间里，建立跨模态的统一表示。也因此，数据里是不包含显式指令的（故此时的MLLMs对指令的理解和遵从还不够好，需要进一步的Instruction Tuning Stage）"></a>首先，Alignment Stage，它类似于llm的pre-training阶段，可以认为目的是让MLLMs具有初步的、基础的能力。这个阶段会使用图像-文本对数据来训练模型，从而让视觉编码器输出的特征可以被语言模型理解，为的是让视觉token和语言token在同一个空间里，建立跨模态的统一表示。也因此，数据里是不包含显式指令的（故此时的MLLMs对指令的理解和遵从还不够好，需要进一步的Instruction Tuning Stage）</h4><h4 id="而Instruction-Tuning-Stage，它的目的就是让模型学会遵循用户指令，完成具体任务（比如视频问答、推理）。此时用到的数据就是指令-回答对数据"><a href="#而Instruction-Tuning-Stage，它的目的就是让模型学会遵循用户指令，完成具体任务（比如视频问答、推理）。此时用到的数据就是指令-回答对数据" class="headerlink" title="而Instruction Tuning Stage，它的目的就是让模型学会遵循用户指令，完成具体任务（比如视频问答、推理）。此时用到的数据就是指令-回答对数据"></a>而Instruction Tuning Stage，它的目的就是让模型学会遵循用户指令，完成具体任务（比如视频问答、推理）。此时用到的数据就是指令-回答对数据</h4><h4 id="但关于论文里提到的，加入Conditional-Pre-training-Stage的原因，个人理解是这样的：传统范式里是两个阶段。而论文此前提出的技术，主要是为了压缩视频的内容，简单说就是把视频对应的token数量减少。其余地方是不变的。但因为压缩的时候是条件压缩，会把指令给当作条件注入其中，如果模型此时的指令遵循能力还不够好，那么把指令注入之后，效果可能并不好（这一点推测可能是实验中发现了这个现象，而后归纳出这个原因）。然而一般的流程里，为了解决模型指令遵循效果不好的问题，就会进行Instruction-Tuning。所以现在有点卡在这了：正常的Alignment-Stage结束后，需要进行Instruction-Tuning来增强模型的指令遵循能力；但因为论文的方法是条件压缩，对指令遵循有更高的要求，所以Alignment后直接进行Instruction-Tuning，在压缩的时候效果会不好；为此我们需要提高指令遵循能力，但提高指令遵循能力，传统方案又是进行Instruction-Tuning……所以，论文直接跳出来，在Instruction-Tuning前增加一个前置stage，先稍微把条件压缩时的指令遵循能力提高一些（这里不像Instruction-Tuning-Stage，会对llm也进行微调；这个阶段我们只微调条件压缩相关的部分，提高那些模块里指令注入的效果。这样，后面到了Instruction-Tuning-Stage时，条件压缩也能做得比较好了，不用担心模型的指令遵循能力过差导致的条件压缩效果不好）"><a href="#但关于论文里提到的，加入Conditional-Pre-training-Stage的原因，个人理解是这样的：传统范式里是两个阶段。而论文此前提出的技术，主要是为了压缩视频的内容，简单说就是把视频对应的token数量减少。其余地方是不变的。但因为压缩的时候是条件压缩，会把指令给当作条件注入其中，如果模型此时的指令遵循能力还不够好，那么把指令注入之后，效果可能并不好（这一点推测可能是实验中发现了这个现象，而后归纳出这个原因）。然而一般的流程里，为了解决模型指令遵循效果不好的问题，就会进行Instruction-Tuning。所以现在有点卡在这了：正常的Alignment-Stage结束后，需要进行Instruction-Tuning来增强模型的指令遵循能力；但因为论文的方法是条件压缩，对指令遵循有更高的要求，所以Alignment后直接进行Instruction-Tuning，在压缩的时候效果会不好；为此我们需要提高指令遵循能力，但提高指令遵循能力，传统方案又是进行Instruction-Tuning……所以，论文直接跳出来，在Instruction-Tuning前增加一个前置stage，先稍微把条件压缩时的指令遵循能力提高一些（这里不像Instruction-Tuning-Stage，会对llm也进行微调；这个阶段我们只微调条件压缩相关的部分，提高那些模块里指令注入的效果。这样，后面到了Instruction-Tuning-Stage时，条件压缩也能做得比较好了，不用担心模型的指令遵循能力过差导致的条件压缩效果不好）" class="headerlink" title="但关于论文里提到的，加入Conditional Pre-training Stage的原因，个人理解是这样的：传统范式里是两个阶段。而论文此前提出的技术，主要是为了压缩视频的内容，简单说就是把视频对应的token数量减少。其余地方是不变的。但因为压缩的时候是条件压缩，会把指令给当作条件注入其中，如果模型此时的指令遵循能力还不够好，那么把指令注入之后，效果可能并不好（这一点推测可能是实验中发现了这个现象，而后归纳出这个原因）。然而一般的流程里，为了解决模型指令遵循效果不好的问题，就会进行Instruction Tuning。所以现在有点卡在这了：正常的Alignment Stage结束后，需要进行Instruction Tuning来增强模型的指令遵循能力；但因为论文的方法是条件压缩，对指令遵循有更高的要求，所以Alignment后直接进行Instruction Tuning，在压缩的时候效果会不好；为此我们需要提高指令遵循能力，但提高指令遵循能力，传统方案又是进行Instruction Tuning……所以，论文直接跳出来，在Instruction Tuning前增加一个前置stage，先稍微把条件压缩时的指令遵循能力提高一些（这里不像Instruction Tuning Stage，会对llm也进行微调；这个阶段我们只微调条件压缩相关的部分，提高那些模块里指令注入的效果。这样，后面到了Instruction Tuning Stage时，条件压缩也能做得比较好了，不用担心模型的指令遵循能力过差导致的条件压缩效果不好）"></a>但关于论文里提到的，加入Conditional Pre-training Stage的原因，个人理解是这样的：传统范式里是两个阶段。而论文此前提出的技术，主要是为了压缩视频的内容，简单说就是把视频对应的token数量减少。其余地方是不变的。但因为压缩的时候是条件压缩，会把指令给当作条件注入其中，如果模型此时的指令遵循能力还不够好，那么把指令注入之后，效果可能并不好（这一点推测可能是实验中发现了这个现象，而后归纳出这个原因）。然而一般的流程里，为了解决模型指令遵循效果不好的问题，就会进行Instruction Tuning。所以现在有点卡在这了：正常的Alignment Stage结束后，需要进行Instruction Tuning来增强模型的指令遵循能力；但因为论文的方法是条件压缩，对指令遵循有更高的要求，所以Alignment后直接进行Instruction Tuning，在压缩的时候效果会不好；为此我们需要提高指令遵循能力，但提高指令遵循能力，传统方案又是进行Instruction Tuning……<br>所以，论文直接跳出来，在Instruction Tuning前增加一个前置stage，先稍微把条件压缩时的指令遵循能力提高一些（这里不像Instruction Tuning Stage，会对llm也进行微调；这个阶段我们只微调条件压缩相关的部分，提高那些模块里指令注入的效果。这样，后面到了Instruction Tuning Stage时，条件压缩也能做得比较好了，不用担心模型的指令遵循能力过差导致的条件压缩效果不好）</h4>
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/MLLM/" rel="tag"># MLLM</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/06/11/algo/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/%E4%B8%8D%E5%AE%9A%E9%95%BF%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/%E5%92%8C%E7%9B%B8%E5%90%8C%E7%9A%84%E4%BA%8C%E5%85%83%E5%AD%90%E6%95%B0%E7%BB%84/" rel="prev" title="和相同的二元子数组">
      <i class="fa fa-chevron-left"></i> 和相同的二元子数组
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/06/12/algo/Leetcode-hot100/%E7%9F%A9%E9%98%B5/%E7%9F%A9%E9%98%B5%E7%BD%AE%E9%9B%B6/%E7%9F%A9%E9%98%B5%E7%BD%AE%E9%9B%B6/" rel="next" title="矩阵置零">
      矩阵置零 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#abstract"><span class="nav-number">1.</span> <span class="nav-text">abstract</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%B0%E5%9C%A8%E7%9A%84MLLMs%E5%9C%A8%E5%A4%84%E7%90%86%E8%A7%86%E9%A2%91%E8%BE%93%E5%85%A5%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%E6%98%AF%E8%AE%A1%E7%AE%97%E5%BC%80%E9%94%80%E5%A4%A7%EF%BC%88%E5%9B%A0%E4%B8%BA%E8%A7%86%E9%A2%91%E6%98%AF%E5%A4%9A%E5%B8%A7%E7%9A%84%EF%BC%8C%E9%80%9A%E5%B8%B8MLLMs%E9%9C%80%E8%A6%81%E6%8A%8A%E5%AE%83%E5%BD%93%E6%88%90%E5%9B%BE%E5%83%8F%E5%BA%8F%E5%88%97%E6%9D%A5%E5%A4%84%E7%90%86%E3%80%82%E5%9B%A0%E6%AD%A4%E4%BC%9A%E4%BA%A7%E7%94%9F%E5%BE%88%E5%A4%9Avisual-tokens%EF%BC%89%E3%80%82%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%8C%E4%B8%80%E4%B8%AA%E5%B8%B8%E8%A7%81%E7%9A%84%E7%AD%96%E7%95%A5%E6%98%AF%E8%BF%9B%E8%A1%8C%E5%8E%8B%E7%BC%A9%E3%80%82%E4%BD%86%E5%8E%8B%E7%BC%A9%E5%8F%88%E5%B8%A6%E6%9D%A5%E5%8F%A6%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%9A%E7%8E%B0%E5%9C%A8%E5%B8%B8%E8%A7%81%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%EF%BC%8C%E5%BF%BD%E8%A7%86%E4%BA%86%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E4%B8%8E%E6%8C%87%E4%BB%A4%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%EF%BC%8C%E5%AF%BC%E8%87%B4%E5%8E%8B%E7%BC%A9%E4%B9%8B%E5%90%8E%E5%AF%B9%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E7%9A%84%E7%90%86%E8%A7%A3%E6%9C%89%E7%BC%BA%E5%A4%B1%EF%BC%88%E6%8D%A2%E5%8F%A5%E8%AF%9D%E8%AF%B4%EF%BC%8C%E7%8E%B0%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98%E6%98%AF%EF%BC%8C%E4%BF%A1%E6%81%AF%E8%B4%A8%E9%87%8F%E5%92%8C%E8%AE%A1%E7%AE%97%E5%BC%80%E9%94%80%E4%B9%8B%E9%97%B4%E9%9C%80%E8%A6%81%E8%BF%9B%E8%A1%8C%E6%9D%83%E8%A1%A1%EF%BC%8C%E6%97%A0%E6%B3%95%E5%90%8C%E6%97%B6%E5%81%9A%E5%BE%97%E6%AF%94%E8%BE%83%E5%A5%BD%EF%BC%89"><span class="nav-number">1.1.</span> <span class="nav-text">现在的MLLMs在处理视频输入的时候，遇到的一个问题是计算开销大（因为视频是多帧的，通常MLLMs需要把它当成图像序列来处理。因此会产生很多visual tokens）。为了解决这个问题，一个常见的策略是进行压缩。但压缩又带来另一个问题：现在常见的压缩方法，忽视了视频内容与指令之间的关系，导致压缩之后对视频内容的理解有缺失（换句话说，现在的问题是，信息质量和计算开销之间需要进行权衡，无法同时做得比较好）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%8C%E8%AE%BA%E6%96%87%E6%98%AF%E4%BB%8E%E5%8E%8B%E7%BC%A9%E7%AD%96%E7%95%A5%E4%B8%8A%E5%85%A5%E6%89%8B%E3%80%82%E5%85%B6%E5%A4%A7%E4%BD%93%E6%80%9D%E8%B7%AF%E6%98%AF%EF%BC%9A%E6%8A%8A%E7%94%A8%E6%88%B7%E7%9A%84%E6%8C%87%E4%BB%A4%E4%BD%9C%E4%B8%BA%E6%9D%A1%E4%BB%B6%EF%BC%8C%E8%BF%9B%E8%A1%8C%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E3%80%82%E8%BF%99%E6%A0%B7%EF%BC%8C%E6%97%A2%E8%83%BD%E5%AF%B9%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E8%BF%9B%E8%A1%8C%E5%8E%8B%E7%BC%A9%EF%BC%8C%E5%87%8F%E5%B0%91%E8%AE%A1%E7%AE%97%E5%BC%80%E9%94%80%EF%BC%9B%E5%90%8C%E6%97%B6%E5%8F%88%E5%9B%A0%E4%B8%BA%E7%94%A8%E4%BA%86%E6%8C%87%E4%BB%A4%E4%BD%9C%E4%B8%BA%E6%9D%A1%E4%BB%B6%EF%BC%8C%E5%88%99%E4%BC%9A%E5%AF%B9%E9%87%8D%E8%A6%81%E7%9A%84%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E5%81%9A%E6%9B%B4%E5%A4%9A%E4%BF%9D%E7%95%99%EF%BC%8C%E5%9B%A0%E6%AD%A4%E8%A7%86%E9%A2%91%E4%BF%A1%E6%81%AF%E7%9A%84%E6%8D%9F%E5%A4%B1%E4%BC%9A%E6%9B%B4%E5%B0%91"><span class="nav-number">1.2.</span> <span class="nav-text">为了解决这个问题，论文是从压缩策略上入手。其大体思路是：把用户的指令作为条件，进行条件压缩。这样，既能对视频内容进行压缩，减少计算开销；同时又因为用了指令作为条件，则会对重要的视频内容做更多保留，因此视频信息的损失会更少</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#method"><span class="nav-number">2.</span> <span class="nav-text">method</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E6%98%AF%E4%B8%89%E4%B8%AA%E9%83%A8%E4%BB%B6%EF%BC%8C%E6%88%96%E8%80%85%E8%AF%B4%E4%B8%89%E4%B8%AA%E6%8A%80%E5%B7%A7%EF%BC%9ALocal-Level-Compression%EF%BC%8CGlobal-Level-Compression%EF%BC%8CInstruction-Condition-Injection%E3%80%82%E6%9C%80%E5%90%8E%EF%BC%8C%E8%AE%BA%E6%96%87%E5%9C%A8%E8%AE%AD%E7%BB%83%E7%9A%84%E8%8C%83%E5%BC%8F%E4%B8%8A%E4%B9%9F%E4%BD%9C%E5%87%BA%E5%88%9B%E6%96%B0%EF%BC%8C%E5%A2%9E%E5%8A%A0%E4%BA%86%E4%B8%80%E4%B8%AAstage%EF%BC%8C%E5%8D%B3Conditional-Pre-training-Stage"><span class="nav-number">2.1.</span> <span class="nav-text">主要是三个部件，或者说三个技巧：Local-Level Compression，Global-Level Compression，Instruction Condition Injection。最后，论文在训练的范式上也作出创新，增加了一个stage，即Conditional Pre-training Stage</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Local-Level-Compression%EF%BC%8C%E5%AE%83%E6%98%AF%E6%8A%8A%E8%A7%86%E9%A2%91%E8%BE%93%E5%85%A5%E7%BB%99%E5%88%86%E6%88%90%E8%8B%A5%E5%B9%B2%E4%B8%AAgroup%EF%BC%8C%E5%9C%A8%E6%AF%8F%E4%B8%AAgroup%E9%87%8C%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%8F%90%E5%8F%96%E7%BB%86%E8%8A%82%E4%BF%A1%E6%81%AF%EF%BC%88%E5%8C%85%E6%8B%AC%E4%BA%86%E6%8C%87%E4%BB%A4%E4%BF%A1%E6%81%AF%E7%9A%84%E6%B3%A8%E5%85%A5%EF%BC%89%E3%80%82%E8%80%8C%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E5%B0%B1%E4%BD%93%E7%8E%B0%E5%9C%A8%E4%BC%9A%E6%8A%8A%E6%AF%8F%E4%B8%AAgroup%E5%8E%8B%E7%BC%A9%E5%88%B0%E4%B8%80%E4%B8%AAtoken%EF%BC%8C%E4%B8%94%E8%BF%99%E4%B8%AAtoken%E6%98%AF%E9%80%9A%E8%BF%87%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%BE%97%E5%88%B0%E7%9A%84%EF%BC%8C%E8%BF%99%E4%B8%AA%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8C%E6%B3%A8%E5%85%A5%E4%BA%86%E6%8C%87%E4%BB%A4%E6%9D%A1%E4%BB%B6"><span class="nav-number">2.2.</span> <span class="nav-text">Local-Level Compression，它是把视频输入给分成若干个group，在每个group里用注意力机制提取细节信息（包括了指令信息的注入）。而条件压缩就体现在会把每个group压缩到一个token，且这个token是通过注意力机制得到的，这个过程中，注入了指令条件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Global-Level-Compression%EF%BC%8C%E5%AE%83%E5%88%99%E6%98%AF%E4%BD%9C%E4%B8%BA%E5%92%8CLocal-Level-Compression%E4%BA%92%E8%A1%A5%E7%9A%84%E9%83%A8%E5%88%86%E5%87%BA%E7%8E%B0%E7%9A%84%E3%80%82Local-Level-Compression%E6%98%AF%E5%9C%A8%E7%BB%84%E5%86%85%E8%BF%9B%E8%A1%8C%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E6%AD%A4%E6%97%B6%E5%8F%AA%E8%83%BD%E5%BE%97%E5%88%B0%E9%9B%B6%E6%95%A3%E7%9A%84%E5%B1%80%E9%83%A8%E4%BF%A1%E6%81%AF%EF%BC%88%E5%9B%A0%E4%B8%BA%E9%83%BD%E6%98%AF%E5%9C%A8%E7%BB%84%E5%86%85%E7%9A%84%E6%93%8D%E4%BD%9C%EF%BC%89%E3%80%82%E6%88%91%E4%BB%AC%E5%B8%8C%E6%9C%9B%E5%85%A8%E5%B1%80%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%8E%8B%E7%BC%A9%EF%BC%8C%E5%B9%B6%E4%B8%94%E8%BF%98%E8%A6%81%E5%B0%BD%E5%8F%AF%E8%83%BD%E9%81%B5%E4%BB%8E%E6%8C%87%E4%BB%A4%E3%80%82%E6%89%80%E4%BB%A5%EF%BC%8C%E8%AE%BA%E6%96%87%E4%BC%9A%E9%A2%84%E8%AE%BE%E4%B8%80%E7%BB%84learnable-tokens-L-in-R-N-L-times-D-%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BC%9A%E5%BE%80%E5%AE%83%E9%87%8C%E9%9D%A2%E6%B3%A8%E5%85%A5%E6%9D%A1%E4%BB%B6%E6%8C%87%E4%BB%A4%E4%BF%A1%E6%81%AF%EF%BC%8C%E4%B9%8B%E5%90%8E%E5%AE%83%E4%BC%9A%E5%92%8C%E8%A7%86%E9%A2%91%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92%EF%BC%88%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%89%EF%BC%8C%E6%9C%80%E7%BB%88%E8%BE%93%E5%87%BA%E7%9A%84%E7%BB%93%E6%9E%9C%E7%9A%84token%E6%95%B0%E4%B9%9F%E6%98%AF-N-L-%EF%BC%8C%E8%80%8C%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E8%B6%85%E5%8F%82%E6%95%B0%EF%BC%8C%E7%94%B1%E6%88%91%E4%BB%AC%E6%8C%87%E5%AE%9A%EF%BC%8C%E6%89%80%E4%BB%A5%E5%8F%AF%E4%BB%A5%E5%AE%9A%E5%BE%97%E7%9B%B8%E5%AF%B9%E5%B0%8F%E4%B8%80%E4%BA%9B%EF%BC%8C%E4%BB%8E%E8%80%8C%E5%AE%9E%E7%8E%B0%E5%8E%8B%E7%BC%A9%E6%95%88%E6%9E%9C"><span class="nav-number">2.3.</span> <span class="nav-text">Global-Level Compression，它则是作为和Local-Level Compression互补的部分出现的。Local-Level Compression是在组内进行压缩和注意力机制，此时只能得到零散的局部信息（因为都是在组内的操作）。我们希望全局也可以压缩，并且还要尽可能遵从指令。所以，论文会预设一组learnable tokens $L\in R^{N_{L}\times D}$ ，我们会往它里面注入条件指令信息，之后它会和视频进行交互（用注意力机制），最终输出的结果的token数也是$N_{L}$，而这是一个超参数，由我们指定，所以可以定得相对小一些，从而实现压缩效果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Instruction-Condition-Injection%EF%BC%8C%E8%AE%BA%E6%96%87%E9%87%8C%E6%8F%90%E5%87%BA%E5%88%86%E4%B8%89%E7%A7%8D%EF%BC%8Cdirect-injection%EF%BC%8Ccoarse-injection%EF%BC%8Cfine-injection%E3%80%82%E5%A4%A7%E4%BD%93%E4%B8%8A%EF%BC%8C%E6%84%9F%E8%A7%89%E8%AE%A1%E7%AE%97%E7%9A%84%E7%BB%86%E8%8A%82%E5%B9%B6%E4%B8%8D%E6%98%AF%E7%89%B9%E5%88%AB%E6%96%B0%E9%A2%96%EF%BC%8C%E4%B9%9F%E5%BE%88%E9%9A%BE%E8%AF%B4%E6%9C%89%E7%89%B9%E5%88%AB%E6%89%8E%E5%AE%9E%E7%9A%84%E7%90%86%E8%AE%BA%E6%94%AF%E6%92%91%EF%BC%8C%E4%BC%BC%E4%B9%8E%E9%83%BD%E6%98%AF%E6%AF%94%E8%BE%83%E5%B8%B8%E8%A7%81-%E7%9C%BC%E7%86%9F%E7%9A%84%E6%93%8D%E4%BD%9C%E3%80%82%E8%AE%BA%E6%96%87%E4%BA%AE%E7%82%B9%E5%BA%94%E8%AF%A5%E5%B9%B6%E4%B8%8D%E5%9C%A8%E4%BA%8E%E8%BF%99%E9%87%8C%E7%9A%84%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82%EF%BC%8C%E8%80%8C%E6%98%AF%E5%9C%A8%E4%BA%8E%E5%8F%91%E7%8E%B0%E4%BA%86%E9%97%AE%E9%A2%98%EF%BC%88%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E8%AE%A1%E7%AE%97%E5%BC%80%E9%94%80%E5%A4%A7%E2%80%94-%E5%8E%8B%E7%BC%A9%E6%95%88%E6%9E%9C%E5%8F%88%E4%B8%8D%E5%A4%9F%E5%A5%BD%E2%80%94-%E5%8F%AF%E4%BB%A5%E6%8F%90%E5%87%BA%E6%96%B0%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E6%9D%A5%E8%A7%A3%E5%86%B3%EF%BC%89%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%AE%83%E6%8F%90%E5%87%BA%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E7%9A%84%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF"><span class="nav-number">2.4.</span> <span class="nav-text">Instruction Condition Injection，论文里提出分三种，direct injection，coarse injection，fine injection。大体上，感觉计算的细节并不是特别新颖，也很难说有特别扎实的理论支撑，似乎都是比较常见&#x2F;眼熟的操作。论文亮点应该并不在于这里的技术细节，而是在于发现了问题（视频处理计算开销大—&gt;压缩效果又不够好—&gt;可以提出新的条件压缩来解决），以及它提出的条件压缩的解决思路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conditional-Pre-training-Stage%EF%BC%8C%E6%98%AFMLLMs%E8%AE%AD%E7%BB%83%E8%8C%83%E5%BC%8F%E4%B8%AD%E6%96%B0%E5%A2%9E%E5%8A%A0%E7%9A%84%E4%B8%80%E4%B8%AAstage%E3%80%82%E4%BC%A0%E7%BB%9F%E7%9A%84MLLMs%E8%AE%AD%E7%BB%83%E4%BE%9D%E6%AC%A1%E6%98%AF%E4%B8%A4%E4%B8%AAstage%EF%BC%9AAlignment-Stage%E3%80%81Instruction-Tuning-Stage%EF%BC%8C%E8%80%8C%E8%AE%BA%E6%96%87%E5%88%99%E6%8F%90%E5%87%BA%E5%9C%A8%E4%B8%AD%E9%97%B4%E5%8A%A0%E5%85%A5%E4%B8%80%E4%B8%AAstage%EF%BC%8CConditions-Pre-training-Stage%EF%BC%8C%E8%BF%99%E6%A0%B7%E5%8F%AF%E4%BB%A5%E8%AE%A9%E8%AE%AD%E7%BB%83%E6%9B%B4%E5%8A%A0%E6%B5%81%E7%95%85"><span class="nav-number">2.5.</span> <span class="nav-text">Conditional Pre-training Stage，是MLLMs训练范式中新增加的一个stage。传统的MLLMs训练依次是两个stage：Alignment Stage、Instruction Tuning Stage，而论文则提出在中间加入一个stage，Conditions Pre-training Stage，这样可以让训练更加流畅</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8B%E9%9D%A2%E8%AE%B2%E4%B8%80%E4%B8%8B%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82%E5%90%A7%EF%BC%9A"><span class="nav-number">2.6.</span> <span class="nav-text">下面讲一下技术细节吧：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Local-Level-Compression"><span class="nav-number">2.6.1.</span> <span class="nav-text">Local-Level Compression</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%99%E9%87%8C%E9%A6%96%E5%85%88%E6%B6%89%E5%8F%8A%E5%88%B0%E5%85%B7%E4%BD%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%88%86%E7%BB%84%E7%9A%84%E3%80%82%E5%8F%88%E5%BE%97%E8%B0%88%E5%88%B0%E8%A7%86%E9%A2%91%E8%BE%93%E5%85%A5%E5%A4%84%E7%90%86%E5%90%8E%E7%9A%84%E5%BD%A2%E7%8A%B6%EF%BC%8C%E4%B8%80%E8%88%AC%E6%98%AF-T-H-W-D-%EF%BC%8C%E5%85%B6%E4%B8%ADT%E4%BB%A3%E8%A1%A8%E6%97%B6%E9%97%B4%E5%B8%A7%E6%95%B0%EF%BC%8C-H-times-W-%E6%98%AF%E7%A9%BA%E9%97%B4%E5%B0%BA%E5%AF%B8%EF%BC%8CD%E6%98%AF%E7%89%B9%E5%BE%81%E7%BB%B4%E5%BA%A6%EF%BC%88%E8%A7%86%E9%A2%91%E5%85%B6%E5%AE%9E%E6%98%AF%E8%A2%AB%E8%A7%86%E4%B8%BA%E5%9B%BE%E5%83%8F%E5%BA%8F%E5%88%97%E6%9D%A5%E5%A4%84%E7%90%86%E7%9A%84%E3%80%82%E8%BF%99%E6%A0%B7%E7%9C%8B%EF%BC%8CT%E5%85%B6%E5%AE%9E%E5%8F%AF%E4%BB%A5%E8%AE%A4%E4%B8%BA%E6%98%AF%E5%9B%BE%E5%83%8F%E7%9A%84%E6%95%B0%E9%87%8F%EF%BC%89-%E5%8E%8B%E7%BC%A9%E6%97%B6%EF%BC%8C%E6%9C%89%E4%B8%AA%E5%8E%8B%E7%BC%A9%E6%AF%94-alpha-T-alpha-H-alpha-W-%EF%BC%8C%E5%8F%AF%E4%BB%A5%E4%BB%8E%E4%B8%8B%E6%A0%87%E7%9C%8B%E5%87%BA%E6%9D%A5%E5%88%86%E5%88%AB%E4%BB%A3%E8%A1%A8%E4%BA%86T%E3%80%81H%E3%80%81W%E7%BB%B4%E5%BA%A6%E4%B8%8A%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%AF%94%E3%80%82%E5%85%B7%E4%BD%93%E7%9A%84%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BC%9A%E5%9C%A8T%E7%BB%B4%E5%BA%A6%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%88%92%E5%88%86%EF%BC%8C%E5%88%86%E6%88%90-frac-T-alpha-T-N-T-%E5%9D%97%EF%BC%8C%E5%9C%A8H%E5%92%8CW%E7%BB%B4%E5%BA%A6%E4%B9%9F%E6%98%AF%E7%B1%BB%E4%BC%BC%E8%AE%A1%E7%AE%97%E3%80%82%E6%9C%80%E7%BB%88%E5%8F%AF%E4%BB%A5%E5%BE%97%E5%88%B0-N-T-times-N-H-times-N-W-%E4%B8%AA%E7%BB%84%E3%80%82%E5%88%86%E5%A5%BD%E7%BB%84%E5%90%8E%EF%BC%8C%E6%88%91%E4%BB%AC%E7%9A%84%E5%8E%8B%E7%BC%A9%E4%BC%9A%E6%8A%8A%E4%B8%80%E4%B8%AA%E7%BB%84%E9%87%8C%E7%9A%84%E6%89%80%E6%9C%89token%EF%BC%88%E5%8F%AF%E4%BB%A5%E7%AE%97%E5%87%BA%EF%BC%8C%E6%9C%89-alpha-T-times-alpha-H-times-alpha-W-%E4%B8%AAtoken%EF%BC%89%E5%8E%8B%E7%BC%A9%E6%88%90%E4%B8%80%E4%B8%AAtoken%E3%80%82%E6%AD%A4%E6%97%B6%E6%88%91%E4%BB%AC%E5%86%8D%E6%9D%A5%E7%9C%8B%E8%BF%99%E4%B8%AA%E5%88%86%E7%BB%84%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%8C%E5%AE%83%E6%B2%BF%E7%9D%80%E6%97%B6%E9%97%B4%E7%BB%B4%E5%BA%A6%EF%BC%88T%EF%BC%89%E5%92%8C%E7%A9%BA%E9%97%B4%E7%BB%B4%E5%BA%A6%EF%BC%88H%E3%80%81W%EF%BC%89%E9%83%BD%E6%9C%89%E5%88%86%E7%BB%84%EF%BC%8C%E5%9B%A0%E6%AD%A4%E4%B8%80%E5%AE%9A%E7%A8%8B%E5%BA%A6%E4%B8%8A%E4%BF%9D%E7%95%99%E4%BA%86%E5%8E%9F%E6%9D%A5%E8%BE%93%E5%85%A5%E7%9A%84%E6%97%B6%E7%A9%BA%E7%BB%93%E6%9E%84"><span class="nav-number">2.6.1.1.</span> <span class="nav-text">这里首先涉及到具体是怎么分组的。又得谈到视频输入处理后的形状，一般是$(T,H,W,D)$，其中T代表时间帧数，$H\times W$是空间尺寸，D是特征维度（视频其实是被视为图像序列来处理的。这样看，T其实可以认为是图像的数量）&#x3D;压缩时，有个压缩比$(\alpha_{T},\alpha_{H},\alpha_{W})$，可以从下标看出来分别代表了T、H、W维度上的压缩比。具体的，我们会在T维度上进行划分，分成$\frac{T}{\alpha_{T}}&#x3D;N_{T}$ 块，在H和W维度也是类似计算。最终可以得到$N_{T}\times N_{H}\times N_{W}$个组。分好组后，我们的压缩会把一个组里的所有token（可以算出，有$\alpha_{T}\times \alpha_{H}\times \alpha_{W}$ 个token）压缩成一个token。此时我们再来看这个分组的方式，它沿着时间维度（T）和空间维度（H、W）都有分组，因此一定程度上保留了原来输入的时空结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Global-Level-Compression"><span class="nav-number">2.6.2.</span> <span class="nav-text">Global-Level Compression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Instruction-Condition-Injection"><span class="nav-number">2.6.3.</span> <span class="nav-text">Instruction Condition Injection</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#direct-injection%EF%BC%8C%E5%AE%83%E5%B0%B1%E6%98%AF%E7%9B%B4%E6%8E%A5%E6%8A%8A%E6%96%87%E6%9C%AC%E6%8C%87%E4%BB%A4%E7%9A%84pooling%E5%90%8E%E7%9A%84token%EF%BC%8C%E8%AE%B0%E4%B8%BA-C-p-%EF%BC%88%E4%B9%9F%E5%B0%B1%E6%98%AF%E5%8D%95%E4%B8%AAtoken%EF%BC%89%EF%BC%8C%E7%94%A8%E4%B8%80%E4%B8%AAMLP%E7%9B%B4%E6%8E%A5%E6%98%A0%E5%B0%84%E5%88%B0%E8%A7%86%E9%A2%91%E7%89%B9%E5%BE%81%E7%9A%84%E7%A9%BA%E9%97%B4%E3%80%82%E4%B9%9F%E5%8D%B3%EF%BC%8C-Inj-A-C-MLP-C-%EF%BC%88%E8%BF%99%E9%87%8C%E5%8F%AF%E8%83%BD%E5%AE%B9%E6%98%93%E9%80%A0%E6%88%90%E5%9B%B0%E6%83%91%E7%9A%84%E7%82%B9%E5%9C%A8%E4%BA%8E%EF%BC%8C%E7%9C%8B%E8%B5%B7%E6%9D%A5%E8%BF%99%E9%87%8C%E5%B0%B1%E6%B2%A1%E7%94%A8%E5%88%B0A%EF%BC%88%E4%B9%9F%E5%8D%B3%E5%8F%AF%E5%AD%A6%E4%B9%A0%E7%9A%84token%EF%BC%89%E4%BA%86%E3%80%82%E4%BA%8B%E5%AE%9E%E4%B8%8A%E4%B9%9F%E6%98%AF%E5%8F%AF%E4%BB%A5%E7%9A%84%EF%BC%88%E6%9F%90%E4%BA%9B%E5%9C%BA%E6%99%AF%E4%B8%8B%EF%BC%89%E3%80%82%E5%9B%A0%E4%B8%BA%E6%88%91%E4%BB%AC%E6%B3%A8%E5%85%A5%E6%8C%87%E4%BB%A4%EF%BC%8C%E6%9C%AC%E8%B4%A8%E5%B0%B1%E6%98%AF%E5%B8%8C%E6%9C%9B%E6%8A%8A%E6%8C%87%E4%BB%A4%E4%BD%9C%E4%B8%BA%E6%9D%A1%E4%BB%B6%EF%BC%8C%E5%8A%A0%E5%85%A5%E5%88%B0%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8C%E4%BB%8E%E8%80%8C%E8%AE%A9%E7%BB%93%E6%9E%9C%E6%9B%B4%E5%8A%A0%E7%AC%A6%E5%90%88%E6%8C%87%E4%BB%A4%E3%80%82%E4%B8%8D%E7%AE%A1%E6%98%AFlocal%E8%BF%98%E6%98%AFglobal-compression%EF%BC%8C%E6%9C%80%E7%BB%88%E9%83%BD%E6%98%AF%E7%94%A8%E4%B8%80%E4%B8%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%9D%A5%E4%BA%A4%E4%BA%92%E6%8F%90%E5%8F%96%E4%BF%A1%E6%81%AF%E3%80%82query%E9%83%A8%E5%88%86%E5%8F%AA%E8%A6%81%E6%9C%89%E5%8C%85%E5%90%AB%E6%8C%87%E4%BB%A4%E6%9D%A1%E4%BB%B6%E5%B0%B1%E8%A1%8C%EF%BC%88%E8%BF%99%E9%87%8C%E7%90%86%E8%AE%BA%E4%B8%8A%E8%AF%B4%EF%BC%8Cquery%E9%87%8C%E6%B2%A1%E6%9C%89%E8%A7%86%E9%A2%91%E4%BF%A1%E6%81%AF%E4%B9%9F%E6%98%AF%E5%8F%AF%E4%BB%A5%E7%9A%84%EF%BC%8C%E6%AF%95%E7%AB%9Fquery%E6%98%AF%E8%A6%81%E5%92%8Ckey%E4%BA%A4%E4%BA%92%E7%9A%84%EF%BC%8C%E8%80%8Ckey%E9%87%8C%E6%98%AF%E6%9C%89%E8%A7%86%E9%A2%91%E4%BF%A1%E6%81%AF%E7%9A%84%EF%BC%9B%E4%BB%A5%E5%8F%8A%E6%9C%80%E5%90%8E%E5%92%8Cvalue%E8%BF%9B%E8%A1%8C%E5%8A%A0%E6%9D%83%E5%BE%97%E5%88%B0%E7%BB%93%E6%9E%9C%EF%BC%8Cvalue%E4%B9%9F%E6%98%AF%E8%A7%86%E9%A2%91%E4%BF%A1%E6%81%AF%E3%80%82%E5%8F%AA%E4%B8%8D%E8%BF%87%E5%AE%B9%E6%98%93%E6%83%B3%E5%88%B0%EF%BC%8C%E8%BF%99%E4%B8%AAdirect-injection%E5%AF%B9%E8%A7%86%E9%A2%91%E4%BF%A1%E6%81%AF%E7%9A%84%E5%88%A9%E7%94%A8%E8%BF%98%E6%98%AF%E4%B8%8D%E5%A4%9F%E3%80%82%E7%B2%92%E5%BA%A6%E5%BA%94%E8%AF%A5%E6%98%AF%E4%B8%89%E7%A7%8Dinjection%E4%B8%AD%E6%9C%80%E7%B2%97%E7%B3%99%E7%9A%84%EF%BC%89"><span class="nav-number">2.6.3.1.</span> <span class="nav-text">direct injection，它就是直接把文本指令的pooling后的token，记为$C_{p}$（也就是单个token），用一个MLP直接映射到视频特征的空间。也即，$Inj(A,C)&#x3D;MLP(C)$（这里可能容易造成困惑的点在于，看起来这里就没用到A（也即可学习的token）了。事实上也是可以的（某些场景下）。因为我们注入指令，本质就是希望把指令作为条件，加入到信息提取的过程中，从而让结果更加符合指令。不管是local还是global compression，最终都是用一个注意力机制来交互提取信息。query部分只要有包含指令条件就行（这里理论上说，query里没有视频信息也是可以的，毕竟query是要和key交互的，而key里是有视频信息的；以及最后和value进行加权得到结果，value也是视频信息。只不过容易想到，这个direct injection对视频信息的利用还是不够。粒度应该是三种injection中最粗糙的）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%B3%E4%BA%8Ecoarse%E5%92%8Cfine-injection%EF%BC%8C%E7%AE%80%E5%8D%95%E8%AF%B4%EF%BC%8C%E5%AE%83%E4%BB%AC%E4%B8%80%E4%B8%AA%E7%B1%BB%E4%BC%BC%E4%BA%8EadaIn%EF%BC%8C%E4%B8%80%E4%B8%AA%E5%9F%BA%E6%9C%AC%E5%B0%B1%E6%98%AF%E7%94%A8%E4%BA%86cross-attention%E8%80%8C%E5%B7%B2%E3%80%82%E5%97%AF%E3%80%82%E8%B7%9F%E4%B8%80%E5%BC%80%E5%A7%8B%E7%8C%9C%E7%9A%84%E5%85%AB%E4%B9%9D%E4%B8%8D%E7%A6%BB%E5%8D%81%E5%90%A7%E3%80%82"><span class="nav-number">2.6.3.2.</span> <span class="nav-text">至于coarse和fine injection，简单说，它们一个类似于adaIn，一个基本就是用了cross attention而已。嗯。跟一开始猜的八九不离十吧。</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#coarse-injection%EF%BC%8C%E5%AE%83%E6%98%AF%E5%85%88%E5%AF%B9%E8%A7%86%E9%A2%91%E7%89%B9%E5%BE%81%E8%BF%9B%E8%A1%8C%E4%B8%80%E4%B8%AALN%EF%BC%8C%E4%B9%8B%E5%90%8E%E8%A6%81%E5%AF%B9%E5%AE%83scale%E5%B9%B6shift%E3%80%82%E8%80%8Cscale%E5%92%8Cshift%E7%9A%84%E9%87%8F%E5%88%99%E6%98%AF%E7%94%B1%E5%8D%95%E4%B8%AA%E7%9A%84%E6%8C%87%E4%BB%A4token-C-p-%E9%80%9A%E8%BF%87%E4%B8%80%E4%B8%AAMLP%E5%9B%9E%E5%BD%92%E5%BE%97%E5%88%B0%EF%BC%88%E4%BC%BC%E4%B9%8E%E5%8F%AF%E4%BB%A5%E8%AE%A4%E4%B8%BA%EF%BC%8C%E6%98%AF%E7%B1%BB%E4%BC%BC%E4%BA%8E%E5%B8%B8%E8%A7%81%E7%9A%84%E6%83%B3%E6%B3%95%EF%BC%8C%E6%8A%8Amean%E5%92%8Cstd%E8%A7%86%E4%B8%BA%E5%86%85%E5%AE%B9%E9%A3%8E%E6%A0%BC%E7%9A%84%E4%B8%80%E7%A7%8D%E8%A1%A8%E5%BE%81%E3%80%82%E8%BF%99%E9%87%8C%E9%80%9A%E8%BF%87%E7%94%B1%E6%8C%87%E4%BB%A4%E6%9D%A5%E5%BD%B1%E5%93%8D%E8%A7%86%E9%A2%91token%E7%9A%84mean%E5%92%8Cstd%EF%BC%8C%E4%BB%8E%E8%80%8C%E5%BD%B1%E5%93%8D%E4%BA%86%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%EF%BC%8C%E5%81%9A%E5%88%B0%E8%AE%A9%E6%8C%87%E4%BB%A4%E6%8E%A7%E5%88%B6%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E6%8C%87%E4%BB%A4%E6%B3%A8%E5%85%A5%EF%BC%89"><span class="nav-number">2.6.3.3.</span> <span class="nav-text">coarse injection，它是先对视频特征进行一个LN，之后要对它scale并shift。而scale和shift的量则是由单个的指令token $C_{p}$ 通过一个MLP回归得到（似乎可以认为，是类似于常见的想法，把mean和std视为内容风格的一种表征。这里通过由指令来影响视频token的mean和std，从而影响了视频内容，做到让指令控制视频内容，也就是指令注入）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fine-injection%EF%BC%8C%E5%AE%83%E6%8B%BF%E5%88%B0%E7%9A%84%E6%9D%A1%E4%BB%B6%E4%B8%8D%E6%98%AF%E6%8C%87%E4%BB%A4%E7%BB%8F%E8%BF%87pooling%E5%90%8E%E7%9A%84%E4%B8%80%E4%B8%AAtoken%EF%BC%8C%E8%80%8C%E6%98%AF%E5%8E%9F%E6%9D%A5%E7%9A%84token%E5%BA%8F%E5%88%97-C-f-in-R-L-times-D-%E3%80%82%E8%BF%99%E9%87%8C%E6%8A%8A%E6%8C%87%E4%BB%A4%E6%9D%A1%E4%BB%B6%E6%B3%A8%E5%85%A5%E5%88%B0%E8%A7%86%E9%A2%91%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%E6%98%AF%E9%80%9A%E8%BF%87%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%8C%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4%E6%98%AF-Inj-A-C-Attn-LN-A-C-f-C-f"><span class="nav-number">2.6.3.4.</span> <span class="nav-text">fine injection，它拿到的条件不是指令经过pooling后的一个token，而是原来的token序列$C_{f}\in R^{L\times D}$。这里把指令条件注入到视频中的方法是通过注意力机制，具体来说是$Inj(A,C)&#x3D;Attn(LN(A),C_{f},C_{f})$</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conditional-Pre-training-Stage"><span class="nav-number">2.6.4.</span> <span class="nav-text">Conditional Pre-training Stage</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A6%96%E5%85%88%EF%BC%8CAlignment-Stage%EF%BC%8C%E5%AE%83%E7%B1%BB%E4%BC%BC%E4%BA%8Ellm%E7%9A%84pre-training%E9%98%B6%E6%AE%B5%EF%BC%8C%E5%8F%AF%E4%BB%A5%E8%AE%A4%E4%B8%BA%E7%9B%AE%E7%9A%84%E6%98%AF%E8%AE%A9MLLMs%E5%85%B7%E6%9C%89%E5%88%9D%E6%AD%A5%E7%9A%84%E3%80%81%E5%9F%BA%E7%A1%80%E7%9A%84%E8%83%BD%E5%8A%9B%E3%80%82%E8%BF%99%E4%B8%AA%E9%98%B6%E6%AE%B5%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%9B%BE%E5%83%8F-%E6%96%87%E6%9C%AC%E5%AF%B9%E6%95%B0%E6%8D%AE%E6%9D%A5%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%EF%BC%8C%E4%BB%8E%E8%80%8C%E8%AE%A9%E8%A7%86%E8%A7%89%E7%BC%96%E7%A0%81%E5%99%A8%E8%BE%93%E5%87%BA%E7%9A%84%E7%89%B9%E5%BE%81%E5%8F%AF%E4%BB%A5%E8%A2%AB%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%90%86%E8%A7%A3%EF%BC%8C%E4%B8%BA%E7%9A%84%E6%98%AF%E8%AE%A9%E8%A7%86%E8%A7%89token%E5%92%8C%E8%AF%AD%E8%A8%80token%E5%9C%A8%E5%90%8C%E4%B8%80%E4%B8%AA%E7%A9%BA%E9%97%B4%E9%87%8C%EF%BC%8C%E5%BB%BA%E7%AB%8B%E8%B7%A8%E6%A8%A1%E6%80%81%E7%9A%84%E7%BB%9F%E4%B8%80%E8%A1%A8%E7%A4%BA%E3%80%82%E4%B9%9F%E5%9B%A0%E6%AD%A4%EF%BC%8C%E6%95%B0%E6%8D%AE%E9%87%8C%E6%98%AF%E4%B8%8D%E5%8C%85%E5%90%AB%E6%98%BE%E5%BC%8F%E6%8C%87%E4%BB%A4%E7%9A%84%EF%BC%88%E6%95%85%E6%AD%A4%E6%97%B6%E7%9A%84MLLMs%E5%AF%B9%E6%8C%87%E4%BB%A4%E7%9A%84%E7%90%86%E8%A7%A3%E5%92%8C%E9%81%B5%E4%BB%8E%E8%BF%98%E4%B8%8D%E5%A4%9F%E5%A5%BD%EF%BC%8C%E9%9C%80%E8%A6%81%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%9A%84Instruction-Tuning-Stage%EF%BC%89"><span class="nav-number">2.6.4.1.</span> <span class="nav-text">首先，Alignment Stage，它类似于llm的pre-training阶段，可以认为目的是让MLLMs具有初步的、基础的能力。这个阶段会使用图像-文本对数据来训练模型，从而让视觉编码器输出的特征可以被语言模型理解，为的是让视觉token和语言token在同一个空间里，建立跨模态的统一表示。也因此，数据里是不包含显式指令的（故此时的MLLMs对指令的理解和遵从还不够好，需要进一步的Instruction Tuning Stage）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%80%8CInstruction-Tuning-Stage%EF%BC%8C%E5%AE%83%E7%9A%84%E7%9B%AE%E7%9A%84%E5%B0%B1%E6%98%AF%E8%AE%A9%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%BC%9A%E9%81%B5%E5%BE%AA%E7%94%A8%E6%88%B7%E6%8C%87%E4%BB%A4%EF%BC%8C%E5%AE%8C%E6%88%90%E5%85%B7%E4%BD%93%E4%BB%BB%E5%8A%A1%EF%BC%88%E6%AF%94%E5%A6%82%E8%A7%86%E9%A2%91%E9%97%AE%E7%AD%94%E3%80%81%E6%8E%A8%E7%90%86%EF%BC%89%E3%80%82%E6%AD%A4%E6%97%B6%E7%94%A8%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E5%B0%B1%E6%98%AF%E6%8C%87%E4%BB%A4-%E5%9B%9E%E7%AD%94%E5%AF%B9%E6%95%B0%E6%8D%AE"><span class="nav-number">2.6.4.2.</span> <span class="nav-text">而Instruction Tuning Stage，它的目的就是让模型学会遵循用户指令，完成具体任务（比如视频问答、推理）。此时用到的数据就是指令-回答对数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%86%E5%85%B3%E4%BA%8E%E8%AE%BA%E6%96%87%E9%87%8C%E6%8F%90%E5%88%B0%E7%9A%84%EF%BC%8C%E5%8A%A0%E5%85%A5Conditional-Pre-training-Stage%E7%9A%84%E5%8E%9F%E5%9B%A0%EF%BC%8C%E4%B8%AA%E4%BA%BA%E7%90%86%E8%A7%A3%E6%98%AF%E8%BF%99%E6%A0%B7%E7%9A%84%EF%BC%9A%E4%BC%A0%E7%BB%9F%E8%8C%83%E5%BC%8F%E9%87%8C%E6%98%AF%E4%B8%A4%E4%B8%AA%E9%98%B6%E6%AE%B5%E3%80%82%E8%80%8C%E8%AE%BA%E6%96%87%E6%AD%A4%E5%89%8D%E6%8F%90%E5%87%BA%E7%9A%84%E6%8A%80%E6%9C%AF%EF%BC%8C%E4%B8%BB%E8%A6%81%E6%98%AF%E4%B8%BA%E4%BA%86%E5%8E%8B%E7%BC%A9%E8%A7%86%E9%A2%91%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E7%AE%80%E5%8D%95%E8%AF%B4%E5%B0%B1%E6%98%AF%E6%8A%8A%E8%A7%86%E9%A2%91%E5%AF%B9%E5%BA%94%E7%9A%84token%E6%95%B0%E9%87%8F%E5%87%8F%E5%B0%91%E3%80%82%E5%85%B6%E4%BD%99%E5%9C%B0%E6%96%B9%E6%98%AF%E4%B8%8D%E5%8F%98%E7%9A%84%E3%80%82%E4%BD%86%E5%9B%A0%E4%B8%BA%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%97%B6%E5%80%99%E6%98%AF%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%EF%BC%8C%E4%BC%9A%E6%8A%8A%E6%8C%87%E4%BB%A4%E7%BB%99%E5%BD%93%E4%BD%9C%E6%9D%A1%E4%BB%B6%E6%B3%A8%E5%85%A5%E5%85%B6%E4%B8%AD%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%A8%A1%E5%9E%8B%E6%AD%A4%E6%97%B6%E7%9A%84%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%E8%BF%98%E4%B8%8D%E5%A4%9F%E5%A5%BD%EF%BC%8C%E9%82%A3%E4%B9%88%E6%8A%8A%E6%8C%87%E4%BB%A4%E6%B3%A8%E5%85%A5%E4%B9%8B%E5%90%8E%EF%BC%8C%E6%95%88%E6%9E%9C%E5%8F%AF%E8%83%BD%E5%B9%B6%E4%B8%8D%E5%A5%BD%EF%BC%88%E8%BF%99%E4%B8%80%E7%82%B9%E6%8E%A8%E6%B5%8B%E5%8F%AF%E8%83%BD%E6%98%AF%E5%AE%9E%E9%AA%8C%E4%B8%AD%E5%8F%91%E7%8E%B0%E4%BA%86%E8%BF%99%E4%B8%AA%E7%8E%B0%E8%B1%A1%EF%BC%8C%E8%80%8C%E5%90%8E%E5%BD%92%E7%BA%B3%E5%87%BA%E8%BF%99%E4%B8%AA%E5%8E%9F%E5%9B%A0%EF%BC%89%E3%80%82%E7%84%B6%E8%80%8C%E4%B8%80%E8%88%AC%E7%9A%84%E6%B5%81%E7%A8%8B%E9%87%8C%EF%BC%8C%E4%B8%BA%E4%BA%86%E8%A7%A3%E5%86%B3%E6%A8%A1%E5%9E%8B%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E6%95%88%E6%9E%9C%E4%B8%8D%E5%A5%BD%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%8C%E5%B0%B1%E4%BC%9A%E8%BF%9B%E8%A1%8CInstruction-Tuning%E3%80%82%E6%89%80%E4%BB%A5%E7%8E%B0%E5%9C%A8%E6%9C%89%E7%82%B9%E5%8D%A1%E5%9C%A8%E8%BF%99%E4%BA%86%EF%BC%9A%E6%AD%A3%E5%B8%B8%E7%9A%84Alignment-Stage%E7%BB%93%E6%9D%9F%E5%90%8E%EF%BC%8C%E9%9C%80%E8%A6%81%E8%BF%9B%E8%A1%8CInstruction-Tuning%E6%9D%A5%E5%A2%9E%E5%BC%BA%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%EF%BC%9B%E4%BD%86%E5%9B%A0%E4%B8%BA%E8%AE%BA%E6%96%87%E7%9A%84%E6%96%B9%E6%B3%95%E6%98%AF%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%EF%BC%8C%E5%AF%B9%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E6%9C%89%E6%9B%B4%E9%AB%98%E7%9A%84%E8%A6%81%E6%B1%82%EF%BC%8C%E6%89%80%E4%BB%A5Alignment%E5%90%8E%E7%9B%B4%E6%8E%A5%E8%BF%9B%E8%A1%8CInstruction-Tuning%EF%BC%8C%E5%9C%A8%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%97%B6%E5%80%99%E6%95%88%E6%9E%9C%E4%BC%9A%E4%B8%8D%E5%A5%BD%EF%BC%9B%E4%B8%BA%E6%AD%A4%E6%88%91%E4%BB%AC%E9%9C%80%E8%A6%81%E6%8F%90%E9%AB%98%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%EF%BC%8C%E4%BD%86%E6%8F%90%E9%AB%98%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%EF%BC%8C%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%A1%88%E5%8F%88%E6%98%AF%E8%BF%9B%E8%A1%8CInstruction-Tuning%E2%80%A6%E2%80%A6%E6%89%80%E4%BB%A5%EF%BC%8C%E8%AE%BA%E6%96%87%E7%9B%B4%E6%8E%A5%E8%B7%B3%E5%87%BA%E6%9D%A5%EF%BC%8C%E5%9C%A8Instruction-Tuning%E5%89%8D%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E5%89%8D%E7%BD%AEstage%EF%BC%8C%E5%85%88%E7%A8%8D%E5%BE%AE%E6%8A%8A%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E6%97%B6%E7%9A%84%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%E6%8F%90%E9%AB%98%E4%B8%80%E4%BA%9B%EF%BC%88%E8%BF%99%E9%87%8C%E4%B8%8D%E5%83%8FInstruction-Tuning-Stage%EF%BC%8C%E4%BC%9A%E5%AF%B9llm%E4%B9%9F%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83%EF%BC%9B%E8%BF%99%E4%B8%AA%E9%98%B6%E6%AE%B5%E6%88%91%E4%BB%AC%E5%8F%AA%E5%BE%AE%E8%B0%83%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E7%9B%B8%E5%85%B3%E7%9A%84%E9%83%A8%E5%88%86%EF%BC%8C%E6%8F%90%E9%AB%98%E9%82%A3%E4%BA%9B%E6%A8%A1%E5%9D%97%E9%87%8C%E6%8C%87%E4%BB%A4%E6%B3%A8%E5%85%A5%E7%9A%84%E6%95%88%E6%9E%9C%E3%80%82%E8%BF%99%E6%A0%B7%EF%BC%8C%E5%90%8E%E9%9D%A2%E5%88%B0%E4%BA%86Instruction-Tuning-Stage%E6%97%B6%EF%BC%8C%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E4%B9%9F%E8%83%BD%E5%81%9A%E5%BE%97%E6%AF%94%E8%BE%83%E5%A5%BD%E4%BA%86%EF%BC%8C%E4%B8%8D%E7%94%A8%E6%8B%85%E5%BF%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8C%87%E4%BB%A4%E9%81%B5%E5%BE%AA%E8%83%BD%E5%8A%9B%E8%BF%87%E5%B7%AE%E5%AF%BC%E8%87%B4%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%8E%8B%E7%BC%A9%E6%95%88%E6%9E%9C%E4%B8%8D%E5%A5%BD%EF%BC%89"><span class="nav-number">2.6.4.3.</span> <span class="nav-text">但关于论文里提到的，加入Conditional Pre-training Stage的原因，个人理解是这样的：传统范式里是两个阶段。而论文此前提出的技术，主要是为了压缩视频的内容，简单说就是把视频对应的token数量减少。其余地方是不变的。但因为压缩的时候是条件压缩，会把指令给当作条件注入其中，如果模型此时的指令遵循能力还不够好，那么把指令注入之后，效果可能并不好（这一点推测可能是实验中发现了这个现象，而后归纳出这个原因）。然而一般的流程里，为了解决模型指令遵循效果不好的问题，就会进行Instruction Tuning。所以现在有点卡在这了：正常的Alignment Stage结束后，需要进行Instruction Tuning来增强模型的指令遵循能力；但因为论文的方法是条件压缩，对指令遵循有更高的要求，所以Alignment后直接进行Instruction Tuning，在压缩的时候效果会不好；为此我们需要提高指令遵循能力，但提高指令遵循能力，传统方案又是进行Instruction Tuning……所以，论文直接跳出来，在Instruction Tuning前增加一个前置stage，先稍微把条件压缩时的指令遵循能力提高一些（这里不像Instruction Tuning Stage，会对llm也进行微调；这个阶段我们只微调条件压缩相关的部分，提高那些模块里指令注入的效果。这样，后面到了Instruction Tuning Stage时，条件压缩也能做得比较好了，不用担心模型的指令遵循能力过差导致的条件压缩效果不好）</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">bluemouse</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">134</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">31</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">70</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bluemouse</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
