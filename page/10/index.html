<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueeemouse.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="bluemouse&#39;s blog">
<meta property="og:url" content="https://blueeemouse.github.io/page/10/index.html">
<meta property="og:site_name" content="bluemouse&#39;s blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="bluemouse">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueeemouse.github.io/page/10/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>bluemouse's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">bluemouse's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/02/09/python%E7%9B%B8%E5%85%B3bugs%E6%88%96%E7%9F%A5%E8%AF%86/pytorch/torch.nn%E4%B8%8Etorch.nn.functional%E7%9A%84%E5%85%B3%E7%B3%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/09/python%E7%9B%B8%E5%85%B3bugs%E6%88%96%E7%9F%A5%E8%AF%86/pytorch/torch.nn%E4%B8%8Etorch.nn.functional%E7%9A%84%E5%85%B3%E7%B3%BB/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-02-09 01:27:48 / Modified: 01:36:25" itemprop="dateCreated datePublished" datetime="2025-02-09T01:27:48+08:00">2025-02-09</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>有些东西是既可以用torch.nn.functional来调用，也可以用torch.nn来调用，不禁让人疑惑：这不是多此一举吗？其实它们都是有必要的
结论上来说，写神经网络的时候，一般都是统一用torch.nn来调用（即使像relu这种没有参数的激活函数，用torch.nn.functional调用，虽然效果差不太多，但是为了统一，用torch.nn调用也许是更好的），因为此时调用的是类，它的
参数定义（用torch.nn调用的话，它们都是继承了torch.nn.Module类，所以一旦初始化，就已经有参数了；而用torch.nn.functional调用，则需要自己定义参数，并且在调用的时候手动传入，相比之下复杂许多）
参数管理（比如，用类的时候就可以结合优化器，自动更新参数；而如果是用torch.nn.functional来调用，不仅参数需要我们自己传入，还需要我们自己指定是否要求梯度，并且即使我们指定了要求梯度，优化器也不能实现自动更新参数，必须得我们手动更细，极其麻烦）
设备控制（就是控制在cpu还是gpu/哪块gpu）
模型参数保存（torch.nn类保存参数可以用torch.save(model.state_dict(),
'model.pth')这种语句很快捷地保存，而torch.nn.functional的话，就需要手动保存和加载参数）
等方面都要方便很多</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/02/04/algo/%E5%9F%BA%E7%A1%80%E8%AF%BE/chap1.%E7%AC%AC%E4%B8%80%E8%AE%B2%20%20%E5%BF%AB%E6%8E%92&%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F&%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/04/algo/%E5%9F%BA%E7%A1%80%E8%AF%BE/chap1.%E7%AC%AC%E4%B8%80%E8%AE%B2%20%20%E5%BF%AB%E6%8E%92&%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F&%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" class="post-title-link" itemprop="url">chap1.第一讲 快排&归并排序&二分查找</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-02-04 16:00:00" itemprop="dateCreated datePublished" datetime="2025-02-04T16:00:00+08:00">2025-02-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-04-13 21:15:25" itemprop="dateModified" datetime="2025-04-13T21:15:25+08:00">2025-04-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/algo/" itemprop="url" rel="index"><span itemprop="name">algo</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="快速排序">1.快速排序</h1>
<h2 id="核心思想分治思想">1.1.核心思想：分治思想</h2>
<h2 id="步骤">1.2.步骤：</h2>
<h3 id="对于一个给定的数组选定一个中间值x理论上来说选哪个都行但后面的代码需要注意相应的搭配否则会陷入死循环后面具体讲常见的就是选数组的左边右边中间值随机选">1.2.1.对于一个给定的数组，选定一个中间值x（理论上来说，选哪个都行，但后面的代码需要注意相应的搭配，否则会陷入死循环。后面具体讲），常见的就是选数组的左边/右边/中间值/随机选</h3>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/02/04/algo/%E5%9F%BA%E7%A1%80%E8%AF%BE/chap1.%E7%AC%AC%E4%B8%80%E8%AE%B2%20%20%E5%BF%AB%E6%8E%92&%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F&%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/02/04/algo/%E5%9F%BA%E7%A1%80%E8%AF%BE/chap1.%E7%AC%AC%E4%BA%8C%E8%AE%B2%20%E9%AB%98%E7%B2%BE%E5%BA%A6&%E5%89%8D%E7%BC%80%E5%92%8C&%E5%B7%AE%E5%88%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/04/algo/%E5%9F%BA%E7%A1%80%E8%AF%BE/chap1.%E7%AC%AC%E4%BA%8C%E8%AE%B2%20%E9%AB%98%E7%B2%BE%E5%BA%A6&%E5%89%8D%E7%BC%80%E5%92%8C&%E5%B7%AE%E5%88%86/" class="post-title-link" itemprop="url">chap1.第二讲 高精度&前缀和&差分</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-02-04 16:00:00" itemprop="dateCreated datePublished" datetime="2025-02-04T16:00:00+08:00">2025-02-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-02-16 17:04:46" itemprop="dateModified" datetime="2025-02-16T17:04:46+08:00">2025-02-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/algo/" itemprop="url" rel="index"><span itemprop="name">algo</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="高精度">1.高精度</h1>
<h2 id="简介">1.1.简介</h2>
<h3 id="所谓高精度在这里指的是大数相关的运算且不是每一种语言都需要自己实现这种算法像java和python就不需要大体上是因为它们已经自带这个功能了而算法常用的cc则没有这种功能因此需要自己实现-而这门课讲的高精度主要局限在两个大数相加相减以及一个大数乘以一个小数这里的大数一般指位数很多的正整数lenaleq-1e6小数一般指位数不那么多的正整数lenbleq-9">所谓高精度，在这里指的是大数相关的运算。且不是每一种语言都需要自己实现这种算法。像java和python就不需要（大体上是因为它们已经自带这个功能了）。而算法常用的c/c++则没有这种功能，因此需要自己实现<br>而这门课讲的高精度，主要局限在两个大数相加/相减，以及一个大数乘以一个小数（这里的大数，一般指位数很多的正整数，<span class="math inline">\(len(A)\leq
1e6\)</span>；小数一般指位数不那么多的正整数，<span class="math inline">\(len(B)\leq 9\)</span>）</h3>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/02/04/algo/%E5%9F%BA%E7%A1%80%E8%AF%BE/chap1.%E7%AC%AC%E4%BA%8C%E8%AE%B2%20%E9%AB%98%E7%B2%BE%E5%BA%A6&%E5%89%8D%E7%BC%80%E5%92%8C&%E5%B7%AE%E5%88%86/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/02/03/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/03/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-02-03 17:28:21" itemprop="dateCreated datePublished" datetime="2025-02-03T17:28:21+08:00">2025-02-03</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/01/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/VI-ReID/%E6%B3%9B%E8%AF%BB/%E6%B3%9B%E8%AF%BB%EF%BC%88VI-ReID%EF%BC%89%E2%80%94%E2%80%942025.1.29/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/VI-ReID/%E6%B3%9B%E8%AF%BB/%E6%B3%9B%E8%AF%BB%EF%BC%88VI-ReID%EF%BC%89%E2%80%94%E2%80%942025.1.29/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-01-30 00:25:39" itemprop="dateCreated datePublished" datetime="2025-01-30T00:25:39+08:00">2025-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-02-10 02:31:27" itemprop="dateModified" datetime="2025-02-10T02:31:27+08:00">2025-02-10</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="from-cross-modal-to-mixed-modal-visible-infrared-re-identification">From
Cross-Modal to Mixed-Modal Visible-Infrared Re-Identification</h1>
<h2 id="arxiv-2025.1.23">arxiv 2025.1.23</h2>
<h2 id="这篇论文主要是提出一个vi-reid中的新的场景吧就是gallery-images中有两种模态的图像而不止一种模态">这篇论文主要是提出一个vi-reid中的新的场景吧，就是gallery
images中有两种模态的图像，而不止一种模态。</h2>
<h2 id="动机经典的vi-reid实验的时候都是query和gallery模态不同那么其实就是一种visible-infraredinfrared-visible的匹配对应到实际情况可能就是白天照片-晚上照片晚上照片-白天照片但更实际的情况应该是匹配的时候可能既有可见光照片也有红外照片所以gallery中有两种模态的图像也就是文中提到的mixed-modal的setting这会带来一个问题就是gallery中同一模态的图像的domain-gap显然会比不同模态的domain-gap要小然而其中同一模态的图像却有可能是属于不同id的这可能导致匹配错误举个具体例子gallery中有id-1的一个红外图像一个可见光图像和一个id-2的可见光图像现在有一个id-2的红外query如果特征学的不够好进行匹配的时候很可能会把query匹配到id-1的那个红外图像上了毕竟都是红外图像本身的gap就比较小而红外和可见光之间的gap可就大了-这篇论文就是想解决这个问题">动机：经典的vi-reid，实验的时候，都是query和gallery模态不同。那么，其实就是一种visible-infrared/infrared-visible的匹配。对应到实际情况，可能就是白天照片-晚上照片/晚上照片-白天照片。但更实际的情况，应该是，匹配的时候，可能既有可见光照片，也有红外照片，所以gallery中有两种模态的图像，也就是文中提到的mixed-modal的setting。这会带来一个问题，就是，gallery中同一模态的图像的domain
gap显然会比不同模态的domain
gap要小，然而其中同一模态的图像却有可能是属于不同id的，这可能导致匹配错误。举个具体例子，gallery中有id
1的一个红外图像，一个可见光图像，和一个id 2的可见光图像。现在有一个id
2的红外query。如果特征学的不够好，进行匹配的时候，很可能会把query匹配到id
1的那个红外图像上了，毕竟都是红外图像，本身的gap就比较小，而红外和可见光之间的gap可就大了。<br>这篇论文就是想解决这个问题</h2>
<h2 id="方法它的大致思想是既然gallery中有两种模态的图像那么匹配的时候就既要用到modality-shared-feature也要用到modality-specific-feature文章提出一种方法把特征分解到两个正交的子空间中一个代表shared-feature一个代表specific-feature好经典的做法和讲故事的套路有没有什么手段能验证可视化这俩确实正交确实代表了shared-feature和specific-feature呢">方法：它的大致思想是，既然gallery中有两种模态的图像，那么匹配的时候就既要用到modality-shared
feature，也要用到modality-specific
feature。文章提出一种方法，把特征分解到两个正交的子空间中，一个代表shared
feature，一个代表specific
feature（好经典的做法和讲故事的套路。。有没有什么手段能验证、可视化这俩确实正交，确实代表了shared
feature和specific feature呢？）</h2>
<h4 id="话说回来在经典的vi-reid中真的有必要用到modality-specific-feature吗在经典设定下不是query和gallery一定不同模态吗那modality-specific-feature只有一方有匹配的时候用不上啊事实上人来进行红外和可见光的匹配的时候也是通过神态和脸来判断的吧服装那些基本用不上啊换装设定是不是也是这个思路">（话说回来，在经典的vi-reid中，真的有必要用到modality-specific
feature吗？在经典设定下，不是query和gallery一定不同模态吗？那modality-specific
feature，只有一方有，匹配的时候用不上啊？事实上，人来进行红外和可见光的匹配的时候，也是通过神态和脸来判断的吧，服装那些基本用不上啊（换装设定是不是也是这个思路？）</h4>
<h2 id="分析这篇文章用到一些互信息的公式来进行推导和阐述因为要用学到的模型生成的embedding来判断id所以要最大化embedding和id之间的标签而考虑到现在的mixed-modality-scenario需要把embedding拆分成两块就是上面提到的modality-shared和-specific-feature或者说原文的modality-erased-related-feature下面就是怎么把这两部分学到的问题论文把这部分转化成一个待优化的式子max_z_mez_mrmiz_mez_mry-s.t.miz_mez_mr0miz_mem0and-miz_mrym0-上面的z_me代表模态m下的modality-erased-feature也就是与模态无关的特征z_mr代表模态m下的modality-related-feature也就是与模态相关的特征模态m可能是visible也可能是infrared三个约束也是保证学到的特征有效的关键第一个约束是想让modality-erased-feature与modality-related-feature相互独立这个是合理的毕竟理论上这两部分的交集是空集并集就是所有的特征信息了第二个约束是因为z_me代表modality-erased-feature所以用这个特征应该推断不出模态信息所以它应该与模态独立也合理第三个约束没搞明白它想干什么按原论文它是希望z_mr不包含id相关的信息但为什么要这样如果真的满足了这个约束z_mr就是只能用来推断模态信息不能用来推断id信息那它和z_me组合起来用又是为什么还是说它是彻底的把模态和id语义信息给分开了分到两个特征里所以推断的时候是怎么推断的是说如果是同一模态的图像来匹配则用的特征是上面提到的modality-erased-feature和modality-related-feature拼接起来的一个特征如果是跨模态的匹配则只用modality-erased-feature但这样不是很麻烦吗得再看看代码了可能-总而言之得到了上面的待优化式子下面就是把它转化成一个近似的式子用损失去刻画从而变成可以用深度学习解决的问题得到结果如下500-且针对四个部分都进行了各自的优化">分析：这篇文章用到一些互信息的公式来进行推导和阐述。因为要用学到的模型生成的embedding来判断id，所以要最大化embedding和id之间的标签。而考虑到现在的mixed-modality
scenario，需要把embedding拆分成两块，就是上面提到的modality-shared和-specific
feature（或者说原文的modality-erased/-related
feature）。下面就是怎么把这两部分学到的问题。论文把这部分转化成一个待优化的式子：<span class="math display">\[\max_{Z_{m}^{e},Z_{m}^{r}}\{MI(Z_{m}^{e},Z_{m}^{r};Y)\}\
\ s.t.MI(Z_{m}^{e},Z_{m}^{r})=0,MI(Z_{m}^{e};M)=0,and\
MI(Z_{m}^{r};Y|M)=0\]</span><br>上面的<span class="math inline">\(Z_{m}^{e}\)</span>代表模态m下的modality-erased
feature，也就是与模态无关的特征；<span class="math inline">\(Z_{m}^{r}\)</span>代表模态m下的modality-related
feature，也就是与模态相关的特征。模态m可能是visible，也可能是infrared。三个约束也是保证学到的特征有效的关键。第一个约束，是想让modality-erased
feature与modality-related
feature相互独立。这个是合理的。毕竟理论上这两部分的交集是空集，并集就是所有的特征信息了。第二个约束，是因为<span class="math inline">\(Z_{m}^{e}\)</span>代表modality-erased
feature，所以用这个特征应该推断不出模态信息，所以它应该与模态独立，也合理。第三个约束，没搞明白它想干什么。按原论文，它是希望<span class="math inline">\(Z_{m}^{r}\)</span>不包含ID相关的信息。但为什么要这样？如果真的满足了这个约束，<span class="math inline">\(Z_{m}^{r}\)</span>就是只能用来推断模态信息，不能用来推断ID信息。那它和<span class="math inline">\(Z_{m}^{e}\)</span>组合起来用，又是为什么？还是说，它是彻底的把模态和ID（语义）信息给分开了，分到两个特征里？所以推断的时候是怎么推断的？是说，如果是同一模态的图像来匹配，则用的特征是上面提到的modality-erased
feature和modality-related
feature拼接起来的一个特征；如果是跨模态的匹配，则只用modality-erased
feature（但这样不是很麻烦吗？得再看看代码了可能）<br>总而言之，<strong>得到了上面的待优化式子，下面就是把它转化成一个近似的式子，用损失去刻画，从而变成可以用深度学习解决的问题</strong>。得到结果如下：<img src="/2025/01/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/VI-ReID/%E6%B3%9B%E8%AF%BB/%E6%B3%9B%E8%AF%BB%EF%BC%88VI-ReID%EF%BC%89%E2%80%94%E2%80%942025.1/泛读/pic/cross-modal.png" alt="|500"><br>且针对四个部分，都进行了各自的优化</h2>
<h2 id="评价虽然这篇论文乍一看很烂特别是摘要那里还把数据集的名字打错了更是降低印象分可是看完以后一来它提出的新场景也不算空中楼阁确实是更有实际意义的二来它提出方法以后对每一部分的刻画和阐述都还算合理有一点娓娓道来的感觉都是就事论事的分析">评价：虽然这篇论文乍一看很烂，特别是摘要那里还把数据集的名字打错了，更是降低印象分，可是看完以后，一来，它提出的新场景也不算空中楼阁，确实是更有实际意义的；二来，它提出方法以后，对每一部分的刻画和阐述都还算合理，有一点娓娓道来的感觉，都是就事论事的分析</h2>
<h2 id="trick总结">trick总结：</h2>
<h3 id="想让两个向量尽可能独立可以用互信息为0来进行理论上的刻画虽说其实可能是有失偏颇的然后用正交损失来近似代替">1.想让两个向量尽可能独立，可以用互信息为0来进行理论上的刻画（虽说其实可能是有失偏颇的），然后用正交损失来近似代替</h3>
<h3 id="如果要最大化某个互信息那么可以从语义上去理解给出相应的损失比如论文里提到的要最大化miz_mey即要最大化modality-erased-feature与标签变量之间的互信息其实目的就是让modality-erased-feature能尽可能揭示出id信息所以用一个交叉熵的分类损失就是理所应当的了可以认为是对常见的交叉熵分类损失给出一个理论上的解释">2.如果要最大化某个互信息，那么可以从语义上去理解，给出相应的损失。比如论文里提到的，要最大化<span class="math inline">\(MI(Z_{m}^{e};Y)\)</span>，即要最大化modality-erased
feature与标签变量之间的互信息，其实目的就是让modality-erased
feature能尽可能揭示出ID信息，所以用一个交叉熵的分类损失就是理所应当的了（可以认为是对常见的交叉熵分类损失给出一个理论上的解释）</h3>
<h3 id="要让模型混淆某几个部分这可能是出于模型设计的考虑可以考虑进行分类但加上梯度反转层">3.要让模型混淆某几个部分（这可能是出于模型设计的考虑），可以考虑进行分类，但加上梯度反转层</h3>
<h3 id="要约束某两个量xy尽可能接近可以考虑给出这个形式的损失lmaxx-yalpha0maxy-xalpha0alpha是正常数也是超参数那么x和y必须相差绝对值不大于alpha这部分损失才为0否则就产生损失了">4.要约束某两个量x，y尽可能接近，可以考虑给出这个形式的损失：<span class="math inline">\(L=max(x-y+\alpha,0)+max(y-x+\alpha,0)\)</span>，<span class="math inline">\(\alpha\)</span>是正常数，也是超参数。那么，x和y必须相差绝对值不大于<span class="math inline">\(\alpha\)</span>，这部分损失才为0，否则就产生损失了</h3>
<h3 id="这个trick目前看下来好像还是比较局限的就是针对跨模态行人重识别的时候才会用到就是如果要学习modality-specific-feature且每个id都有两种模态的数据则可以考虑把每一个id给doubled比如如果它是visible的图像则id-2如果它是infrared的图像则idid-2-1基于这一套新的标签进行分类并用交叉熵分类损失来优化这里之所以能起到效果是因为我们把同一id的不同模态的数据给视为不同标签相当于进行更细粒度的分类模型如果要正确分类就必须学会捕获同一id下visible和infrared图像的各自的有判别力的特征这样模型就能学会提取出modality-specific-feature当然这个trick也并不唯一肯定是还有别的方法的就比如再用个损失约束同一id的不同模态的数据要尽可能远离有点对比学习的意思通过让不同类别的数据尽可能远离让模型潜移默化地学会了语义信息应该也能学会提取modality-specific-feature">5.这个trick目前看下来好像还是比较局限的，就是针对跨模态行人重识别的时候才会用到。。。就是，如果要学习modality-specific
feature，且每个ID都有两种模态的数据，则可以考虑把每一个ID给“doubled”，比如，如果它是visible的图像，则ID
* 2；如果它是infrared的图像，则ID=ID * 2 +
1。基于这一套新的标签，进行分类，并用交叉熵分类损失来优化。这里之所以能起到效果，是因为，我们把同一ID的不同模态的数据给视为不同标签，相当于进行更细粒度的分类。模型如果要正确分类，就必须学会捕获同一ID下visible和infrared图像的各自的、有判别力的特征。这样模型就能学会提取出modality-specific
feature。当然，这个trick也并不唯一，肯定是还有别的方法的。就比如，再用个损失，约束同一ID的不同模态的数据要尽可能远离（有点对比学习的意思：通过让不同类别的数据尽可能远离，让模型潜移默化地学会了语义信息），应该也能学会提取modality-specific
feature</h3>
<h1 id="spectral-enhancement-and-pseudo-anchor-guidance-for-infrared-visible-person-re-identification">Spectral
Enhancement and Pseudo-Anchor Guidance for Infrared-Visible Person
Re-Identification</h1>
<h2 id="arxiv-2025.1.2">arxiv, 2025.1.2</h2>
<h2 id="这篇文章主要是从谱域的角度来缓解两种模态的巨大差异但它只是直接指出这两种模态的数据有巨大的spectral-gap却并没有分析为什么有这种gap或者说我们怎么确认这种gap确实存在而不只是说说而已有种拿到谱域方法就来试一下的感觉">这篇文章主要是从谱域的角度来缓解两种模态的巨大差异（但它只是直接指出这两种模态的数据有巨大的spectral
gap，却并没有分析为什么有这种gap，或者说我们怎么确认这种gap确实存在，而不只是说说而已。有种拿到谱域方法就来试一下的感觉）</h2>
<h2 id="动机">动机：</h2>
<h2 id="方法">方法：</h2>
<h2 id="分析第一步是生成一个semantically-enhanced-grey-images姑且可以认为是一种拉近两种模态的数据的方法只不过是从可见光图像出发往红外上靠拢也合理毕竟可见光图像信息更多红外图像信息更少从信息更多的往信息更少的变换是比较容易的它主要做的其实是在很常见的灰度映射之余加上了高频信息具体来说它会先对可见光图像进行一个傅里叶变换提取它的频域信息然后用其中的频率成分进行傅里叶逆变换这里是为了提取轮廓信息然后将逆变换的结果与灰度映射的结果相加得到semantically-enhanced-grey-images下简称seg图像btw这个方法倒是可以借鉴一下感觉还是行得通的起码可以试试用到我们的方法里就是加上傅里叶变换之后可能计算量大了-第二步是对红外图像和seg图像进行进一步的特征提取也是为了进一步缩小两种模态的数据之间的差异因为最后还是要用特征进行相似度计算的这里其实平平无奇-就是用resnet-50的前三块共享权重来提取共同的特征之后又用resnet-50的最后一个块不同权重来分别提取modality-specific-feature-第三步是paba-loss即pseudo-anchor-guided-bidirectional-aggregation-loss它的目的是对于前面的共同特征希望它们能更加兼容也就是尽可能的变换到一个空间里但也不能就失去判断力了而所谓anchor-guided其实就是说用向anchor靠拢来实现两种数据的靠拢举个具体例子我有同一id的两种模态的若干数据我希望把它们变换到一个统一的空间里则可以考虑求一下可见光的一个anchor比如所有可见光数据的均值然后拉近所有红外数据与这个anchor的距离从而实现红外数据与可见光数据的靠拢说回这里它是对上面提到的共同特征f_sharedseg和f_sharedir先进行一个分块分成n块之后对每个块都施加paba-loss拉近同一id的不同模态的数据的距离同时拉远不同id的不同模态的数据的距离相比于常见的triplet-loss这里增加了跨模态的考虑而相比于cross-center-loss这里的改进在于分了块且是对每个块都施加paba-loss故更加细粒度这里其实要结合公式来看才清楚-除了上面提到的paba-loss经典的交叉熵分类损失当然也是不能少的针对specific和shared-feature都有这个分类损失三部分损失加权求和即得到总的损失权重是超参">分析：第一步是生成一个Semantically
Enhanced Grey
Images（姑且可以认为是一种拉近两种模态的数据的方法，只不过是从可见光图像出发，往红外上靠拢。也合理，毕竟可见光图像信息更多，红外图像信息更少，从信息更多的往信息更少的变换是比较容易的）。它主要做的其实是，在很常见的灰度映射之余，加上了高频信息。具体来说，它会先对可见光图像进行一个傅里叶变换，提取它的频域信息，然后用其中的频率成分进行傅里叶逆变换（这里是为了提取轮廓信息），然后将逆变换的结果与灰度映射的结果相加，得到Semantically
Enhanced Grey
Images（下简称SEG图像）。btw，这个方法倒是可以借鉴一下，感觉还是行得通的，起码可以试试用到我们的方法里。就是加上傅里叶变换之后，可能计算量大了<br><br>第二步是对红外图像和SEG图像进行进一步的特征提取，也是为了进一步缩小两种模态的数据之间的差异（因为最后还是要用特征进行相似度计算的）。这里其实平平无奇，
就是用ResNet-50的前三块（共享权重）来提取共同的特征，之后又用ResNet-50的最后一个块（不同权重），来分别提取modality-specific
feature<br><br>第三步是PABA loss，即Pseudo Anchor-guided Bidirectional
Aggregation
Loss。它的目的是，对于前面的共同特征，希望它们能更加兼容，也就是尽可能的变换到一个空间里，但也不能就失去判断力了。而所谓Anchor-guided，其实就是说，用“向Anchor靠拢”来实现两种数据的靠拢。举个具体例子，我有同一ID的两种模态的若干数据，我希望把它们变换到一个统一的空间里，则可以考虑，求一下可见光的一个Anchor（比如，所有可见光数据的均值），然后拉近所有红外数据与这个Anchor的距离，从而实现红外数据与可见光数据的靠拢。说回这里，它是对上面提到的共同特征<span class="math inline">\(F_{shared}^{seg}\)</span>和<span class="math inline">\(F_{shared}^{ir}\)</span>，先进行一个分块，分成N块，之后对每个块都施加PABA
loss，拉近同一ID的不同模态的数据的距离，同时拉远不同ID的不同模态的数据的距离。相比于常见的triplet
loss，这里增加了跨模态的考虑；而相比于cross-center
loss，这里的改进在于分了块，且是对每个块都施加PABA
loss，故更加细粒度（这里其实要结合公式来看才清楚）<br>除了上面提到的PABA
loss，经典的交叉熵分类损失当然也是不能少的。针对specific和shared
feature都有这个分类损失。三部分损失加权求和即得到总的损失（权重是超参）</h2>
<h1 id="embedding-and-enriching-explicit-semantics-for-visible-infrared-person-re-identification">Embedding
and Enriching Explicit Semantics for Visible-Infrared Person
Re-Identification</h1>
<h2 id="arxiv2024.12.11">arxiv，2024.12.11</h2>
<h2 id="这篇文章的方法看起来有点复杂然后动机上看感觉也有些牵强更多是为了用上现在很火的大模型所以硬凑了个理由">这篇文章的方法看起来有点复杂，然后动机上看，感觉也有些牵强，更多是为了用上现在很火的大模型，所以硬凑了个理由</h2>
<h2 id="insight利用了一下text用文本信息来直接补充一部分图像的语义信息可能会比单纯用图像encoder来提取语义信息要好一点提出若干损失来利用多视角信息但是否合理有待考察至少看它的消融实验结果证明了这部分是有效的">insight：利用了一下text，用文本信息来直接补充一部分图像的语义信息，可能会比单纯用图像encoder来提取语义信息要好一点；提出若干损失来利用多视角信息（但是否合理有待考察，至少看它的消融实验结果，证明了这部分是有效的）</h2>
<h2 id="动机文章指出现在的vi-reid方法有两大类一类是基于生成式模型的方法效果不够好个人不太了解一类是基于判别式模型的方法也就是用模型把图像进行embed用embedding来进行匹配通常需要各种魔改网络架构这种方法的效果会更好也更主流而文章指出这种方法仅利用图像对语义信息的提取不够因此希望加入文本描述来帮助更好的提取文本信息就是这一点让我感觉略有点牵强它所谓的文本描述也是人llm基于图像进行的描述语义信息本身就是来自图像的至于说提取的不够可以认为是网络架构不够好数据不够多等问题导致的加入文本描述更多可能是希望能让模型能比较容易地学到语义信息不过考虑到现在reid的骨干基本都是一个resnet50模型容量应该是有上限的那么用文字embedding来辅助一下也有道理">动机：文章指出，现在的VI-ReID方法有两大类，一类是基于生成式模型的方法，效果不够好（个人不太了解），一类是基于判别式模型的方法，也就是用模型把图像进行embed，用embedding来进行匹配，通常需要各种魔改网络架构。这种方法的效果会更好，也更主流。而文章指出，这种方法仅利用图像，对语义信息的提取不够，因此希望加入文本描述，来帮助更好的提取文本信息。（就是这一点，让我感觉略有点牵强。它所谓的文本描述，也是人/llm基于图像进行的描述，语义信息本身就是来自图像的。至于说提取的不够，可以认为是网络架构不够好、数据不够多等问题导致的。加入文本描述，更多可能是希望能让模型能“比较容易”地学到语义信息）（不过考虑到现在reid的骨干基本都是一个ResNet50，模型容量应该是有上限的，那么用文字embedding来辅助一下也有道理）</h2>
<h2 id="方法-1">方法：</h2>
<h3 id="提出一个eees框架包含三个部分各司其职-第一个是ese模块explicit-semantics-embedding它的目的是利用文本让图像embedding学到更多语义信息主要做的是引入vllm为图像生成文本描述然后用对比学习拉近图像embedding和对应的文本描述的embedding让图像embedding学到文本的语义信息">提出一个EEES框架，包含三个部分，各司其职<br>第一个是ESE模块（Explicit
Semantics
Embedding），它的目的是，利用文本，让图像embedding学到更多语义信息。主要做的是引入vllm，为图像生成文本描述，然后用对比学习，拉近图像embedding和对应的文本描述的embedding，让图像embedding学到文本的语义信息</h3>
<h3 id="第二个是cvsccross-view-semantics-compensation它的目的是利用多视角的图像让模型能提取出更加丰富的语义信息举个例子对于同一个人一个摄像头视角拍到的照片所蕴含的信息终归是有限的可能这个视角下的照片能拍到身材轮廓脸却被遮住了这时如果能用到其它视角下这个人的照片可能就能获得脸部信息了综合起来就能提取出这个人的更多特征所以训练的时候对于一个batch里的每个图像这套方法都会去利用同id在其它视角下的图像而具体的利用方法就是在训练时对一个batch中的每个图像都去随机取m个同id的不同摄像头下的图像然后求个平均值共m1个图像我们就认为这个均值图像里蕴含了多视角的信息对于文本也是进行类似的操作从而得到蕴含了多视角信息的文本embedding当然都必须是同模态下的就是说可见光图像要去找同id的不同摄像头下的其它可见光图像其余类似之后会用一个对齐损失去双向约束多视角信息下的图像embedding和文字embedding毕竟即使是综合了多视角信息对于同一个人的图像embedding和文字embedding依然应该尽可能相近确保图像学到更多合理的语义信息-然而实际测试的时候我们都是拿到一个图像就要去进行匹配了也就是说没有多视角的信息可以利用上面也提到了是训练时可以这样利用多视角信息那为了弥补这一缺点论文提出进行一个蒸馏就是让每个图像embedding去逼近它对应的那个多视角下的均值embedding文字embedding类似两种模态都进行这个操作所以这个蒸馏损失就是四项了公式如下500">第二个是CVSC（Cross-View
Semantics
Compensation），它的目的是，利用多视角的图像，让模型能提取出更加丰富的语义信息。举个例子，对于同一个人，一个摄像头（视角）拍到的照片所蕴含的信息，终归是有限的。可能这个视角下的照片能拍到身材轮廓，脸却被遮住了；这时如果能用到其它视角下这个人的照片，可能就能获得脸部信息了。综合起来，就能提取出这个人的更多特征。所以，训练的时候，对于一个batch里的每个图像，这套方法都会去利用同ID在其它视角下的图像。而具体的利用方法，就是在训练时，对一个batch中的每个图像，都去随机取M个同ID的，不同摄像头下的图像，然后求个平均值（共<span class="math inline">\(M+1\)</span>个图像），我们就认为这个均值图像里蕴含了多视角的信息。对于文本，也是进行类似的操作，从而得到蕴含了多视角信息的文本embedding（当然，都必须是同模态下的。就是说，可见光图像要去找同ID的不同摄像头下的其它可见光图像。其余类似）。之后会用一个对齐损失，去双向约束多视角信息下的图像embedding和文字embedding。毕竟，即使是综合了多视角信息，对于同一个人的图像embedding和文字embedding依然应该尽可能相近，确保图像学到更多合理的语义信息<br>然而，实际测试的时候，我们都是拿到一个图像，就要去进行匹配了。也就是说，没有多视角的信息可以利用（上面也提到了，是<strong>训练</strong>时可以这样利用多视角信息。那为了弥补这一缺点，论文提出进行一个蒸馏，就是让每个图像embedding去逼近它对应的那个多视角下的均值embedding，文字embedding类似。两种模态都进行这个操作。所以这个蒸馏损失就是四项了。公式如下：<img src="/2025/01/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/VI-ReID/%E6%B3%9B%E8%AF%BB/%E6%B3%9B%E8%AF%BB%EF%BC%88VI-ReID%EF%BC%89%E2%80%94%E2%80%942025.1/泛读/pic/distillation_loss.png" alt="|500"></h3>
<h3 id="第三个是cmsp模块cross-modality-semantics-purification它的目的是避免学到的语义发生冲突具体来说同一个id会有灰度图和可见光图像也会有对应的灰度图的文字描述和可见光图像的文字描述而这两种文字描述可能发生冲突比如llm针对可见光图像可能可以准确地描述出人穿的衣服的颜色也许是蓝色而拿到灰度图像全部都是会的它可能就会输出人穿的衣服的颜色是灰的这无疑会造成矛盾所以我们希望对两种模态的文字描述可以不同互补当然是好现象但不能矛盾因此论文提出一个cmsp-loss公式如下l_cmspfrac1nsum_i1nd_ivv-d_ivr2frac1nsum_i1nd_irr-d_irv2-其中d_ivvlvert-f_iv-t_ivrvert_2d_ivrlvert-f_iv-t_irrvert_2其余定义类似可以看到我们的目的是让这个损失约束同一id下的红外图像文字描述要尽可能接近它的可见光图像的文字描述至于为什么模型不会塌缩直接让红外图像文字描述与可见光图像文字描述完全一样可能是因为前面的对比损失分类损失约束了这些文字embedding让它们必须有合理的语义信息吧">第三个是CMSP模块（Cross-Modality
Semantics
Purification），它的目的是，避免学到的语义发生冲突。具体来说，同一个ID会有灰度图和可见光图像，也会有对应的灰度图的文字描述和可见光图像的文字描述。而这两种文字描述，可能发生冲突。比如，llm针对可见光图像，可能可以准确地描述出人穿的衣服的颜色，也许是蓝色；而拿到灰度图像，全部都是会的，它可能就会输出“人穿的衣服的颜色是灰的”，这无疑会造成矛盾。所以我们希望，对两种模态的文字描述，可以不同（互补当然是好现象），但不能矛盾。因此，论文提出一个cmsp
loss，公式如下：<span class="math display">\[L_{cmsp}=\frac{1}{N}\sum_{i=1}^{N}{(d_{i}^{vv}-d_{i}^{vr})}^{2}+\frac{1}{N}\sum_{i=1}^{N}{(d_{i}^{rr}-d_{i}^{rv})}^{2}\]</span><br>其中，<span class="math inline">\(d_{i}^{vv}=\lVert
f_{i}^{v}-t_{i}^{v}\rVert_{2}\)</span>，<span class="math inline">\(d_{i}^{vr}=\lVert
f_{i}^{v}-t_{i}^{r}\rVert_{2}\)</span>，其余定义类似。可以看到，我们的目的是，让这个损失约束同一ID下的红外图像文字描述要尽可能接近它的可见光图像的文字描述（至于为什么模型不会塌缩，直接让红外图像文字描述与可见光图像文字描述完全一样，可能是因为前面的对比损失、分类损失约束了这些文字embedding，让它们必须有合理的语义信息吧</h3>
<h2 id="分析">分析</h2>
<h3 id="第一部分是稀松平常的但好像也就第一部分看起来靠点谱">第一部分是稀松平常的，但好像也就第一部分看起来靠点谱。。</h3>
<h3 id="第二部分想法是挺好的但一来训练的时候凭什么说求个均值图像就蕴含了多视角的信息或者说这种方法是不是太简单粗暴了还有测试的时候那个蒸馏就是说希望单视角下的embedding能尽可能接近多视角下的embedding可见光红外图像文字也就是说我们竟然是希望模型拿到一个单视角的图像就能脑补出多视角下的图像信息这合理吗只能说有一些合理之处毕竟人拿到一张图像确实能靠空间想象力脑补出一些东西但也有些不合理之处比如上面的脸部遮挡例子这个是无论如何也不能脑补出来的逼迫模型去学这个也是不合理的难说最后学出来的是什么可能过拟合了">第二部分想法是挺好的，但一来，训练的时候，凭什么说求个均值图像，就蕴含了多视角的信息？或者说，这种方法是不是太简单粗暴了？还有，测试的时候，那个蒸馏，就是说，希望单视角下的embedding能尽可能接近多视角下的embedding（可见光/红外，图像/文字），也就是说，我们竟然是希望模型拿到一个单视角的图像，就能“脑补”出多视角下的图像信息？这合理吗？只能说，有一些合理之处（毕竟人拿到一张图像，确实能靠空间想象力脑补出一些东西），但也有些不合理之处（比如上面的脸部遮挡例子，这个是无论如何也不能脑补出来的。逼迫模型去学这个，也是不合理的，难说最后学出来的是什么，可能过拟合了）</h3>
<h3 id="第三部分同样出发点倒也没错就是这个损失看起来有些奇怪以cmsp-loss的第一部分为例其实我们可以说这个损失是在以可见光图像的embedding为锚点让红外图像的文字embedding和可见光图像的文字embedding距离这个锚点的距离尽可能接近我猜想作者的目的是让两种文字embedding尽可能接近这样就相当于说让文字embedding尽可能提取出共性的语义信息而不会去提取出矛盾的一方独有的信息如果真是这样它就应该直接约束两个文字embedding了没必要掺和上图像embedding但几何上看要让损失最小它们也可以在一个以可见光图像为圆心的某个圆上只不过是高维的此时它们未必就距离很近这样得到的两种embedding有什么含义呢不能认为说在同一个圆周上语义信息就不矛盾了吧有点怪或者我们认为文字embedding不动优化的是图像embedding这样最理想的情况是图像embedding落在了两种文字embedding的中垂线上了这样就能认为图像embedding没有学到什么矛盾的语义信息吗还是没道理啊又或者上面的分析都是假定了一种embedding是不动的文字图像实际是一起优化的那它想优化什么呢还是不太明白">第三部分，同样，出发点倒也没错，就是这个损失，看起来有些奇怪。以cmsp
loss的第一部分为例，其实我们可以说，这个损失是在以可见光图像的embedding为锚点，让红外图像的文字embedding和可见光图像的文字embedding距离这个锚点的距离尽可能接近。我猜想作者的目的是，让两种文字embedding尽可能接近，这样就相当于说让文字embedding尽可能提取出共性的语义信息，而不会去提取出矛盾的/一方独有的信息（如果真是这样，它就应该直接约束两个文字embedding了，没必要掺和上图像embedding？但几何上看，要让损失最小，它们也可以在一个以可见光图像为“圆心”的某个“圆”上（只不过是高维的）。此时它们未必就距离很近。这样得到的两种embedding有什么含义呢？不能认为说，在同一个圆周上，语义信息就不矛盾了吧？有点怪。或者我们认为，文字embedding不动，优化的是图像embedding？这样最理想的情况是，图像embedding落在了两种文字embedding的“中垂线”上了。这样就能认为图像embedding没有学到什么矛盾的语义信息吗？还是没道理啊。又或者上面的分析都是假定了一种embedding是不动的（文字/图像），实际是一起优化的。那它想优化什么呢？还是不太明白。。</h3>
<h1 id="prototype-driven-multi-feature-generation-for-visible-infrared-person-re-identification">Prototype-Driven
Multi-Feature Generation for Visible-Infrared Person
Re-identification</h1>
<h2 id="icassp2024.9.9">ICASSP，2024.9.9</h2>
<h2 id="动机其实感觉不太明确似乎是魔改完有效果了就开始讲故事了">动机其实感觉不太明确，似乎是魔改完有效果了，就开始讲故事了</h2>
<h2 id="insight提出一个mfgm来获取多样特征但其实不是很新奇了跟deen差不多的思路就是多几个分支加上一些损失约束让这些生成的特征不太一样用一个prototype来提取特征感觉本质只是11的卷积跨模态用同一套模板然后又用一个损失来约束模板提取不同的特征和上面约束生成特征的差不多这里只是换了个cos的套子拉近同id特征拉远不同id特征来确保特征的语义信息的正确性">insight：提出一个MFGM来获取多样特征（但其实不是很新奇了，跟DEEN差不多的思路，就是多几个分支加上一些损失约束，让这些生成的特征不太一样）；用一个prototype来提取特征（感觉本质只是1×1的卷积），跨模态用同一套模板，然后又用一个损失来约束模板提取不同的特征（和上面约束生成特征的差不多，这里只是换了个cos的套子），拉近同ID特征，拉远不同ID特征，来确保特征的语义信息的正确性</h2>
<h2 id="动机-1">动机：</h2>
<h2 id="方法-2">方法：</h2>
<h3 id="提出的pdm框架主要是两个组成部分分别是multi-feature-generation-modulemfgm用于生成更多多样的特征参考deen和prototype-learning-moduelplm">提出的PDM框架，主要是两个组成部分，分别是Multi-Feature
Generation Module（MFGM）（用于生成更多多样的特征，参考DEEN）和Prototype
Learning Moduel（PLM）</h3>
<h3 id="mfgm感觉真的和deen很像都是用几个分支生成多几个特征然后分支上都有dilation-convolution之后又用一些损失来把某些特征拉远以实现多样化特征这里的损失就是文中的center-guided-pair-mining-loss">MFGM感觉真的和DEEN很像，都是用几个分支，生成多几个特征，然后分支上都有dilation
convolution，之后又用一些损失来把某些特征拉远，以实现“多样化”特征（这里的损失就是文中的Center-guided
Pair Mining Loss</h3>
<h3 id="plm的话可能是我论文看少了相对没那么常见但它这里提出prototype也不是一般的为了保留知识而是为了提取知识它的大概思想和cnn里的卷积核差不多吧因为对卷积核的一种理解就是它学到了一些特定的模式然后用卷积操作来进行模式匹配这里提取知识也是类似的用一组可学习的prototype类比卷积核来和图像进行哈达玛积再求均值类比卷积操作并且是两种模态的数据用同一组prototype所以以此来促进跨模态的共性知识提取但怎么保证prototype提取的就一定是局部信息呢仅仅是因为prototype的形状是cchannel维的向量吗这样的话倒是能稍微解释一下为什么不直接用一个cnn了或者说这其实就是一种特殊的cnn只不过是11卷积了这么说来其实还是讲故事啊">PLM的话，可能是我论文看少了，相对没那么常见，但它这里提出prototype也不是一般的为了保留知识，而是为了提取知识。它的大概思想和CNN里的卷积核差不多吧，因为对卷积核的一种理解就是，它学到了一些特定的模式，然后用卷积操作来进行模式匹配；这里提取知识也是类似的，用一组可学习的prototype（类比卷积核），来和图像进行哈达玛积，再求均值（类比卷积操作），并且是两种模态的数据用同一组prototype，所以以此来促进跨模态的共性知识提取（但怎么保证prototype提取的就一定是局部信息呢，仅仅是因为prototype的形状是c（channel）维的向量吗，这样的话倒是能稍微解释一下为什么不直接用一个CNN了，或者说这其实就是一种特殊的CNN，只不过是1×1卷积了。这么说来，其实还是讲故事啊。。）</h3>
<h3 id="此外为了保证它的不同prototype提取出的特征也尽可能多样提出了cosine-heterogeneity-loss其实很老套了跟欧氏距离差不多只不过这里换成了用cos还有一个dual-center-seperation-loss这个损失似乎并没有说明它解决了什么问题感觉很可能只是为了提点而已本身它的思想也很常见了就是换个法子让同id的特征近一点不同id的特征远一点">此外，为了保证它的不同prototype提取出的特征也尽可能多样，提出了Cosine
Heterogeneity
Loss（其实很老套了，跟欧氏距离差不多，只不过这里换成了用cos），还有一个Dual-Center
Seperation
Loss（这个损失似乎并没有说明它解决了什么问题，感觉很可能只是为了提点而已。本身它的思想也很常见了，就是换个法子让同id的特征近一点，不同id的特征远一点）</h3>
<h1 id="parameter-hierarchical-optimization-for-visible-infrared-person-re-identification">Parameter
Hierarchical Optimization for Visible-Infrared Person
Re-Identification</h1>
<h2 id="arxiv2024.4.11">arxiv，2024.4.11</h2>
<h2 id="好像确实有点新奇把参数划分为两种类型一种是正常在深度学习中用梯度反传来优化一种是基于一些规则来优化应该是比较传统的那种以此来减少需要梯度反传来优化的参数这个是可以减少一些计算量但其它好处呢基于规则来优化效果有保证吗原理是什么还提出一个sas可以把红外可见光两种模态的图像相互转化这个倒是可以看看最后还有一个一致性学习估摸着是提出某个损失又是拉近同id的不同模态的特征之间的距离回头看看猜对没">好像确实有点新奇？把参数划分为两种类型，一种是正常在深度学习中用梯度反传来优化，一种是基于一些规则来优化（应该是比较传统的那种），以此来减少需要梯度反传来优化的参数（这个是可以减少一些计算量，但其它好处呢？基于规则来优化，效果有保证吗？原理是什么？）。还提出一个SAS，可以把红外/可见光两种模态的图像相互转化。这个倒是可以看看。最后还有一个一致性学习，估摸着是提出某个损失，又是拉近同ID的不同模态的特征之间的距离。。。回头看看猜对没</h2>
<h1 id="bidirectional-multi-step-domain-generalization-for-visible-infrared-person-re-identification">Bidirectional
Multi-Step Domain Generalization for Visible-Infrared Person
Re-Identification</h1>
<h2 id="arxiv2024.3.16">arxiv，2024.3.16</h2>
<h2 id="这篇论文想解决改善的点在于大部分方法都是把vis和ir-images投影到一个公共空间然后用这个空间里的embedding进行相似度匹配这种方法叫所谓单中间域生成而论文提到这个方法提取的信息不够好因为它可能提取出了一些公共的背景信息而这部分信息是没用的所以从结果上来说就是单单投影到同一空间效果不够好至于说提取出背景信息不好判断是讲故事还是说真的主要没有实验来辅佐验证论文提出的方法bmdgbidirectional-multi-step-domain-generalization主要由两部分组成一是part-prototype-alignment-learning负责提取出局部的身体部位信息二是bidirectional-multi-step-learning通过多步学习从红外和可见光分别出发以减小modality-gap">这篇论文想解决/改善的点在于，大部分方法都是把vis和ir
images投影到一个公共空间，然后用这个空间里的embedding进行相似度匹配（这种方法叫所谓“单中间域生成”），而论文提到，这个方法提取的信息不够好，因为它可能提取出了一些公共的背景信息，而这部分信息是没用的（所以从结果上来说，就是单单投影到同一空间，效果不够好；至于说提取出背景信息，不好判断是讲故事还是说真的。主要没有实验来辅佐验证）。论文提出的方法BMDG（Bidirectional
Multi-Step Domain Generalization）主要由两部分组成，一是part prototype
alignment learning（负责提取出局部的身体部位信息）；二是bidirectional
multi-step
learning（通过多步学习，从红外和可见光分别出发，以减小modality
gap）</h2>
<h2 id="insight">insight</h2>
<h2 id="动机-2">动机</h2>
<h2 id="方法-3">方法</h2>
<h3 id="part-prototype-alignment-learning主要由三个部分组成">part
prototype alignment learning主要由三个部分组成：</h3>
<h4 id="prototype-discovery这个部分是用来获取身体部位细节信息的并且要在feature-map上挖掘出具有判别性的位置具体来说它的一个prototype的形状是">1.prototype
discovery（这个部分是用来获取身体部位细节信息的，并且要在feature
map上挖掘出具有判别性的位置）。具体来说，它的一个prototype的形状是</h4>
<h1 id="clip-driven-semantic-discovery-network-for-visible-infrared-person-re-identification">CLIP-Driven
Semantic Discovery Network for Visible-Infrared Person
Re-Identification</h1>
<h2 id="tmm2024.1.11">TMM，2024.1.11</h2>
<h2 id="这篇文章又是引入clip好多文章引入了clip看来单纯做vi-reid还在魔改网络的话可能上限不太高了而且太卷了又不创新所以试着引入clip提高能力也显得创新一点文章的大体的亮点出发点在于利用clip的获取图像语义信息的能力提取一些高层语义信息用来辅助检索图像这个和前面eees那篇embedding-and-enriching-explicit-semantics-for-visible-infrared-person-re-identification的出发点有点类似">这篇文章又是引入clip（好多文章引入了clip，看来单纯做vi-reid，还在魔改网络的话，可能上限不太高了，而且太卷了，又不创新；所以试着引入clip，提高能力，也“显得”创新一点。文章的大体的亮点/出发点在于，利用clip的获取图像语义信息的能力，提取一些高层语义信息，用来辅助检索图像。这个和前面EEES那篇（Embedding
and Enriching Explicit Semantics for Visible-Infrared Person
Re-Identification）的出发点有点类似</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/01/18/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/RAG/Retrieval-Augmented%20Generation%20for%20%20AI-Generated%20Content%20%20A%20Survey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/18/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/RAG/Retrieval-Augmented%20Generation%20for%20%20AI-Generated%20Content%20%20A%20Survey/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-01-18 21:48:08" itemprop="dateCreated datePublished" datetime="2025-01-18T21:48:08+08:00">2025-01-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-01-19 10:49:54" itemprop="dateModified" datetime="2025-01-19T10:49:54+08:00">2025-01-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="结构可以从下面几个部分来阅读总结论文">1.结构：可以从下面几个部分来阅读、总结论文</h1>
<h2 id="介绍一下rag中的基本概念">1.0.介绍一下RAG中的基本概念</h2>
<h2 id="根据retriever是如何辅助生成内容的对rag技术进行分类这个在文章中被称为underlinefoundational-paradigms简称underlinefoundations">1.1.根据retriever是如何辅助生成内容的，对RAG技术进行分类（这个在文章中被称为<span class="math inline">\(\underline{foundational \
paradigms}\)</span>，简称<span class="math inline">\(\underline{foundations}\)</span></h2>
<h2 id="总结一下其它的提高rag的手段">1.2.总结一下其它的提高RAG的手段</h2>
<h2 id="调研rag在不同模态数据和不同任务下的应用场景文本的搜索和rag应该是目前最常见也是研究最多的但-不同模态数据的检索其实也可能为文本rag带来一些启发而一些常见的不同模态的检索包括但不限于识图听歌识曲">1.3.调研RAG在不同模态数据和不同任务下的应用场景（文本的搜索和RAG应该是目前最常见、也是研究最多的。但
不同模态数据的检索，其实也可能为文本RAG带来一些启发。而一些常见的不同模态的检索，包括但不限于识图、听歌识曲）</h2>
<h2 id="介绍一下rag的benchmark并讨论现有rag系统的一些问题局限性也讨论了一下未来的发展方向">1.4.介绍一下RAG的benchmark，并讨论现有RAG系统的一些问题/局限性，也讨论了一下未来的发展方向</h2>
<h1 id="preliminary-of-rag">2.preliminary of RAG</h1>
<h2 id="overview">2.1.overview</h2>
<h3 id="rag系统一般就是包含两个核心模块retriever和generatorretriever用于根据用户的请求进行检索把找到的一些相关信息和输入一起给generator让它进行生成这就是一个大致的流程-我们可以分为三步">RAG系统一般就是包含两个核心模块：retriever和generator。retriever用于根据用户的请求进行检索，把找到的一些相关信息和输入一起给generator，让它进行生成。这就是一个大致的流程。
我们可以分为三步：</h3>
<h4 id="retriever根据输入请求检索相关信息">1.retriever根据输入请求检索相关信息</h4>
<h4 id="原来的请求比如生成图像的时候我们的指令就是原来的请求和检索的结果一起给到generator这里如何把检索的结果和原来的请求进行结合是非常关键的一步也是对rag进行分类的一个判据可能是结合的方式不同可能是结合的位置不同">2.原来的请求（比如，生成图像的时候，我们的指令就是“原来的请求”）和检索的结果一起给到generator（这里如何把检索的结果和原来的请求进行结合，是非常关键的一步，也是对RAG进行分类的一个判据。可能是结合的方式不同，可能是结合的位置不同）</h4>
<h4 id="generator生成结果">3.generator生成结果</h4>
<h3 id="rag中generator主要包括transformer-modellstmdiffusion-modelgan">RAG中，generator主要包括transformer
model，LSTM，diffusion model，GAN</h3>
<h3 id="retriever主要分三类sparse-retrieverdense-retrieverothers-sparse-retriever感觉主要是传统的方法通常用于文档索引就是nlp课上讲的那些比较古老的方法-dense-retriever核心思想是用一些embedding来对query和key进行表征之后通过衡量query和key之间的相似性找出和query相似性高的那些key对应的结果就是检索结果这里有两个关键点一个是embedding一般是用一些预训练好的大模型对数据进行编码这种方法和sparse-retriever中用词袋模型等简单的统计模型进行的表征不同那些简单统计模型我的理解是考虑的信息更加简单局部以及通常会比较稀疏而相比之下深度学习进行编码得到的embedding则更加复杂但也包含更多信息也不会非常稀疏这应该也是为什么这种方法叫dense-retriever另一个关键点就是检索哪些key和query相似性高当数据量很大的时候想根据一个query计算它和所有key之间的相似性再来排序筛选计算量就太大了更别说多个query的情况了所以需要用到最近邻近似approximate-nearest-neighborann方法它的目的就是实现高效的最近邻搜索-others主要是在衡量相似性或者检索上有一些不同也是依据使用场景而定的如对文本我们可以直接用类似于最小编辑距离的指标进行相似度衡量而不是用embedding表示再衡量key和query之间的相似度对于代码我们也可以考虑用抽象语法树abstract-syntax-treesast来衡量代码片段相似度在知识图谱中我们进行检索其实就可以根据节点之间的关系进行索引比如对知识图谱的某个节点进行k-hop邻居搜索这些方法其实都算不上通用吧只是在一些特定领域里可能是可以用的但效果也不好说一定就比上面的dense-retriever要好">retriever主要分三类，sparse
retriever，dense retriever，others<br>sparse
retriever感觉主要是传统的方法，通常用于文档索引（就是nlp课上讲的那些比较古老的方法）<br>dense
retriever核心思想是，用一些embedding来对query和key进行表征，之后通过衡量query和key之间的相似性，找出和query相似性高的那些key，对应的结果就是检索结果。这里有两个关键点，一个是embedding，一般是用一些预训练好的大模型对数据进行编码。这种方法和sparse
retriever中用词袋模型等简单的统计模型进行的表征不同（那些简单统计模型，我的理解是，考虑的信息更加简单、局部，以及通常会比较稀疏；而相比之下，深度学习进行编码得到的embedding，则更加复杂、但也包含更多信息，也不会非常稀疏。这应该也是为什么这种方法叫dense
retriever）。另一个关键点就是检索哪些key和query相似性高。当数据量很大的时候，想根据一个query，计算它和所有key之间的相似性，再来排序、筛选，计算量就太大了，更别说多个query的情况了。所以需要用到最近邻近似（Approximate
Nearest
Neighbor，ANN）方法。它的目的就是实现高效的最近邻搜索<br>others主要是在衡量相似性或者检索上有一些不同，也是依据使用场景而定的。如，对文本，我们可以直接用类似于最小编辑距离的指标进行相似度衡量，而不是用embedding表示再衡量key和query之间的相似度；对于代码，我们也可以考虑用抽象语法树（Abstract
Syntax
Trees，AST）来衡量代码片段相似度；在知识图谱中，我们进行检索，其实就可以根据节点之间的关系进行索引，比如对知识图谱的某个节点进行k-hop邻居搜索。（这些方法其实都算不上通用吧，只是在一些特定领域里可能是可以用的，但效果也不好说一定就比上面的dense
retriever要好）</h3>
<h1 id="rag-foundations">3.RAG Foundations</h1>
<h2 id="query-based-rag">3.1.Query-based RAG</h2>
<h3 id="其实就是在把输入送到generator之前把retriever获得的信息一起融合得到一个新的输入再把新的输入送到generator也即feed-the-retrieved-information-directly-into-the-initial-stage-of-the-generators-input这里的directly和initial-stage很重要和后面的方法不同">其实就是在把输入送到generator之前，把retriever获得的信息一起融合，得到一个新的输入，再把新的输入送到generator。也即，feed
the retrieved information directly into the initial stage of the
generator's input（这里的directly和initial
stage很重要，和后面的方法不同）</h3>
<h2 id="latent-representation-based-rag">3.2.Latent Representation-based
RAG</h2>
<h3 id="这里的核心思想是把检索到的信息进行编码同时把原本的query也进行编码再将编码后的二者进行一个结合此处结合的手段也很多有大家魔改出来的模块也有经典模块如cross-attention">这里的核心思想是，把检索到的信息进行编码，同时把原本的query也进行编码，再将编码后的二者进行一个结合。此处结合的手段也很多，有大家魔改出来的模块，也有经典模块，如Cross
Attention</h3>
<h3 id="经典方法如fid">经典方法如FiD</h3>
<h2 id="logit-based-rag">3.3.Logit-based RAG</h2>
<h3 id="这种方法主要适用于序列生成的情形generator正常会在生成下一个token的时候有一个候选token概率分布而检索到的信息也可以用于获取一个概率分布可视为一种先验概率分布再把两种概率分布进行结合就得到最终的概率分布因为是从概率分布的角度上讲所以是logit-based">这种方法主要适用于序列生成的情形。generator正常会在生成下一个token的时候，有一个候选token概率分布；而检索到的信息，也可以用于获取一个概率分布（可视为一种先验概率分布），再把两种概率分布进行结合，就得到最终的概率分布。因为是从概率分布的角度上讲，所以是“Logit-based”</h3>
<h3 id="经典方法有knn-lm">经典方法有kNN-LM</h3>
<h2 id="speculative-rag">3.4.Speculative RAG</h2>
<h3 id="这个看着有点像是用rag代替了generator">这个看着有点像是用RAG代替了generator</h3>
<h1 id="rag-enhancements">4.RAG Enhancements</h1>
<h2 id="根据enhance的目标对象不同进行分类分五类input-enhancementretriever-enhancementgenerator-enhancementresult-enhancementrag-pipeline-enhancement">根据enhance的目标对象不同，进行分类。分五类：Input
Enhancement，Retriever Enhancement，Generator Enhancement，Result
Enhancement，RAG Pipeline Enhancement</h2>
<h2 id="input-enhancement">4.1.Input Enhancement</h2>
<h3 id="这类方法从输入上入手可以对query进行变换即query-transformation也可以对检索结果进行增强data-augmentation">这类方法从输入上入手。可以对query进行变换（即Query
Transformation），也可以对检索结果进行增强（Data Augmentation）</h3>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/01/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/MM-LLMs--Recent%20Advances%20in%20MultiModal%20Large%20Language%20Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/MM-LLMs--Recent%20Advances%20in%20MultiModal%20Large%20Language%20Models/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-01-08 10:27:51 / Modified: 10:31:09" itemprop="dateCreated datePublished" datetime="2025-01-08T10:27:51+08:00">2025-01-08</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="这是一篇survey主要内容包括一下几个方面列出了常用的模型架构和训练流程对常见的mm-llms截至2024.2进行分类主要依据模型的specific-formulations回顾部分挑出的模型在主流benchmark上的性能并总结一下关键的训练语料配比探索一下mm-llms未来比较有前景的发展方向">这是一篇survey。主要内容包括一下几个方面：列出了常用的模型架构和训练流程；对常见的MM-LLMs（截至2024.2）进行分类（主要依据模型的specific
formulations）；回顾部分挑出的模型在主流benchmark上的性能，并总结一下关键的训练语料配比；探索一下MM-LLMs未来比较有前景的发展方向</h1>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/01/02/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/theory/On%20Layer%20Normalization%20in%20the%20Transformer%20Architecture/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/02/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/theory/On%20Layer%20Normalization%20in%20the%20Transformer%20Architecture/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-01-02 20:10:52" itemprop="dateCreated datePublished" datetime="2025-01-02T20:10:52+08:00">2025-01-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-01-04 10:41:43" itemprop="dateModified" datetime="2025-01-04T10:41:43+08:00">2025-01-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="icml2020pkumsra">ICML2020，pku，msra</h1>
<h1 id="authorsruibin-xiong-1-2-yunchang-yang-3-di-he-4-5-kai-zheng-4-shuxin-zheng-5-chen-xing-6-huishuai-zhang-5-yanyan-lan-1-2-liwei-wang-4-3-tie-yan-liu-5">authors：Ruibin
Xiong†* 1 2 Yunchang Yang* 3 Di He 4 5 Kai Zheng 4 Shuxin Zheng 5 Chen
Xing 6 Huishuai Zhang 5 Yanyan Lan 1 2 Liwei Wang 4 3 Tie-Yan Liu 5</h1>
<h1 id="problemmotivationtransformer模型极为常用但训练它的时候通常需要一个精心设计的warm-up阶段实验表明这一步对最终的性能表现影响很大但加上这个步骤却减缓了优化的速度同时需要调更多的参数所以本质上我们希望不需要warm-up也能达到同样好的性能这样优化的速度更快调参的工作量也少了这个工作的意义在训练大型模型的时候才能更加显现出来吧如果只是平时训练解决一些小任务作业之类的意义就没那么大了吧">problem&amp;motivation：transformer模型极为常用。但训练它的时候通常需要一个精心设计的warm-up阶段。实验表明，这一步对最终的性能表现影响很大，但加上这个步骤却减缓了优化的速度，同时需要调更多的参数（所以本质上，我们希望不需要warm-up，也能达到同样好的性能。这样优化的速度更快，调参的工作量也少了。这个工作的意义在训练大型模型的时候才能更加显现出来吧，如果只是平时训练，解决一些小任务、作业之类的，意义就没那么大了吧）</h1>
<h1 id="contribution用mean-field-theory证明了为何warm-up阶段很重要且证明了layer-norm的位置也很重要对结果影响很大">contribution：用mean
field theory证明了为何warm-up阶段很重要，且证明了layer
norm的位置也很重要，对结果影响很大</h1>
<h1 id="insight原来的经典transformer架构中它把layer-norm放到了残差连接层后面也就是post-ln而这时输出层的梯度会很大所以如果一开始就用一个比较大的lr它就在这里炸了因此需要warm-up而如果把layer-norm放到residual-blocks里面也就是所谓pre-ln梯度就正常了不会过大此时再去掉warm-up效果是差不多的但是达到了我们最初的目的去掉warm-up优化更快调参更少有没有图可以看一下什么叫putting-the-layer-norm-between-the-residual-blocks">insight：原来的经典transformer架构中，它把layer
norm放到了残差连接层后面，也就是Post-LN。而这时输出层的梯度会很大，所以如果一开始就用一个比较大的lr，它就在这里炸了，因此需要warm-up。而如果把layer
norm放到residual
blocks里面（也就是所谓Pre-LN），梯度就正常了，不会过大。此时再去掉warm-up，效果是差不多的，但是达到了我们最初的目的：去掉warm-up，优化更快，调参更少（有没有图可以看一下什么叫putting
the layer norm between the residual blocks？）</h1>
<h1 id="related-works脉络梳理">related works（脉络梳理）：</h1>
<h2 id="在以往的cnnrnn式的网络中一般都是大lr然后慢慢减小warm-up很少用一般也就是在batch-size很大的时候采用">在以往的cnn/rnn式的网络中，一般都是大lr，然后慢慢减小。warm-up很少用，一般也就是在batch
size很大的时候采用</h2>
<h2 id="后面出现的transformer模型则非常需要warm-up且有论文发现对于post-ln-transformer-model不用用很少的warm-up模型都发散pre-ln-transformer-model也有人提出但它们依然还是需要warm-up">后面出现的transformer模型，则非常需要warm-up（且有论文发现，对于Post-LN
transformer model，不用/用很少的warm-up，模型都发散）。Pre-LN
transformer model也有人提出，但它们依然还是需要warm-up</h2>
<h2 id="有研究认为warm-up的效果来自于对adam优化器里的adaptive-learning-rate的方差进行了限制然而warm-up并不只是对adam优化器起作用即使是用其它优化器的时候warm-up也经常有用下面的实验证明了对于sgd也是有效的所以它的收益应该不来自于这里尽管同期有工作发现pre-ln-transformer可以不需要warm-up但他们是经验上发现结论而这篇论文给出了一个理论的解释">有研究认为warm-up的效果来自于对Adam优化器里的adaptive
learning
rate的方差进行了限制。然而warm-up并不只是对Adam优化器起作用，即使是用其它优化器的时候，warm-up也经常有用（下面的实验证明了，对于SGD也是有效的）（所以它的收益应该不来自于这里）。尽管同期有工作发现Pre-LN
Transformer可以不需要warm-up，但他们是经验上发现结论，而这篇论文给出了一个理论的解释</h2>
<h1 id="optimization-for-the-transformer正文精读">Optimization for the
Transformer（正文精读）</h1>
<h2 id="介绍经典现有transformer结构它主要是由堆叠的transformer-layer组成而每个transformer-layer都有两种sub-layerthe-multi_head-self-attention-sub-layer和the-position-wise-feed-forward-network-sub-layer">1.介绍经典现有Transformer结构。它主要是由堆叠的Transformer
layer组成，而每个Transformer layer都有两种sub-layer：the (multi_head)
self-attention sub-layer和the position-wise feed-forward network
sub-layer</h2>
<h3 id="the-multi-head-self-attention-sub-layer">1.1.the (multi-head)
self-attention sub-layer：</h3>
<h4 id="先一个多头注意力然后是一个残差链接之后是一个ln">先一个多头注意力，然后是一个残差链接，之后是一个LN</h4>
<h3 id="the-position-wise-feed-forward-network-sub-layer">1.2.the
position-wise feed-forward network sub-layer：</h3>
<h4 id="先一个两层前馈网络再一个残差链接之后是一个ln">先一个两层前馈网络，再一个残差链接，之后是一个LN</h4>
<h2 id="改进后的pre-ln还是由这两种sub-layer组成只不过里面的具体顺序稍微调换了一下">2.改进后的Pre-LN，还是由这两种sub-layer组成，只不过里面的具体顺序稍微调换了一下</h2>
<h3 id="the-multi-head-self-attention-sub-layer-1">2.1.the (multi-head)
self-attention sub-layer</h3>
<h4 id="先ln再多头注意力加残差">先LN，再多头注意力加残差</h4>
<h3 id="the-position-wise-feed-forward-network-sub-layer-1">2.2.the
position-wise feed-forward network sub-layer</h3>
<h4 id="先ln再两层前馈加残差">先LN，再两层前馈加残差</h4>
<h2 id="实验结果">3.实验结果</h2>
<h3 id="实验目的实验部分主要想研究的是warm-up-stage具体来说想要探讨的是">3.1.实验目的：实验部分主要想研究的是warm-up
stage，具体来说，想要探讨的是：</h3>
<h4 id="warm-up阶段是否重要有多重要">1.warm-up阶段是否重要（有多重要）</h4>
<h4 id="模型性能对于warm-up的迭代次数t_warmup是否敏感">2.模型性能对于warm-up的迭代次数<span class="math inline">\(T_{warmup}\)</span>是否敏感</h4>
<h3 id="实验设计">3.2.实验设计：</h3>
<h4 id="做一个机器翻译的任务即iwslt14-german-to-englishde-enmachine-translation-task">做一个机器翻译的任务，即IWSLT14
German-to-English（De-En）machine translation task</h4>
<h4 id="对于第一个问题实验考虑用两种优化器adam和sgd变量主要在于warmup-iterations-t_warmup-adam在一个固定的初始学习率上做三组实验t_warmup15004000这里的1代表不进行warmup所以后面的结果就能看出有没有warmup的模型性能差异就能验证warm-up-stage是否重要同时500和4000两种不同的warmup-iterations也能来验证模型性能是否对t_warmup很敏感虽然感觉这里做的实验有点少了不应该再多试几个t_warmup嘛此外每种优化器的初始学习率会尝试两种5e-4和1e-3">对于第一个问题，实验考虑用两种优化器（Adam和SGD），变量主要在于warmup
iterations <span class="math inline">\(T_{warmup}\)</span>
。Adam在一个固定的初始学习率上，做三组实验（<span class="math inline">\(T_{warmup}=1/500/4000\)</span>（这里的1代表不进行warmup。所以后面的结果就能看出有没有warmup的模型性能差异，就能验证warm-up
stage是否重要。同时，500和4000两种不同的warmup
iterations，也能来验证模型性能是否对<span class="math inline">\(T_{warmup}\)</span>很敏感（虽然感觉这里做的实验有点少了，不应该再多试几个<span class="math inline">\(T_{warmup}\)</span>嘛？（此外，每种优化器的初始学习率会尝试两种，5e-4和1e-3
）</h4>
<h4 id="sgd也是类似只是用它做实验的时候t_warmup只尝试了1和4000">SGD也是类似，只是用它做实验的时候，<span class="math inline">\(T_{warmup}\)</span>只尝试了1和4000</h4>
<h3 id="结果分析">3.3.结果分析：</h3>
<h4 id="首先对于两种优化器来说无论是用validation-loss还是bleu指标都是用warmup的效果比不用warmup的效果要好这证明了warmup在训练transformer中的重要性">首先，对于两种优化器来说，无论是用validation
loss还是BLEU指标，都是用warmup的效果比不用warmup的效果要好。这证明了warmup在训练Transformer中的重要性</h4>
<h4 id="其次warm-up阶段确实是对t_warmup很敏感的如果用的是原论文推荐的4000效果就比500要好得多总感觉实验做少了">其次，warm-up阶段确实是对<span class="math inline">\(T_{warmup}\)</span>很敏感的。如果用的是原论文推荐的4000，效果就比500要好得多（总感觉实验做少了。。。）</h4>
<h2 id="理论解析">4.理论解析</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2024/12/19/%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/%E5%AE%89%E8%A3%85apex==0.1%E5%8F%8A%E5%8F%AF%E8%83%BD%E7%9A%84%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/12/19/%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/%E5%AE%89%E8%A3%85apex==0.1%E5%8F%8A%E5%8F%AF%E8%83%BD%E7%9A%84%E9%97%AE%E9%A2%98/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-12-19 15:30:23" itemprop="dateCreated datePublished" datetime="2024-12-19T15:30:23+08:00">2024-12-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-01-10 03:53:53" itemprop="dateModified" datetime="2025-01-10T03:53:53+08:00">2025-01-10</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="不知道是不是apex库的0.1版本用的比较多啊反正前几天配idkl的环境的时候它是要求装这个版本的但是它也不给个详细的步骤只说要装这个库不纯折磨人嘛">不知道是不是apex库的0.1版本用的比较多啊，反正前几天配IDKL的环境的时候它是要求装这个版本的，但是它也不给个详细的步骤，只说要装这个库，不纯折磨人嘛</h1>
<h1 id="说回来可以参考这个教程但是需要注意一下如果是apex0.1版本则clone库的时候要选择22.04-dev的branchclone那个别直接git-clone-网址了clone指定branch的库应该是有个特殊的命令的可以问问aiclone了对的库之后就可以按照教程里的做了从它的第2步开始然后关于它的第3步我安装的时候是没加-user的也成功了应该就是哪个指令能成功就用哪个">说回来，可以参考这个<a target="_blank" rel="noopener" href="https://blog.csdn.net/piaoliangjinjin/article/details/137566614">教程</a>（但是需要注意一下，如果是apex0.1版本，则clone库的时候要选择22.04-dev的branch，clone那个，别直接git
clone
+网址了。（clone指定branch的库应该是有个特殊的命令的，可以问问ai）。clone了对的库之后，就可以按照教程里的做了（从它的第2步开始）（然后关于它的第3步，我安装的时候是没加-user的，也成功了，应该就是哪个指令能成功就用哪个）</h1>
<h1 id="如果要安装其它版本的apex就需要根据自己的torch版本和cuda版本进行选择了未必就是apex库的22.04-dev-branch的内容了或许可以参考这个教程但我没试过它这里提到可以一次多试几个版本感觉有点麻烦了不知道有没有对应的版本可以查询的">如果要安装其它版本的apex，就需要根据自己的torch版本和cuda版本进行选择了，未必就是apex库的22.04-dev
branch的内容了。或许可以参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_33440910/article/details/134812895?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-134812895-blog-137566614.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3">这个教程</a>（但我没试过）（它这里提到可以一次多试几个版本，感觉有点麻烦了，不知道有没有对应的版本可以查询的）</h1>
<h1 id="另外有可能运行代码的时候会遇到这个报错-indexerror-tuple-index-out-of-range可以参考这个链接的解决方法反正我试过一次是可行的">另外，有可能运行代码的时候会遇到这个报错：
‘IndexError: tuple index out of range‘，可以参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/starvapour/article/details/122275439">这个链接</a>的解决方法，反正我试过一次，是可行的</h1>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2024/12/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/Lifelong-VI-ReID/Adaptive%20Middle%20Modality%20Alignment%20Learning%20for%20Visible-Infrared%20Person%20Re-identification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2024/12/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/Lifelong-VI-ReID/Adaptive%20Middle%20Modality%20Alignment%20Learning%20for%20Visible-Infrared%20Person%20Re-identification/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2024-12-15 01:02:57 / Modified: 13:13:14" itemprop="dateCreated datePublished" datetime="2024-12-15T01:02:57+08:00">2024-12-15</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="ijcv24实际是23年10月投的24年才中的">ijcv24（实际是23年10月投的，24年才中的）</h1>
<h1 id="一点吐槽这个跨模态数据集里有一些红外数据本身的质量真的差到不行啊这样子人也没办法来重识别啊说到底数据已经决定了模型的上限了啊">一点吐槽：这个跨模态数据集里，有一些红外数据本身的质量真的差到不行啊，这样子，人也没办法来重识别啊，说到底，数据已经决定了模型的上限了啊</h1>
<h1 id="等会得看看它所谓的自适应中间模态到底是怎样的如果还是把两种模态的数据投影到一个公共的模态那和之前的方法的本质就没区别啊真正有区别的应该是说把rgb模态的投影到一个中间模态1把ir模态的投影到一个中间模态2然后去拉近中间模态1和中间模态2-至少这样是看起来更为合理的如果原来rgb和ir模态差距太大了不好一口气直接投影到一个公共的空间那么就一步一步来有点像扩散模型那样扩散模型也是如果想直接从噪声里还原出一幅图像那可能太难了所以它才一步一步地往回逆向这样讲故事起码是更合理的事实上或许还可以尝试多套几个中间模态看看最终的中间模态会不会效果更好">等会得看看它所谓的自适应中间模态，到底是怎样的，如果还是把两种模态的数据投影到一个公共的模态，那和之前的方法的本质就没区别啊。。真正有区别的，应该是说，把rgb模态的投影到一个中间模态1，把ir模态的投影到一个中间模态2，然后去拉近中间模态1和中间模态2
。至少这样是看起来更为合理的：如果原来rgb和ir模态差距太大了，不好一口气直接投影到一个公共的空间，那么就一步一步来。有点像扩散模型那样。扩散模型也是，如果想直接从噪声里还原出一幅图像，那可能太难了，所以它才一步一步地往回逆向。这样讲故事起码是更合理的。事实上，或许还可以尝试，多套几个中间模态，看看最终的中间模态会不会效果更好？</h1>
<h1 id="method">method：</h1>
<h2 id="提出adaptive-middle-modality-generator-amg-module它可以生成一种中间模态的图像后续会用到但它的输入是谁哪种模态的图像">1.提出Adaptive
Middle-modality Generator (AMG)
module，它可以生成一种中间模态的图像，后续会用到（但它的输入是谁？哪种模态的图像？）</h2>
<h3 id="详细讲解">详细讲解：</h3>
<h4 id="这个module有两个submodule一个是middle-modality-generator-mmg-sub-module一个是adaptive-middle-modality-mixup-amm-sub-module先从宏观上看这里两个submodule的作用是mmg根据输入的一对同id的rgb和ir图像各自生成一个中间模态数据也就是会用rgb的数据生成一个中间数据1再用ir数据生成一个中间数据2-而amm则会根据上面的两个中间数据进行一个mixup操作最终得到一个中间模态数据这个数据就是之后要用的">这个module有两个submodule，一个是Middle-modality
Generator (MMG) Sub-module，一个是Adaptive Middle-modality Mixup (AMM)
Sub-module。先从宏观上看，这里两个submodule的作用是，MMG根据输入的一对同id的rgb和ir图像，各自生成一个中间模态数据（也就是会用rgb的数据生成一个中间数据1，再用ir数据生成一个中间数据2
。而AMM则会根据上面的两个中间数据，进行一个mixup操作，最终得到一个中间模态数据。这个数据就是之后要用的</h4>
<h4 id="可以说它确实相比之前的方法有改进了吧它是用两个分支去处理输入的两种模态的数据主要是一些11的卷积层毕竟经常要进行channel数的变换另外一个比较合理的地方在于它并没有说用一个11的卷积层就完了而是还加上了一个relu这里我觉得是很有道理的如果单纯是卷积而卷积的本质就是加权求和只用卷积相当于说你认为仅靠加权求和就能把rgb数据和ir数据的通道信息给投影到一个统一空间这不太对吧rgb数据的通道信息明显丰富多了你要说同一id的rgb数据和ir数据之间的关系仅仅是一种线性关系感觉没道理的并且它也引用了论文说了这之中的关系是高度非线性的所以引入一个relu层看起来操作层面上是很简单的但这个解释明显是能自圆其说的">可以说，它确实相比之前的方法有改进了吧。它是用两个分支去处理输入的两种模态的数据，主要是一些1×1的卷积层（毕竟经常要进行channel数的变换）。另外一个比较合理的地方在于，它并没有说，用一个1×1的卷积层就完了，而是还加上了一个relu。这里我觉得是很有道理的。如果单纯是卷积，而卷积的本质就是加权求和，只用卷积，相当于说你认为仅靠加权求和就能把rgb数据和ir数据的通道信息给投影到一个统一空间。这不太对吧，rgb数据的通道信息明显丰富多了，你要说同一id的rgb数据和ir数据之间的关系，仅仅是一种线性关系，感觉没道理的。并且它也引用了论文，说了这之中的关系是高度非线性的，所以引入一个relu层。看起来操作层面上是很简单的，但这个解释明显是能自圆其说的</h4>
<h4 id="mmg模块会根据rgb数据和ir数据各自生成单通道的中间数据和三通道的中间数据而amm会用单通道的中间数据来算mixup的时候两种模态的factor之后会把mmg生成的三通道的中间数据进行mixup得到最终的中间数据">MMG模块会根据rgb数据和ir数据，各自生成单通道的中间数据和三通道的中间数据。而AMM会用单通道的中间数据来算mixup的时候，两种模态的factor，之后会把MMG生成的三通道的中间数据进行mixup，得到最终的中间数据</h4>
<h4 id="好繁琐啊">（好繁琐啊。。。）</h4>
<h2 id="提出adaptive-distribution-alignment-ada-loss会拉近中间模态数据特征的分布和rgbir模态数据特征的分布的距离是一种从特征层面入手的措施这里的话术是拉近特征的分布嗯分布感觉有点玄乎有待商榷不过可以学习一下他们都是怎么去挖掘利用拉近分布信息的尤其注意这个分布它和下面的第三个method有些联系">2.提出Adaptive
Distribution Alignment (ADA)
loss，会拉近中间模态数据特征的分布和rgb，ir模态数据特征的分布的距离，是一种从特征层面入手的措施（这里的话术是，拉近特征的分布。。嗯，分布，感觉有点玄乎，有待商榷）（不过可以学习一下，他们都是怎么去挖掘、利用、拉近分布信息的）（尤其注意这个分布，它和下面的第三个method有些联系）</h2>
<h2 id="提出center-based-diverse-distribution-learning-cddl-loss它会拉近rgb和ir模态与中间模态的特征之间的距离注意这里不是说分布了如果这里还是说分布那就和上面的2矛盾了也会去拉近rgb和ir模态数据特征之间的距离按他说的这样既可以学到多样的特征应该就是指通过拉远rgbir模态与中间模态的距离让中间模态学到一些不一样的知识这个操作和之前的deen那篇很像啊然后是经典的拉近rgb和ir模态特征之间的距离这个真不能少主要想一下如果只是拉远了rgbir模态特征与中间模态特征的距离两个东西都离同一个东西很远这未必就说明这两个东西本身就离得很近所以保底的措施还是要的但这也让人怀疑如果你有这种担忧了为什么要去做这个拉远rgbir模态与中间模态的特征之间的距离-这个操作呢说白了这个操作本身就不好说到底会不会影响我们的保底措施即直接拉近rgb和ir模态特征之间的距离的效果它自己单独也未必有用只能说加上这个操作是为了学到一些不一样的知识吧也就是中间模态里含有的知识当然也需要看看他是怎么利用这个中间模态的知识的别学完了不用那就纯浪费了而且就是纯为了创新而创新了">3.提出Center-based
Diverse Distribution Learning (CDDL)
loss，它会拉近rgb和ir模态与中间模态的特征之间的距离（注意，这里不是说分布了。如果这里还是说分布，那就和上面的2矛盾了），也会去拉近rgb和ir模态数据特征之间的距离。（按他说的，这样既可以学到多样的特征——应该就是指通过拉远rgb/ir模态与中间模态的距离，让中间模态学到一些不一样的知识。这个操作和之前的DEEN那篇很像啊。。。然后是经典的拉近rgb和ir模态特征之间的距离。这个真不能少。主要想一下，如果只是拉远了rgb/ir模态特征与中间模态特征的距离，两个东西都离同一个东西很远，这未必就说明这两个东西本身就离得很近。所以保底的措施还是要的。但这也让人怀疑，如果你有这种担忧了，为什么要去做这个拉远rgb/ir模态与中间模态的特征之间的距离
这个操作呢？说白了，这个操作本身，就不好说到底会不会影响我们的保底措施（即直接拉近rgb和ir模态特征之间的距离）的效果，它自己单独也未必有用。只能说，加上这个操作，是为了学到一些不一样的知识吧，也就是中间模态里含有的知识。当然，也需要看看他是怎么利用这个中间模态的知识的，别学完了不用，那就纯浪费了，而且就是纯为了创新而创新了</h2>
<h2 id="一些问题虽然说2操作的是分布3操作的是特征本身没有直接的矛盾但这样23一起用就相当于希望irrgb中间模态三者的特征的分布是一致的但是具体的特征上ir和rgb希望尽可能一致而希望中间模态对应的特征与它们不一样这合理吗如果中间模态的特征尽可能不一样那还能说它的特征分布和rgbir的特征分布比较接近吗说到底这种树立一个公共敌人朋友的方法到底有没有效果不是很好说啊">一些问题：虽然说，2操作的是分布，3操作的是特征，本身没有直接的矛盾，但这样2，3一起用，就相当于希望ir/rgb/中间模态三者的特征的分布是一致的，但是具体的特征上，ir和rgb希望尽可能一致，而希望中间模态对应的特征与它们不一样。这合理吗？如果中间模态的特征尽可能不一样，那还能说它的特征分布和rgb/ir的特征分布比较接近吗？说到底，这种树立一个公共敌人/朋友的方法，到底有没有效果，不是很好说啊</h2>
<h2 id="总体来说这个方法的目标就是通过构造一个中间模态训练的时候同时用三种模态的数据以此来拉近rgbir模态的数据之间的距离这是最终目的">总体来说，这个方法的目标，就是通过构造一个中间模态，训练的时候同时用三种模态的数据，以此来拉近rgb/ir模态的数据之间的距离（这是最终目的）</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/9/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><a class="extend next" rel="next" href="/page/11/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">bluemouse</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">147</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">71</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bluemouse</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
