<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueeemouse.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="bluemouse&#39;s blog">
<meta property="og:url" content="https://blueeemouse.github.io/page/13/index.html">
<meta property="og:site_name" content="bluemouse&#39;s blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="bluemouse">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueeemouse.github.io/page/13/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>bluemouse's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">bluemouse's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/04/04/%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85torch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/04/04/%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85torch/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-04-04 18:02:59" itemprop="dateCreated datePublished" datetime="2025-04-04T18:02:59+08:00">2025-04-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-04-14 22:15:57" itemprop="dateModified" datetime="2025-04-14T22:15:57+08:00">2025-04-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="虽然已经安装了很多遍不过每次都是得查一下版本对应然后pip-install但通常都不会太顺利总得出点幺蛾子可能是网络问题吧不过想快一点还是可以试试用whl文件首先就是确定一下要装什么版本的torch之后去这个网址里找到对应版本和系统的torchtorchvision的whl文件下载下来然后conda激活要装到的那个虚拟环境pip-install-whl文件的路径即可torchaudio的话似乎一般不装也行吧这个感觉除非是做语音的不然好像还真是一点用不到至少我现在就没用过">虽然已经安装了很多遍，不过每次都是得查一下版本对应，然后pip
install，但通常都不会太顺利，总得出点幺蛾子。可能是网络问题吧。不过想快一点，还是可以试试用whl文件。首先就是确定一下要装什么版本的torch，之后去<a target="_blank" rel="noopener" href="https://download.pytorch.org/whl/torch_stable.html">这个网址</a>里找到对应版本和系统的torch，torchvision的whl文件，下载下来，然后conda激活要装到的那个虚拟环境，pip
install
whl文件的路径，即可（torchaudio的话，似乎一般不装也行吧，这个感觉除非是做语音的，不然好像还真是一点用不到，至少我现在就没用过）</h1>
<h2 id="另外有个小点我本来还以为windows系统里装的时候得区分是amd还是intel但看了一下那个网址里并没有intel也没有x86只有amd一开始还奇怪后来发现就是这个">另外，有个小点，我本来还以为windows系统里装的时候得区分是amd还是intel，但看了一下那个网址里，并没有intel，也没有x86，只有amd，一开始还奇怪，后来发现就是这个。。。</h2>
<h1 id="btw似乎在pip-install的时候指定这个网址--extra-index-url-httpsdownload.pytorch.orgwhlcu117-也可以例如">btw，似乎在pip
install的时候，指定这个网址--extra-index-url
https://download.pytorch.org/whl/cu117 也可以。例如，</h1>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117</span><br></pre></td></tr></table></figure>
<h1 id="这样指定好版本之后再指定下载的网址这个网址实际就是各种whl文件的网址让它自己在这个网址里找似乎也是可以的当然要注意网址和库的版本的对应">这样。指定好版本之后，再指定下载的网址。这个网址实际就是各种whl文件的网址。让它自己在这个网址里找，似乎也是可以的。当然要注意网址和库的版本的对应</h1>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/03/20/%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/%E8%AE%A9%E7%BB%88%E7%AB%AF%E4%B8%8D%E8%A6%81%E8%BF%9B%E5%85%A5%E9%BB%98%E8%AE%A4%E7%9A%84base%E7%8E%AF%E5%A2%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/20/%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/%E8%AE%A9%E7%BB%88%E7%AB%AF%E4%B8%8D%E8%A6%81%E8%BF%9B%E5%85%A5%E9%BB%98%E8%AE%A4%E7%9A%84base%E7%8E%AF%E5%A2%83/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-03-20 16:19:19 / Modified: 16:23:22" itemprop="dateCreated datePublished" datetime="2025-03-20T16:19:19+08:00">2025-03-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="问题描述安装完condaminiconda-之后一旦激活那么每次打开终端命令行前面就会有base的字样其实就是每次启动终端都会自动激活conda的基础环境这个嘛以前我倒是挺介意的不过现在已经习惯了但好歹记录一下吧以前的懒得解决的一个小问题">问题描述：安装完conda/miniconda
之后，一旦激活，那么每次打开终端，命令行前面就会有(base)的字样，其实就是每次启动终端，都会自动激活conda的基础环境。这个嘛，以前我倒是挺介意的，不过现在已经习惯了，但好歹记录一下吧，以前的懒得解决的一个小问题</h1>
<h1 id="解决方法">解决方法：</h1>
<h2 id="每次都通过conda-deactivate当然可以退出这个默认环境但也有点麻烦永久的方法的话就是修改一下终端的配置文件让它不要每次一启动就激活conda即可具体就是执行以下命令">每次都通过conda
deactivate当然可以退出这个默认环境，但也有点麻烦。永久的方法的话，就是修改一下终端的配置文件，让它不要每次一启动就激活conda即可。具体就是执行以下命令</h2>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda config --<span class="built_in">set</span> auto_activate_base <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<h2 id="如果之后又想自动激活了那就把false改为true再执行一次即可">如果之后又想自动激活了，那就把false改为true，再执行一次即可</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/03/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/VI-ReID/%E6%B3%9B%E8%AF%BB/%E6%B3%9B%E8%AF%BB2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/VI-ReID/%E6%B3%9B%E8%AF%BB/%E6%B3%9B%E8%AF%BB2/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-03-14 23:27:03" itemprop="dateCreated datePublished" datetime="2025-03-14T23:27:03+08:00">2025-03-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-03-18 14:31:41" itemprop="dateModified" datetime="2025-03-18T14:31:41+08:00">2025-03-18</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="robust-multimodal-learning-via-representation-decoupling">Robust
Multimodal Learning via Representation Decoupling</h1>
<h1 id="eccv-24">ECCV 24</h1>
<h1 id="motivation">motivation：</h1>
<h1 id="insight">insight：</h1>
<h1 id="方法">方法</h1>
<h2 id="方法的第一节其实没讲新东西而是从一个具体的任务分类任务入手说明了一下为什么传统的学习方法会限制模型的表达能力">1.方法的第一节其实没讲新东西，而是从一个具体的任务——分类任务入手，说明了一下为什么传统的学习方法会限制模型的表达能力</h2>
<h2 id="decoupled-multimodal-representation">2.Decoupled Multimodal
Representation</h2>
<h3 id="这一节主要讲如何缓解上面提到的问题同类的不同模态的数据被强制约束要靠近同一个中心导致模型表达能力降低">这一节主要讲如何缓解上面提到的问题：同类的不同模态的数据被强制约束要靠近同一个中心，导致模型表达能力降低</h3>
<h3 id="首先是prepresentation-probabilization具体来说对得到的embedding我们不直接利用它而是再用它去建立一个分布这里假设是多元高斯分布所以我们会用这个embedding送到两个网络分别预测高斯分布的均值和标准差的对数这个也算是常见的技巧了吧预测标准差这种恒正的量可能预测取对数后的值是更加容易优化的也是更加稳定的建立好分布之后训练时的embedding就是从分布里采样得到的当然为了能优化这个分布的均值和标准差用到了重参数化方法而测试的时候的embedding就是均值向量和dkp的操作几乎完全一样但可能是概率建模embedding的方法并不是特别稀奇吧">首先是Prepresentation
Probabilization。具体来说，对得到的embedding，我们不直接利用它，而是再用它去建立一个分布，这里假设是多元高斯分布。所以我们会用这个embedding，送到两个网络，分别预测高斯分布的均值和标准差的对数（这个也算是常见的技巧了吧。预测标准差这种恒正的量，可能预测取对数后的值是更加容易优化的，也是更加稳定的）。建立好分布之后，训练时的embedding就是从分布里采样得到的（当然，为了能优化这个分布的均值和标准差，用到了重参数化方法）。而测试的时候的embedding就是均值向量（和DKP的操作几乎完全一样。。但可能是概率建模embedding的方法并不是特别稀奇吧）</h3>
<h3 id="通过建立分布现在每个数据的分布的均值并不一定要完全地相互靠近可以稍微远离一点也没关系因为是从一个分布里采样训练的embedding的因此此时的均值向量可以更加多样化一些论文认为这样的话模型能捕捉到更多模态特有的特征显然标准差越大不确定性越大均值向量之间可能离得更加远了但标准差过高是不好的所以需要加一些约束让它不要太随机了故引出下面的distributional-regularizaiton">通过建立分布，现在每个数据的分布的均值并不一定要完全地相互靠近，可以稍微远离一点也没关系，因为是从一个分布里采样训练的embedding的。因此，此时的均值向量可以更加多样化一些，论文认为这样的话，模型能捕捉到更多模态特有的特征（显然，标准差越大，不确定性越大，均值向量之间可能离得更加远了。但标准差过高是不好的，所以需要加一些约束，让它不要太随机了。故引出下面的Distributional
Regularizaiton）</h3>
<h3 id="所谓distributional-regularization就是对建立的分布我们会施加一个它和标准正态分布之间的kl损失这里我的一个理解是往正态分布上约束是可以让标准差不要太大但为什么还要约束均值呢让所有分布都往同一个分布上靠拢似乎也有点奇怪但论文里说是受其它用概率建模embedding的论文的启发才这样做的姑且可以认为是一个比较常见的手段但为什么这样并没有说的很清楚">所谓Distributional
Regularization，就是对建立的分布，我们会施加一个它和标准正态分布之间的KL损失（这里我的一个理解是，往正态分布上约束，是可以让标准差不要太大。但为什么还要约束均值呢？让所有分布都往同一个分布上靠拢？似乎也有点奇怪。但论文里说是受其它用概率建模embedding的论文的启发，才这样做的。姑且可以认为是一个比较常见的手段，但为什么这样，并没有说的很清楚。。。）</h3>
<h2 id="hard-combination-regularizer">3.Hard Combination
Regularizer</h2>
<h3 id="具体原理还没特别明白可能得再细看但它大概的思想以及作用是针对比较少出现的组合论文是处理多模态的输入的假设有k种模态一个输入里未必同时有这k个模态的数据k种模态是否出现一共会有2k种组合形式设计专门的梯度计算模块以免模型对这类组合处理的太差了有点对少样本进行重采样的感觉">具体原理还没特别明白，可能得再细看。。。但它大概的思想以及作用是，针对比较少出现的组合（论文是处理多模态的输入的，假设有k种模态，一个输入里未必同时有这k个模态的数据。k种模态是否出现，一共会有<span class="math inline">\(2^{k}\)</span>种组合形式），设计专门的梯度计算模块，以免模型对这类组合处理的太差了（有点对少样本进行重采样的感觉。。）</h3>
<h1 id="cross-modality-transformer-with-modality-mining-for-visible-infrared-person-re-identification">CROSS-MODALITY
TRANSFORMER WITH MODALITY MINING FOR VISIBLE-INFRARED PERSON
RE-IDENTIFICATION</h1>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/03/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/foundation/Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/foundation/Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-03-11 16:48:45 / Modified: 23:54:15" itemprop="dateCreated datePublished" datetime="2025-03-11T16:48:45+08:00">2025-03-11</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="insight">insight：</h1>
<h1 id="motivation">motivation：</h1>
<h2 id="在此之前视觉预训练的模型通常是用大量数据针对某一个任务进行训练比如分类任务这样得到的预训练模型局限性比较大因为它只能局限在一个特定类型的任务不方便迁移到其它任务迁移到其它下游任务都需要对应的数据进行微调而我们希望的一个好的预训练模型应该能做到比较方便地迁移到各种下游任务">在此之前，视觉预训练的模型通常是用大量数据，针对某一个任务进行训练（比如分类任务）。这样得到的预训练模型局限性比较大，因为它只能局限在一个特定类型的任务，不方便迁移到其它任务。迁移到其它下游任务，都需要对应的数据进行微调。而我们希望的一个好的预训练模型，应该能做到：比较方便地迁移到各种下游任务</h2>
<h2 id="另外一部分愿意也是当时nlp领域里用自监督预训练得到的模型效果特别好迁移到各种不同的下游任务效果都不错zero-shot能力很强相比之下当时cv领域就还是用大量有标签数据进行预训练下游微调的范式而大量标注数据是极其费时费力的所以自然cv领域里也有人想模仿nlp领域也用自监督来预训练但效果不尽如人意一个重要的点就在于规模之前cv领域里想尝试自监督它们用到的模型和数据量都远比nlp领域里的小clip做的一个改进就是设计了一个便于scale-up的架构从而模型大起来了数据量也大起来了效果也上来了">另外一部分愿意，也是当时nlp领域里用自监督预训练得到的模型效果特别好，迁移到各种不同的下游任务效果都不错，zero-shot能力很强。相比之下，当时cv领域就还是用大量有标签数据进行预训练+下游微调的范式。而大量标注数据是极其费时费力的。所以自然cv领域里也有人想模仿nlp领域，也用自监督来预训练。但效果不尽如人意。一个重要的点就在于规模。之前cv领域里想尝试自监督，它们用到的模型和数据量都远比nlp领域里的小。clip做的一个改进就是设计了一个便于scale
up的架构，从而模型大起来了，数据量也大起来了，效果也上来了</h2>
<h1 id="方法">方法</h1>
<h2 id="构建数据集">1.构建数据集</h2>
<h3 id="这里的第一步是构建一个足够大的图像-文本数据对因为预训练的任务就是用到图像-文本数据对的之前常用的几个数据集比如ms-cocovisual-genome质量虽然够高但太小了大约100000而另一个比较大的数据集yfcc100m有大约100-million张图像量级确实够了但它是质量又不够高筛完之后大约只有15-million了一千五百万这和扩展之后的imagenet是差不多量级的imagenet-21k有大约21k个类别约1400万张图像所以确实得自己构造">这里的第一步是构建一个足够大的图像-文本数据对（因为预训练的任务就是用到图像-文本数据对的）。之前常用的几个数据集，比如MS-COCO，Visual
Genome质量虽然够高，但太小了（大约100000）。而另一个比较大的数据集，YFCC100M，有大约100
million张图像，量级确实够了，但它是质量又不够高。筛完之后，大约只有15
million了（一千五百万），这和扩展之后的ImageNet是差不多量级的（ImageNet-21k，有大约21k个类别，约1400万张图像）。所以确实得自己构造</h3>
<h3 id="它构造的大致流程是根据一定方法筛选出高频的有意义的query500000个query然后用这些query在网上进行搜索并获取数据同时为了防止数据的不平衡限制了每个query的结果最多不超过20000个图像-文本对最终得到的数据集是400-million个数据对这和gpt-2的预训练语料差不多大了那边的叫webtext-dataset这里构造出来的就叫做webimagetextwit">它构造的大致流程是，根据一定方法，筛选出高频的，有意义的query（500000个query），然后用这些query在网上进行搜索并获取数据（同时为了防止数据的不平衡，限制了每个query的结果最多不超过20000个图像-文本对）。最终得到的数据集是400
million个数据对，这和GPT-2的预训练语料差不多大了。那边的叫WebText
dataset，这里构造出来的就叫做WebImageText（WIT）</h3>
<h2 id="selecting-an-efficient-pre-training-method">2.Selecting an
Efficient Pre-Training Method</h2>
<h3 id="之前的用文本-图像对来训练的方法是训练一个cnn来提取图像特征还有一个text-transformer接受图像特征之后要预测生成图像的caption还有一个baseline就是仍然训练一个cnn文字部分则是用词袋模型来编码之后会把提取出来的图像特征进行投影希望能得到对应的文本的词袋向量这两个方法进行比较会发现用transformer那个特别慢具体来说就是它得用很多的数据才能做到和baseline差不多的效果论文里给出结果大概是3倍的数据的关系">之前的用文本-图像对来训练的方法，是训练一个CNN来提取图像特征，还有一个text
transformer，接受图像特征之后，要预测生成图像的caption。还有一个baseline，就是，仍然训练一个CNN，文字部分则是用词袋模型来编码，之后会把提取出来的图像特征进行投影，希望能得到对应的文本的词袋向量。这两个方法进行比较，会发现：用transformer那个，特别”慢“。具体来说，就是它得用很多的数据才能做到和baseline差不多的效果。论文里给出结果，大概是3倍的数据的关系</h3>
<h3 id="另一方面近期的工作表明对比式的目标函数比预测式的目标函数效果要好所以论文也进行了一个替换把任务从根据图像特征预测对应文本变成根据图像特征匹配相应的文本这个任务更加简单训练的时候给定n个文本-图像对我们的训练目标就是把匹配的文本和图像特征之间尽可能拉近把不匹配的文本和图像特征之间尽可能拉远且实验上表明它的效果非常好模型学习起来的时候很快只需要用大概baseline的四分之一的数据量就能达到同一个效果当然是指定了一个精度的前提下具体可以看论文的图">另一方面，近期的工作表明对比式的目标函数比预测式的目标函数效果要好，所以论文也进行了一个替换，把任务从根据图像特征预测对应文本，变成根据图像特征，匹配相应的文本。这个任务更加简单（训练的时候，给定N个文本-图像对，我们的训练目标就是把匹配的文本和图像特征之间尽可能拉近，把不匹配的文本和图像特征之间尽可能拉远），且实验上表明它的效果非常好，模型学习起来的时候很快，只需要用大概baseline的四分之一的数据量就能达到同一个效果（当然是指定了一个精度的前提下。具体可以看论文的图）</h3>
<h2 id="choosing-and-scaling-a-model">3.Choosing and Scaling a
Model</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/03/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/Unified-ReID/Instruct-ReID++%EF%BC%9ATowards%20Universal%20Purpose%20%20Instruction-Guided%20Person%20Re-identification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/Unified-ReID/Instruct-ReID++%EF%BC%9ATowards%20Universal%20Purpose%20%20Instruction-Guided%20Person%20Re-identification/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-03-11 11:36:57 / Modified: 15:06:36" itemprop="dateCreated datePublished" datetime="2025-03-11T11:36:57+08:00">2025-03-11</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="motivation现在reid相关的研究有很多不同的设定不同的设定就需要用不同的方法没有一个好用的统一的框架方法且现在绝大多数的检索都是用图像来检索图像然而如果是人来检索还可以通过自然语言的描述来进行检索所以论文提出一套统一的框架尝试解决方法不统一的问题同时加入用文字描述来进行检索的功能进一步提高方法的实用性显然会有一些只能用文字描述来检索图像的场景比如找犯人时可能没有犯人的照片但有被害人的证词">motivation：现在reid相关的研究，有很多不同的设定，不同的设定就需要用不同的方法，没有一个好用的统一的框架/方法。且，现在绝大多数的检索都是用图像来检索图像，然而如果是人来检索，还可以通过自然语言的描述来进行检索。所以，论文提出一套统一的框架，尝试解决方法不统一的问题，同时加入用文字描述来进行检索的功能，进一步提高方法的实用性（显然会有一些只能用文字描述来检索图像的场景。比如，找犯人时，可能没有犯人的照片，但有被害人的证词）</h1>
<h1 id="insight">insight：</h1>
<h1 id="方法">方法：</h1>
<h2 id="instruction-generation">1.Instruction Generation</h2>
<h3 id="论文之所以能把各种任务统一起来就是因为它用了一个框架query-imageinstructiongallery-image不同的设定就由instruction来指定所以instruction是非常重要的">论文之所以能把各种任务统一起来，就是因为它用了一个框架，Query
image+instruction+Gallery
image，不同的设定就由instruction来指定。所以instruction是非常重要的</h3>
<h2 id="model-architecture-of-irm">2.Model Architecture of IRM</h2>
<h3 id="这里先介绍一下irm的架构这个irm就是可以统一处理各种设定的reid任务的模型它和之后的irm有些不同">这里先介绍一下IRM的架构（这个IRM就是可以统一处理各种设定的reid任务的模型。它和之后的IRM++有些不同）</h3>
<h3 id="简单来说它有三大部分一个是instruction-encoder-epsilon_i用于处理文字的instruction把它变成特征向量f_t这里的encoder是一个visual-language-model之所以是visual-language-model而不是单纯的文字模态的模型应该是为了把文字投影到一个图像和文字公共的空间里以便后续进行图像和文字信息的融合否则单独用一个语言模型把文字投影到一个文字模态的特征空间后续也不好用来和图像进行融合-二是editing-transformer-epsilon_e它会把图像特征和文字特征一起当作输入用于获取经过文字指导后的图像特征f-三是一个attention-module-epsilon_f它的输入是文字特征f_t和融合特征f输出即为最终特征f_out主要功能是把文字信息和图像信息进一步融合其实理论上来讲前面的f应该就已经完成了文字和图像信息的融合了这里还来和文字信息一起输入应该就是单纯的想强化一下instruction了毕竟instruction承担的是指示任务类型的作用还是很重要的否则甚至会把任务类型搞错了">简单来说，它有三大部分，一个是instruction
encoder <span class="math inline">\(\epsilon_{i}\)</span>，用于处理文字的instruction，把它变成特征向量<span class="math inline">\(F_{T}\)</span>（这里的encoder是一个visual language
model。之所以是visual language
model，而不是单纯的文字模态的模型，应该是为了把文字投影到一个图像和文字公共的空间里，以便后续进行图像和文字信息的融合。否则单独用一个语言模型，把文字投影到一个文字模态的特征空间，后续也不好用来和图像进行融合）<br>二是editing
transformer <span class="math inline">\(\epsilon_{e}\)</span>，它会把图像特征和文字特征一起当作输入，用于获取经过文字指导后的图像特征<span class="math inline">\(F\)</span><br>三是一个attention module <span class="math inline">\(\epsilon_{f}\)</span>，它的输入是文字特征<span class="math inline">\(F_{T}\)</span>和融合特征<span class="math inline">\(F\)</span>，输出即为最终特征<span class="math inline">\(F_{out}\)</span>，主要功能是把文字信息和图像信息进一步融合（其实理论上来讲，前面的<span class="math inline">\(F\)</span>应该就已经完成了文字和图像信息的融合了。这里还来和文字信息一起输入，应该就是单纯的想强化一下instruction了。毕竟instruction承担的是指示任务类型的作用，还是很重要的，否则甚至会把任务类型搞错了）</h3>
<h3 id="这里训练的损失除了经典的分类损失还有一个论文提出的adaptive-triplet-loss对这个损失我的理解是它是针对同一id的融合了不同instruction的特征进行区分的具体来说假如有两幅图像都是id-0的样本但它们的instruction不同所以理论上图像和文字信息融合之后得到的最终特征f_out也应该尽可能远离本质上看这个损失是为了提高模型对指令的跟随和区分能力这个之所以创新也是因为这篇论文是用instruction的形式来做reid吧确实是一个新任务下的难点-则此时构造的triplet是一个anchor和一个正样本我的理解是同id且和anchor同样instruction以及一个负样本我的理解是同id但和anchor不同instruction然而看论文似乎和anchor同instruction也可以但这样的话这个损失大概率就是0意义不大了-看公式l_atrifrac1n_trisum_i1n_tri-signbeta_1-beta_2df_iaf_ir1beta_1-beta_2m-df_iaf_ir2它的中括号里第一项应该就是anchor和正样本之间的距离我们是希望它尽可能小的第二项是margin因为它是和beta_1beta_2相关的而beta_1beta_2又是和具体的三元组相关的所以它是随数据而变化的故称为所谓的adaptive-triplet-loss减去的第三项是anchor和负样本之间的距离我们希望它尽可能大从而减掉它之后整体会尽可能小损失会尽可能小到这整体是没什么问题的都是常见的思路-下面再仔细看一下中间第二项的自适应marginbeta的计算公式是beta_jiy_ay_r_jcosf_taf_tr_j它的含义是若两个数据的id相同则度量它们的instruction之间的距离这里我们先只考虑id相同的情况则beta度量的就单纯是指令之间的距离指令越相似beta越大那么回到上面的l_atri如果正样本和anchor的instruction尽可能相似乃至完全一样则beta_1就越发接近1而如果负样本和anchor之间的instruction非常不同则beta_2会尽可能接近-1此时beta_1-beta_2就会越大越接近2故margin就会越大这代表了什么呢-可以理解为同一id的数据它们遵循的instruction如果差距越大则我们希望融合了instruction之后的图像特征也应该尽可能差距大这样模型就相当于对指令有了比较好的区分能力它知道指令之间是不同的也知道即使是同一个id的特征融合了不同的指令信息之后就是不同的应该分离的此时模型应当是很好地理解了指令的也就能更好地跟随指令了故margin也应该越大因为margin大代表我们对它们的区分能力要求越高">这里训练的损失，除了经典的分类损失，还有一个论文提出的adaptive
triplet
loss。对这个损失，我的理解是，它是针对同一id的，融合了不同instruction的特征进行区分的。具体来说，假如有两幅图像，都是id
0的样本，但它们的instruction不同，所以理论上图像和文字信息融合之后得到的最终特征<span class="math inline">\(F_{out}\)</span>也应该尽可能远离。（本质上看，这个损失是为了提高模型对指令的跟随和区分能力。这个之所以创新，也是因为这篇论文是用instruction的形式来做reid吧。确实是一个新任务下的难点）<br>则此时构造的triplet是一个anchor，和一个正样本（我的理解是，同id，且和anchor同样instruction），以及一个负样本（我的理解是，同id，但和anchor不同instruction。然而看论文，似乎和anchor同instruction也可以。但这样的话这个损失大概率就是0，意义不大了）<br>看公式<span class="math display">\[L_{atri}=\frac{1}{N_{tri†}}\sum_{i=1}^{N_{tri†}}\{
Sign(\beta_{1}-\beta_{2})[d(F_{i}^{a},F_{i}^{r1})+(\beta_{1}-\beta_{2})m-d(F_{i}^{a},F_{i}^{r2})]\}\]</span>它的中括号里，第一项应该就是anchor和正样本之间的距离，我们是希望它尽可能小的；第二项是margin，因为它是和<span class="math inline">\(\beta_{1},\beta_{2}\)</span>相关的，而<span class="math inline">\(\beta_{1},\beta_{2}\)</span>又是和具体的三元组相关的，所以它是随数据而变化的，故称为所谓的adaptive
triplet
loss，减去的第三项是anchor和负样本之间的距离，我们希望它尽可能大，从而减掉它之后整体会尽可能小，损失会尽可能小。到这，整体是没什么问题的，都是常见的思路<br>下面再仔细看一下中间第二项的自适应margin。<span class="math inline">\(\beta\)</span>的计算公式是：<span class="math inline">\(\beta_{j}=I(y_{a}=y_{r_{j}})Cos&lt;F_{T}^{a},F_{T}^{r_{j}}&gt;\)</span>。它的含义是，若两个数据的id相同，则度量它们的instruction之间的距离。这里我们先只考虑id相同的情况，则<span class="math inline">\(\beta\)</span>度量的就单纯是指令之间的距离。指令越相似，<span class="math inline">\(\beta\)</span>越大。那么，回到上面的<span class="math inline">\(L_{atri}\)</span>，如果正样本和anchor的instruction尽可能相似乃至完全一样，则<span class="math inline">\(\beta_{1}\)</span>就越发接近1；而如果负样本和anchor之间的instruction非常不同，则<span class="math inline">\(\beta_{2}\)</span>会尽可能接近-1，此时<span class="math inline">\(\beta_{1}-\beta_{2}\)</span>就会越大（越接近2），故margin就会越大。这代表了什么呢？<br>可以理解为，同一id的数据，它们遵循的instruction如果差距越大，则我们希望，融合了instruction之后的图像特征也应该尽可能差距大，这样模型就相当于对指令有了比较好的区分能力，它知道指令之间是不同的，也知道即使是同一个id的特征，融合了不同的指令信息之后就是不同的，应该分离的。此时模型应当是很好地理解了指令的，也就能更好地跟随指令了（故margin也应该越大，因为margin大代表我们对它们的区分能力要求越高）</h3>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/03/02/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/Language%20Models%20Encode%20the%20Value%20of%20Numbers%20Linearly/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/02/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/Language%20Models%20Encode%20the%20Value%20of%20Numbers%20Linearly/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-03-02 16:15:06 / Modified: 17:05:09" itemprop="dateCreated datePublished" datetime="2025-03-02T16:15:06+08:00">2025-03-02</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="section"></h1>
<h1 id="动机">动机</h1>
<h1 id="贡献">贡献</h1>
<h1 id="insight">insight</h1>
<h1 id="方法">方法</h1>
<h2 id="需要说明的是这个文章并不是一般的要在某个指标上刷点而是想探究一下大模型的一种编码数字的机理工作方式所以正文里讲的主要是实验的思路和相对应的设计与实验结果">需要说明的是，这个文章并不是一般的要在某个指标上刷点，而是想探究一下大模型的一种编码数字的机理/工作方式，所以正文里讲的主要是实验的思路和相对应的设计与实验结果。</h2>
<h2 id="大体思路大模型对数字的编码信息应该就包含模型的隐状态里理论上如果它真的编码进去了那应该是有某种函数可以将其提取出来的这个函数的形式很难知晓所以不妨用神经网络来拟合而这篇文章则是考虑这个函数的形式是一个线性的所以打算用一个linear-probe也就是单个线性层来把hidden-states映射到相应的数字然而这只是一开始的设想之后文章提到考虑到数据集里涉及的数字的跨度很大有很小的有很大的直接用线性层拟合可能效果并不好所以它实际要预测的是取了对数的结果这样看其实标题里所谓的encode-linearly就是说llm先把数取个对数再用一种线性的方式编码得到隐状态">1.大体思路：大模型对数字的编码信息，应该就包含模型的隐状态里。理论上如果它真的编码进去了，那应该是有某种函数可以将其提取出来的。这个函数的形式很难知晓，所以不妨用神经网络来拟合。而这篇文章则是考虑，这个函数的形式是一个线性的，所以打算用一个linear
probe（也就是单个线性层）来把hidden
states映射到相应的数字。然而这只是一开始的设想。之后文章提到，考虑到数据集里涉及的数字的跨度很大，有很小的，有很大的，直接用线性层拟合，可能效果并不好，所以它实际要预测的是取了对数的结果（这样看，其实标题里所谓的Encode
Linearly，就是说，llm先把数取个对数，再用一种线性的方式编码，得到隐状态）</h2>
<h2 id="评价指标主要是评价两方面linear-probe探测得到的结果与输入的相关性linear-probe得到的结果的准确性相关性会用决定系数r2和皮尔逊相关系数rho来评价准确性则是先对预测的结果取个2指数因为我们预测的结果是实际数以2为底取对数的结果以期望线性层的参数会比较稳定然后再与实际的数进行比较用msemean-square-error和aaccapproximate-accuracy来比较其实就是衡量预测的结果和实际的数之间的差距">2.评价指标：主要是评价两方面，linear
probe探测得到的结果与输入的相关性；linear
probe得到的结果的准确性。相关性会用决定系数<span class="math inline">\(R^{2}\)</span>和皮尔逊相关系数<span class="math inline">\(\rho\)</span>来评价；准确性则是先对预测的结果取个2指数（因为我们预测的结果是实际数以2为底取对数的结果，以期望线性层的参数会比较稳定），然后再与实际的数进行比较，用MSE（Mean
Square Error）和AAcc（Approximate
accuracy）来比较，其实就是衡量预测的结果和实际的数之间的差距</h2>
<h2 id="一些结论">3.一些结论：</h2>
<h3 id="llm确实编码了数字">3.1.llm确实编码了数字：</h3>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/02/20/%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/%E6%9C%AA%E5%91%BD%E5%90%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/20/%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/%E6%9C%AA%E5%91%BD%E5%90%8D/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-02-20 18:07:32 / Modified: 18:10:05" itemprop="dateCreated datePublished" datetime="2025-02-20T18:07:32+08:00">2025-02-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>虚拟环境的python升级版本以后，似乎所有库都需要重新装了。。。</p>
<p>高版本faiss似乎可以替换那个什么idx_long的那个东西</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/02/18/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/Unsupervised-Lifelong-VI-ReID/motivation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/18/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/Unsupervised-Lifelong-VI-ReID/motivation/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-02-18 15:21:48" itemprop="dateCreated datePublished" datetime="2025-02-18T15:21:48+08:00">2025-02-18</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/02/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/Unsupervised-Lifelong-ReID/Unsupervised%20Lifelong%20Person%20Re-identification%20%20via%20Contrastive%20Rehearsal/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/Unsupervised-Lifelong-ReID/Unsupervised%20Lifelong%20Person%20Re-identification%20%20via%20Contrastive%20Rehearsal/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-02-17 22:22:45 / Modified: 23:22:13" itemprop="dateCreated datePublished" datetime="2025-02-17T22:22:45+08:00">2025-02-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="arxiv-22">arxiv 22</h1>
<h1 id="这篇论文提出的设定倒是在现实生活里有意义不过它的动机好像也是提的比较模糊都是针对几个设定加起来的时候产生的问题">这篇论文提出的设定倒是在现实生活里有意义，不过它的动机好像也是提的比较模糊，都是针对几个设定加起来的时候产生的问题</h1>
<h1 id="它讲的故事however-a-real-world-video-monitoring-system-can-record-new-data-every-day-and-from-new-locations-when-new-cameras-are-added-into-an-existing-system.when-new-data-is-recorded-every-day-people-have-to-annotate-new-data-manually-before-deployment-which-is-cumbersome-and-time-consuming.这里在说明无监督方法研究的必要性-towards-a-generalizable-reid-model-lifelong-person-reid-has-been-recently-proposed这里在说明lifelong-learning研究的必要性">它讲的故事：However,
a real-world video monitoring system can record new data every day and
from new locations, when new cameras are added into an existing
system.；When new data is recorded every day, people have to annotate
new data manually before deployment, which is cumbersome and
time-consuming.（这里在说明，无监督方法研究的必要性）<br>Towards a
generalizable ReID model, lifelong person ReID has been recently
proposed（这里在说明，lifelong learning研究的必要性）</h1>
<h1 id="它的方法设计的倒也算简单就是分别针对灾难性遗忘学习新数据的问题">它的方法，设计的倒也算简单，就是分别针对灾难性遗忘、学习新数据的问题</h1>
<h1 id="方法">方法</h1>
<h2 id="current-domain-contrastive-baseline">1.Current domain
contrastive baseline</h2>
<h3 id="它主要是进行经典的拉近样本和簇中心的距离如今已经是一个非常常见的操作了还有一个l_cam就是对同一个簇里属于同一个相机的数据也求一个prototype就是这些数据的均值并要拉近样本与这个prototype的距离还是对比损失的形式">它主要是进行经典的拉近样本和簇中心的距离（如今已经是一个非常常见的操作了），还有一个<span class="math inline">\(L_{cam}\)</span>，就是对同一个簇里，属于同一个相机的数据，也求一个prototype（就是这些数据的均值），并要拉近样本与这个prototype的距离（还是对比损失的形式）</h3>
<h4 id="不过论文里还提到l_cam过于依赖相机标签局限在了reid任务里了如果想更加泛化其实也有其它的损失可以用比如在一个batch里与batch里的hardest-positives进行对比">不过，论文里还提到，<span class="math inline">\(L_{cam}\)</span>过于依赖相机标签，局限在了ReID任务里了；如果想更加泛化，其实也有其它的损失可以用，比如在一个batch里，与batch里的hardest
positives进行对比</h4>
<h4 id="另注意这个方法会有online-encoder和momentum-encoder在这一步里聚类用的特征是momentum-encoder得到的而不是online-encoder">（另，注意，这个方法会有online
encoder和momentum encoder；在这一步里，聚类用的特征是momentum
encoder得到的，而不是online encoder）</h4>
<h2 id="old-domain-contrastive-rehearsal">2.Old domain contrastive
rehearsal</h2>
<h3 id="这个方法里会存储一些旧数据集的prototype也就是我们得到的簇中心的特征以及各个簇的若干个可靠样本就是比较接近簇中心的这一步的核心思想是给定一个已知伪标签的旧数据样本我们希望当前的online-encoder对其编码后得到的特征应该还是尽可能接近原来它所属的那个簇由此我们认为online-encoder对旧数据集知识的保存做的比较好">这个方法里会存储一些旧数据集的prototype（也就是我们得到的簇中心的特征），以及各个簇的若干个可靠样本（就是比较接近簇中心的）。这一步的核心思想是，给定一个已知伪标签的旧数据样本，我们希望当前的online
encoder对其编码后，得到的特征应该还是尽可能接近原来它所属的那个簇（由此我们认为online
encoder对旧数据集知识的保存做的比较好）</h3>
<h2 id="image-to-image-similarity-constraint">3.Image-to-Image
Similarity Constraint</h2>
<h3 id="这一步的作用是抗遗忘然后它的核心思想是给定一个batch我们用encoder得到特征后可以得到一个样本之间的相似性矩阵如果新模型得到的相似性矩阵与旧模型得到的相似性矩阵很接近对于同一个batch而言那么我们就认为这个新模型保留旧知识时保留得比较好论文里新模型就对应online-encoder旧模型就对应momentum-encoder它保留了比较多的旧知识衡量两个相似性矩阵的距离时用的是kl散度">这一步的作用是抗遗忘，然后它的核心思想是，给定一个batch，我们用encoder得到特征后，可以得到一个样本之间的相似性矩阵。如果新模型得到的相似性矩阵与旧模型得到的相似性矩阵很接近（对于同一个batch而言），那么我们就认为这个新模型保留旧知识时，保留得比较好。论文里，新模型就对应online
encoder，旧模型就对应momentum
encoder（它保留了比较多的旧知识）。衡量两个相似性矩阵的距离时，用的是KL散度</h3>
<h3 id="但此处有个小改进就是它的目标矩阵确实是用旧模型得到的但它的新的相似性矩阵计算的时候求行特征用的是新模型求列特征用的是旧模型论文里说这样的效果比单纯用新模型会好确实有一些道理吧因为求列特征用的是旧模型那么要迫使两个相似性矩阵尽可能接近就要求新模型的输出要尽可能接近旧模型的输出无形中其实就进行了蒸馏了吧">但此处有个小改进，就是，它的目标矩阵确实是用旧模型得到的，但它的新的相似性矩阵，计算的时候，求行特征用的是新模型，求列特征用的是旧模型。论文里说这样的效果比单纯用新模型会好。确实有一些道理吧，因为求列特征用的是旧模型，那么，要迫使两个相似性矩阵尽可能接近，就要求新模型的输出要尽可能接近旧模型的输出（无形中其实就进行了蒸馏了吧）</h3>
<h1 id="trick总结">trick总结</h1>
<h2 id="在进行对比的时候既可以和所有的prototype来对比也可以挑出若干个hard-sample保证效果的同时减少一些计算量">1.在进行对比的时候，既可以和所有的prototype来对比，也可以挑出若干个hard
sample，保证效果的同时减少一些计算量</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/02/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/Unsupervised-VI-ReID/Robust%20Pseudo-label%20Learning%20with%20Neighbor%20Relation%20for%20Unsupervised%20Visible-Infrared%20Person%20Re-Identification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/Object_Re-Identification/Unsupervised-VI-ReID/Robust%20Pseudo-label%20Learning%20with%20Neighbor%20Relation%20for%20Unsupervised%20Visible-Infrared%20Person%20Re-Identification/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-02-16 11:51:35 / Modified: 21:47:48" itemprop="dateCreated datePublished" datetime="2025-02-16T11:51:35+08:00">2025-02-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="acm-mm24">acm mm24</h1>
<h1 id="它也是要解决伪标签带噪的问题提出一个noisy-pseudo-label-calibration-module来校正伪标签提出一个nieghbor-relation-learning-module来获取模态内更加一致的特征提出一个optimal-transport-prototype-matching-module来进行跨模态的匹配建立跨模态对应关系提出一个memory-hybrid-leraning-module来更好提取出modality-invariant和modality-specific-feature">它也是要解决伪标签带噪的问题。提出一个Noisy
Pseudo-label Calibration
module来<strong><em>校正伪标签</em></strong>；提出一个Nieghbor Relation
Learning module来获取模态内更加一致的特征；提出一个Optimal Transport
Prototype Matching
module来进行跨模态的匹配，建立跨模态对应关系；提出一个Memory Hybrid
Leraning module来更好提取出modality-invariant和modality-specific
feature</h1>
<h1 id="insight">insight</h1>
<h1 id="动机无监督vi-reid中伪标签带噪声是很常见的问题而论文提出一般的方法聚焦于减少带噪标签的影响但忽略了去校正带噪标签其实这么说好像也不是很严谨那些标签平滑的操作我觉得某种程度上也是在校正标签的">动机：无监督vi-reid中，伪标签带噪声是很常见的问题。而论文提出，一般的方法聚焦于减少带噪标签的影响，但忽略了去校正带噪标签（其实这么说好像也不是很严谨，那些标签平滑的操作，我觉得某种程度上也是在校正标签的）</h1>
<h1 id="方法">方法</h1>
<h2 id="noisy-pseudo-label-calibrationnpc这个模块就是很显然的回应了动机里它想要校正标签的想法它评价两个样本相似度的方法是用邻居的相似度或者说重合度而不是用样本特征本身这种间接衡量相似性的方法和gur论文towards-grand-unified-representation-learning-for-unsupervised-visible-infrared-person-re-identification里的操作思想上是比较相近的只不过那里用的是概率分布要尽可能相似-而它校正标签的方法则是先提取出每个簇内的可靠的样本可靠的判断方法中核心思想是一个簇内如果有很多样本和当前样本非常相似那么当前样本应该就是比较可靠的然后簇中心就初始化为这些可靠样本的均值之后每个样本再和这些新的簇中心进行比较分配到最相似的那个簇中心那里">1.Noisy
Pseudo-label
Calibration（NPC），这个模块就是很显然的，回应了动机里它想要校正标签的想法。它评价两个样本相似度的方法是用邻居的相似度（或者说重合度），而不是用样本特征本身（这种间接衡量相似性的方法，和(GUR论文[[Towards
Grand Unified Representation Learning for Unsupervised Visible-Infrared
Person
Re-Identification]])里的操作，思想上是比较相近的，只不过那里用的是概率分布要尽可能相似）<br>而它校正标签的方法，则是，先提取出每个簇内的“可靠”的样本（“可靠”的判断方法中，核心思想是，一个簇内，如果有很多样本和当前样本非常相似，那么当前样本应该就是比较”可靠“的），然后簇中心就初始化为这些“可靠”样本的均值；之后，每个样本再和这些新的簇中心进行比较，分配到最相似的那个簇中心那里</h2>
<h2 id="neighbor-relation-learningnrl原文里说是为了reduce-high-intra-class-variations我们可以认为是为了提取更好的特征以便更好地进行模态内的聚类所以它应该主要聚焦在挖掘模态内的信息但它的损失没太搞懂">2.Neighbor
Relation Learning（NRL），原文里说是为了reduce high intra-class
variations，我们可以认为，是为了提取更好的特征，以便更好地进行模态内的聚类。所以它应该主要聚焦在挖掘模态内的信息。但它的损失，没太搞懂。。</h2>
<h2 id="optimal-transport-prototype-matchingotpa聚焦于挖掘跨模态对应的信息">Optimal
Transport Prototype Matching（OTPA），聚焦于挖掘跨模态对应的信息</h2>
<h2 id="memory-hybrid-learning聚焦于学习modality-invariant-feature具体来说它在经典的模态内的clusternce-loss的基础上还构建了一个modality-hybrid-memory这个memory的特征是由红外cluster和对应的可见光cluster加权求和得到然后交替地拉近红外实例可见光实例与这个混合memory中的对应cluster之间的距离">Memory
Hybrid Learning，聚焦于学习modality-invariant
feature。具体来说，它在经典的模态内的ClusterNCE
loss的基础上，还构建了一个modality-hybrid
memory（这个memory的特征是由红外cluster和对应的可见光cluster加权求和得到），然后交替地拉近红外实例、可见光实例与这个混合memory中的对应cluster之间的距离</h2>
<h1 id="分析">分析</h1>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/12/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><span class="page-number current">13</span><a class="page-number" href="/page/14/">14</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><a class="extend next" rel="next" href="/page/14/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">bluemouse</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">189</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">58</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">102</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bluemouse</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
