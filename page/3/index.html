<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueeemouse.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="bluemouse&#39;s blog">
<meta property="og:url" content="https://blueeemouse.github.io/page/3/index.html">
<meta property="og:site_name" content="bluemouse&#39;s blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="bluemouse">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueeemouse.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>bluemouse's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">bluemouse's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/10/03/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/MC-LLaVA%EF%BC%9AMulti-Concept%20Personalized%20Vision-Language%20Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/03/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/MC-LLaVA%EF%BC%9AMulti-Concept%20Personalized%20Vision-Language%20Model/" class="post-title-link" itemprop="url">MC-LLaVA：Multi-Concept Personalized Vision-Language Model</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-10-03 21:22:00 / Modified: 23:59:29" itemprop="dateCreated datePublished" datetime="2025-10-03T21:22:00+08:00">2025-10-03</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/MLLM/" itemprop="url" rel="index"><span itemprop="name">MLLM</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/MLLM/personalized-VLMs/" itemprop="url" rel="index"><span itemprop="name">personalized VLMs</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="venuearxiv">Venue：arxiv</h1>
<h1 id="date2025-03-26">date：2025-03-26</h1>
<h1 id="动机">动机：</h1>
<h2 id="论文关注的任务是multi-concept-personalization是要让模型理解并记忆用户自定义的特定概念由此作出回答的任务例如给两幅图片一幅是关于某个任务的简介可能包括了这个人的名字另一幅图里就包含了这个人用户可能就会问到另一幅图里这个人在干什么我们希望模型回答的时候能回答名字而不是说那个人">论文关注的任务是multi-concept
personalization，是要让模型理解并记忆用户自定义的特定概念，由此作出回答的任务。（例如，给两幅图片，一幅是关于某个任务的简介，可能包括了这个人的名字；另一幅图里就包含了这个人，用户可能就会问到另一幅图里这个人在干什么。我们希望模型回答的时候能回答名字，而不是说“那个人”）</h2>
<h2 id="论文创新的点也是现有研究缺乏的点就是大多研究聚焦于single-concept-personalization但是忽略了multi-concept-personalization一次让模型学习多个概念">论文创新的点，也是现有研究缺乏的点，就是：大多研究聚焦于single-concept
personalization，但是忽略了multi-concept
personalization（一次让模型学习多个概念）</h2>
<h1 id="insight">insight：</h1>
<h2 id="指令微调真的很强大感觉论文最主要的部分应该就是收集数据进行指令微调我估计光是这样下来就已经效果不错了至于后面的personalized-textual-prompt以及visual-prompt有点复杂而且有点像在找补提高性能有可能收集数据才是最麻烦的">指令微调，真的很强大……感觉论文最主要的部分应该就是收集数据，进行指令微调。我估计光是这样下来就已经效果不错了。至于后面的personalized
textual prompt以及visual
prompt，有点复杂，而且有点像在找补，提高性能（有可能收集数据才是最麻烦的）</h2>
<h2 id="另外不同领域的指令微调可能区别以及贡献都在于设计相应的合适的微调任务以及指令微调感觉上还是比较能scaling的">另外，不同领域的指令微调，可能区别（以及贡献）都在于设计相应的合适的微调任务。以及，指令微调，感觉上还是比较能scaling的</h2>
<h2 id="不过personalized-vlms这个领域到底有没有意义呢它并不是在扩展模型的能力边界好像不够exciting可是未来如果vlm这些模型继续发展能做到人手一个模型的话是不是需要落实到个性化这个方面呢">不过，personalized
VLMs，这个领域到底有没有意义呢……它并不是在扩展模型的能力边界，好像不够exciting；可是未来如果vlm这些模型继续发展，能做到人手一个模型的话，是不是需要落实到个性化这个方面呢？</h2>
<h1 id="contribution">contribution：</h1>
<h2 id="提出一套训练策略用于提高模型的multi-concept-personalization能力">提出一套训练策略，用于提高模型的multi-concept
personalization能力</h2>
<h2 id="提出一套关于multi-concept-personalization的数据集">提出一套关于multi-concept
personalization的数据集</h2>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/10/03/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/MC-LLaVA%EF%BC%9AMulti-Concept%20Personalized%20Vision-Language%20Model/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/30/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/%E5%A4%9A%E6%A8%A1%E6%80%81GraphRAG%E7%9B%B8%E5%85%B3paper%E8%B0%83%E7%A0%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/30/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/%E5%A4%9A%E6%A8%A1%E6%80%81GraphRAG%E7%9B%B8%E5%85%B3paper%E8%B0%83%E7%A0%94/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-30 10:48:01" itemprop="dateCreated datePublished" datetime="2025-09-30T10:48:01+08:00">2025-09-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-04 16:26:10" itemprop="dateModified" datetime="2025-10-04T16:26:10+08:00">2025-10-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="acl-25">ACL 25</h1>
<h2 id="query-driven-multimodal-graphrag-dynamic-local-knowledge-graph-construction-for-online-reasoning多模态的多模态graphrag但是用于online-reasoning"><strong>Query-Driven
Multimodal GraphRAG: Dynamic Local Knowledge Graph Construction for
Online Reasoning</strong>（多模态的，多模态GraphRAG，但是用于online
reasoning）</h2>
<h1 id="naacl-25">NAACL 25</h1>
<h2 id="mes-rag-bringing-multi-modal-entity-storage-and-secure-enhancements-to-rag多模态的疑似多模态graphrag并非它的数据组织形式不是graph所以不算是mmgraphrag不过这个感觉关注的点也还好既有回答的精确性也有安全性方面的但重点可能在于它支持多模态的输出"><strong>MES-RAG:
Bringing Multi-modal, Entity-Storage, and Secure Enhancements to
RAG</strong>（多模态的）（疑似多模态GraphRAG）（并非，它的数据组织形式不是Graph，所以不算是MMGraphRAG。不过这个感觉关注的点也还好，既有回答的精确性，也有安全性方面的，但重点可能在于它支持多模态的输出？）</h2>
<h1 id="icml-25">ICML 25</h1>
<h2 id="scenir-visual-semantic-clarity-through-unsupervised-scene-graph-retrieval多模态的但是是scene-graph相关的这个可以算到graphrag吗不过是scene-graph相关的可能有点关系好吧其实这篇是做image-to-image-retrieval的只不过用到了scene-graph这个技术手段而已"><a target="_blank" rel="noopener" href="https://icml.cc/virtual/2025/poster/43841">SCENIR: Visual Semantic
Clarity through Unsupervised Scene Graph
Retrieval</a>（多模态的？但是是scene
graph相关的。这个可以算到GraphRAG吗？）（不过是scene
graph相关的，可能有点关系）（好吧，其实这篇是做image-to-image
retrieval的，只不过用到了scene graph这个技术手段而已）</h2>
<h2 id="recurrence-enhanced-vision-and-language-transformers-for-robust-multimodal-document-retrieval检索多模态的文档不知道有没有相关真不相关吧"><a target="_blank" rel="noopener" href="https://github.com/aimagelab/ReT">Recurrence-Enhanced
Vision-and-Language Transformers for Robust Multimodal Document
Retrieval</a>（检索多模态的文档，不知道有没有相关？）（真不相关吧）</h2>
<h1 id="iccv-25">ICCV 25</h1>
<h2 id="taming-the-untamed-graph-based-knowledge-retrieval-and-reasoning-for-mllms-to-conquer-the-unknown多模态的vlm方面的以及涉及graph其实也不相关不过这篇论文研究的点感觉有一点道理它是想说现在的mllm其实在遇到不熟悉的领域的时候表现不够好毕竟没有这方面的知识而论文想做的似乎是提高mllm利用外部知识的效率主要是通过提出multi-agent-retriever来实现感觉agentic-rag确实是有必要的"><strong>Taming
the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to
Conquer the
Unknown</strong>（多模态的，VLM方面的，以及涉及graph）（其实也不相关。不过这篇论文研究的点感觉有一点道理？它是想说现在的mllm其实在遇到不熟悉的领域的时候，表现不够好，毕竟没有这方面的知识。而论文想做的似乎是提高mllm利用外部知识的效率。主要是通过提出multi-agent
retriever来实现？感觉agentic rag确实是有必要的）</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/SnapKV%EF%BC%9ALLM%20Knows%20What%20You%20Are%20Looking%20for%20before%20Generation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/SnapKV%EF%BC%9ALLM%20Knows%20What%20You%20Are%20Looking%20for%20before%20Generation/" class="post-title-link" itemprop="url">SnapKV：LLM Knows What You Are Looking for before Generation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-09-29 14:31:00 / Modified: 18:42:47" itemprop="dateCreated datePublished" datetime="2025-09-29T14:31:00+08:00">2025-09-29</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/" itemprop="url" rel="index"><span itemprop="name">nlp</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/" itemprop="url" rel="index"><span itemprop="name">llm</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/" itemprop="url" rel="index"><span itemprop="name">efficiency</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/" itemprop="url" rel="index"><span itemprop="name">kv-cache</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="venue">Venue：</h1>
<h1 id="date">date：</h1>
<h1 id="动机">动机：</h1>
<h2 id="多数方法忽视-prompt-的-kv-缓存压缩仅关注generated-token的kv-cache-compression但其实prompt有可能远比generated-token要长比如输入文档的情况下进行文档qa">多数方法<strong>忽视
prompt 的 KV 缓存压缩</strong>，仅关注generated token的KV cache
compression。但其实prompt有可能远比generated
token要长（比如输入文档的情况下，进行文档QA）</h2>
<h1 id="insight">insight：</h1>
<h2 id="论文通过实验发现对于input-seq-tokens是存在一个consistent-attention-allocation-pattern的这为kv-cache-compression提供了可能因为consistent确保了保留下来的kv-cache会尽可能的有用不会说关键token一直在变化那样的话可能我们生成每个token都需要依赖不同的关键token那某个token的kv-cache一旦被剔除后面生成可能又要用到了">论文通过实验发现，对于input
seq tokens，是存在一个consistent attention allocation pattern的。这为kv
cache compression提供了可能。因为，consistent确保了保留下来的kv
cache会尽可能的有用；不会说关键token一直在变化（那样的话，可能我们生成每个token都需要依赖不同的关键token，那某个token的kv
cache一旦被剔除，后面生成可能又要用到了）</h2>
<h2 id="另外在生成之前事先知道这个attention-allocation-pattern是可行的这也很重要因为这个性质我们才能在生成前知道要保留哪些prompt-token的kv-cache">另外，在生成之前，事先知道这个attention
allocation
pattern，是可行的。这也很重要，因为这个性质，我们才能在生成前知道要保留哪些prompt
token的kv cache</h2>
<h1 id="contribution">contribution：</h1>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/SnapKV%EF%BC%9ALLM%20Knows%20What%20You%20Are%20Looking%20for%20before%20Generation/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/DrVideo%EF%BC%9ADocument%20Retrieval%20Based%20Long%20Video%20Understanding/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/DrVideo%EF%BC%9ADocument%20Retrieval%20Based%20Long%20Video%20Understanding/" class="post-title-link" itemprop="url">DrVideo：Document Retrieval Based Long Video Understanding</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-09-29 10:41:00 / Modified: 11:27:51" itemprop="dateCreated datePublished" datetime="2025-09-29T10:41:00+08:00">2025-09-29</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/" itemprop="url" rel="index"><span itemprop="name">nlp</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/" itemprop="url" rel="index"><span itemprop="name">llm</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/" itemprop="url" rel="index"><span itemprop="name">RAG</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-RAG/" itemprop="url" rel="index"><span itemprop="name">multi-modal RAG</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="venuecvpr-25">Venue：CVPR 25</h1>
<h1 id="date2024-11-24">date：2024-11-24</h1>
<h1 id="动机">动机：</h1>
<h1 id="insight">insight：</h1>
<h2 id="对于视频我们总是希望找到它的关键帧关键部分并且是希望能一次性地在任务开始时就找到但是其实也未必如此如果采用一种不断完善的方法来寻找视频的关键信息最终也能回答好问题那其实也是可以的就像这篇论文前面的操作其实都是最朴素的操作了可就是因为引入了两个agent所以有弥补的空间可以决定是否要重新去检索关键帧可以决定是否要深挖已有的关键帧">对于视频，我们总是希望找到它的关键帧/关键部分，并且是希望能一次性地在任务开始时就找到。但是其实也未必如此，如果采用一种不断完善的方法来寻找视频的关键信息，最终也能回答好问题，那其实也是可以的。就像这篇论文，前面的操作其实都是最朴素的操作了，可就是因为引入了两个agent，所以有弥补的空间：可以决定是否要重新去检索关键帧；可以决定是否要深挖已有的关键帧</h2>
<h1 id="contribution">contribution：</h1>
<h2 id="再稍微读一下感觉没什么贡献啊可能就引入agent那一步值得说到一下其它感觉都是现有的而且那个retrieval-module不就是一个简单的检索吗这也能包装成一个之前没有的东西吗">再稍微读一下，感觉没什么贡献啊……可能就引入agent那一步值得说到一下，其它感觉都是现有的。而且那个retrieval
module不就是一个简单的检索吗，这也能包装成一个之前没有的东西吗……</h2>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/DrVideo%EF%BC%9ADocument%20Retrieval%20Based%20Long%20Video%20Understanding/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/VideoRAG%EF%BC%9ARetrieval-Augmented%20Generation%20over%20Video%20Corpus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/VideoRAG%EF%BC%9ARetrieval-Augmented%20Generation%20over%20Video%20Corpus/" class="post-title-link" itemprop="url">VideoRAG：Retrieval-Augmented Generation over Video Corpus</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-28 17:05:00" itemprop="dateCreated datePublished" datetime="2025-09-28T17:05:00+08:00">2025-09-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-09-29 10:37:54" itemprop="dateModified" datetime="2025-09-29T10:37:54+08:00">2025-09-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/" itemprop="url" rel="index"><span itemprop="name">nlp</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/" itemprop="url" rel="index"><span itemprop="name">llm</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/" itemprop="url" rel="index"><span itemprop="name">RAG</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-RAG/" itemprop="url" rel="index"><span itemprop="name">multi-modal RAG</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="venueacl-25-findings">Venue：ACL 25 findings</h1>
<h1 id="date2025-05-28">date：2025-05-28</h1>
<h1 id="动机">动机：</h1>
<h2 id="现有rag方法通常忽视了视频模态但视频里其实也包含了很丰富的信息-尽管最近有一些研究在尝试利用视频来辅助回答但它们要么不够动态即人工预先定义好query的几个相关视频或者按照固定规则来定义相关视频要么损失了视频中丰富的信息把视频转成文字描述-因此论文提出videorag来直接检索回query相关的视频能同时利用文字和视觉信息">现有RAG方法通常忽视了视频模态。但视频里其实也包含了很丰富的信息<br>尽管最近有一些研究在尝试利用视频来辅助回答，但它们要么不够动态（即人工预先定义好query的几个相关视频，或者按照固定规则来定义相关视频），要么损失了视频中丰富的信息（把视频转成文字描述）<br>因此论文提出VideoRAG，来直接检索回query相关的视频，能同时利用文字和视觉信息</h2>
<h3 id="关于现有方法不够动态的问题可以举几个例子来理解比如人工预先定义的话可能针对打领带这个query人为的找出两三个教学视频它们的确是打领带的教学视频之后如果有query是关于这个的则它们的参考视频就只会是这两三个而不会从海量的视频候选库里检索">关于现有方法不够动态的问题，可以举几个例子来理解。比如人工预先定义的话，可能针对“打领带”这个query，人为的找出两三个教学视频，它们的确是打领带的教学视频。之后如果有query是关于这个的，则它们的参考视频就只会是这两三个，而不会从海量的视频候选库里检索。</h3>
<h2 id="虽然现在有很多image-text-rag但视频终究是有一些独特的性质导致它不能被图像完全取代吧">虽然现在有很多image-text
RAG，但视频终究是有一些独特的性质，导致它不能被图像完全取代吧</h2>
<h1 id="insight">insight：</h1>
<h2 id="判断视频是否和query相关其实也很重要千万不能忽视这一点否则检索的空间太大了">判断视频是否和query相关，其实也很重要。千万不能忽视这一点，否则检索的空间太大了</h2>
<h2 id="视频模态的特点感觉体现在包括但不限于以下的几方面">视频模态的特点，感觉体现在（包括但不限于以下的几方面）：</h2>
<h3 id="多帧之间的时序关系">多帧之间的时序关系</h3>
<h3 id="画面图像和文本语音之间的对应关系">画面（图像）和文本/语音之间的对应关系</h3>
<h1 id="contribution">contribution：</h1>
<h2 id="支持了动态视频的检索包括能动态判断哪些视频是相关的并从中提取信息用于辅助生成">支持了动态视频的检索，包括能动态判断哪些视频是相关的，并从中提取信息用于辅助生成</h2>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/VideoRAG%EF%BC%9ARetrieval-Augmented%20Generation%20over%20Video%20Corpus/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/video%E7%9B%B8%E5%85%B3%E7%9A%84RAGpaper%E8%B0%83%E7%A0%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/video%E7%9B%B8%E5%85%B3%E7%9A%84RAGpaper%E8%B0%83%E7%A0%94/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-09-28 15:55:06 / Modified: 17:00:02" itemprop="dateCreated datePublished" datetime="2025-09-28T15:55:06+08:00">2025-09-28</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="acl-25">ACL 25</h1>
<h2 id="videorag-retrieval-augmented-generation-over-video-corpus多模态的视频相关"><strong>VideoRAG:
Retrieval-Augmented Generation over Video
Corpus</strong>（多模态的，视频相关）</h2>
<h1 id="iclr-25">ICLR 25</h1>
<h2 id="tempme-video-temporal-token-merging-for-efficient-text-video-retrieval多模态的video和efficiency结合的看起来是在压缩video输入的也算是video相关的">TempMe:
Video Temporal Token Merging for Efficient Text-Video
Retrieval（多模态的，video和efficiency结合的，看起来是在压缩video输入的。也算是video相关的）</h2>
<h2 id="generalized-video-moment-retrieval多模态的video相关">Generalized
Video Moment Retrieval（多模态的,video相关）</h2>
<h1 id="nips-24">NIPS 24</h1>
<h2 id="diffusion-inspired-truncated-sampler-for-text-video-retrievaltext-video-retrieval">Diffusion-Inspired
Truncated Sampler for Text-Video Retrieval（text-video retrieval）</h2>
<h1 id="cvpr-25">CVPR 25</h1>
<h2 id="drvideo-document-retrieval-based-long-video-understanding真对口了长视频理解方面的"><strong>DrVideo:
Document Retrieval Based Long Video
Understanding</strong>（真对口了，长视频理解方面的）</h2>
<h2 id="salova-segment-augmented-long-video-assistant-for-targeted-retrieval-and-routing-in-long-form-video-analysis这也是经典了也是长视频理解这一块的">SALOVA:
Segment-Augmented Long Video Assistant for Targeted Retrieval and
Routing in Long-Form Video
Analysis（这也是经典了，也是长视频理解这一块的）</h2>
<h2 id="vlog-video-language-models-by-generative-retrieval-of-narration-vocabulary似乎是video相关的但是理解方面的吗"><strong>VLog:
Video-Language Models by Generative Retrieval of Narration
Vocabulary</strong>（似乎是video相关的，但是理解方面的吗？）</h2>
<h2 id="learning-audio-guided-video-representation-with-gated-attention-for-video-text-retrieval又是text-video-retrieval啊"><strong>Learning
Audio-guided Video Representation with Gated Attention for Video-Text
Retrieval</strong>（又是text-video retrieval啊）</h2>
<h2 id="rethinking-noisy-video-text-retrieval-via-relation-aware-alignment还是text-video-retrieval"><strong>Rethinking
Noisy Video-Text Retrieval via Relation-aware
Alignment</strong>（还是text-video retrieval）</h2>
<h2 id="video-colbert-contextualized-late-interaction-for-text-to-video-retrieval还是text-to-video-retrieval"><strong>Video-ColBERT:
Contextualized Late Interaction for Text-to-Video
Retrieval</strong>（还是text-to-video retrieval）</h2>
<h2 id="multivent-2.0-a-massive-multilingual-benchmark-for-event-centric-video-retrievalbenchmark类不过是关于video-retrieval的"><strong>MultiVENT
2.0: A Massive Multilingual Benchmark for Event-Centric Video
Retrieval</strong>（benchmark类，不过是关于video retrieval的）</h2>
<h2 id="the-devil-is-in-the-prompts-retrieval-augmented-prompt-optimization-for-text-to-video-generation不会是prompt-engineering吧关注text-to-video-generation文生视频吗"><strong>The
Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for
Text-to-Video Generation</strong>（不会是prompt
engineering吧……）（关注text-to-video generation？文生视频吗？）</h2>
<h2 id="narrating-the-video-boosting-text-video-retrieval-via-comprehensive-utilization-of-frame-level-captionstext-to-video-retrieval"><a target="_blank" rel="noopener" href="https://multimodal-understanding-group.github.io/NarVid/">Narrating
the Video: Boosting Text-Video Retrieval via Comprehensive Utilization
of Frame-Level Captions</a>（text-to-video retrieval）</h2>
<h2 id="discovla-discrepancy-reduction-in-vision-language-and-alignment-for-parameter-efficient-video-text-retrieval呃efficiency和video结合text-to-video-retrieval"><a target="_blank" rel="noopener" href="https://github.com/LunarShen/DsicoVLA">DiscoVLA: Discrepancy
Reduction in Vision, Language, and Alignment for Parameter-Efficient
Video-Text Retrieval</a>（呃，efficiency和video结合，text-to-video
retrieval）</h2>
<h1 id="iccv-25">ICCV 25</h1>
<h2 id="hybrid-tower-fine-grained-pseudo-query-interaction-and-generation-for-text-to-video-retrievaltext-to-video-retrievalvideo相关"><strong>Hybrid-Tower:
Fine-grained Pseudo-query Interaction and Generation for Text-to-Video
Retrieval</strong>（text-to-video retrieval，video相关）</h2>
<h2 id="beyond-simple-edits-composed-video-retrieval-with-dense-modificationscomposed-video-retrievalvideo相关的"><strong>Beyond
Simple Edits: Composed Video Retrieval with Dense
Modifications</strong>（Composed Video Retrieval，video相关的）</h2>
<h2 id="borrowing-eyes-for-the-blind-spot-overcoming-data-scarcity-in-malicious-video-detection-via-cross-domain-retrieval-augmentation这是啥video-detection嗯也算是video相关的但应该是那种low-level的video相关工作"><a target="_blank" rel="noopener" href="https://github.com/ronpay/CRAVE">Borrowing Eyes for the Blind
Spot: Overcoming Data Scarcity in Malicious Video Detection via
Cross-Domain Retrieval Augmentation</a>（这是啥？video
detection？嗯，也算是video相关的，但应该是那种low-level的video相关工作）</h2>
<h2 id="enhancing-partially-relevant-video-retrieval-with-hyperbolic-learningvideo-retrieval"><strong>Enhancing
Partially Relevant Video Retrieval with Hyperbolic
Learning</strong>（video retrieval）</h2>
<h2 id="ophclip-hierarchical-retrieval-augmented-learning-for-ophthalmic-surgical-video-language-pretraining这是不太懂不过看起来是video相关的"><strong>OphCLIP:
Hierarchical Retrieval-Augmented Learning for Ophthalmic Surgical
Video-Language
Pretraining</strong>（这是？不太懂，不过看起来是video相关的）</h2>
<h2 id="quantifying-and-narrowing-the-unknown-interactive-text-to-video-retrieval-via-uncertainty-minimizationtext-to-video-retrievalvideo相关"><strong>Quantifying
and Narrowing the Unknown: Interactive Text-to-Video Retrieval via
Uncertainty Minimization</strong>（text-to-video
retrieval，video相关）</h2>
<h2 id="prototypes-are-balanced-units-for-efficient-and-effective-partially-relevant-video-retrievalvideo-retrievalvideo相关"><strong>Prototypes
are Balanced Units for Efficient and Effective Partially Relevant Video
Retrieval</strong>（video retrieval，video相关）</h2>
<h2 id="bidirectional-likelihood-estimation-with-multi-modal-large-language-models-for-text-video-retrievaltext-to-video-retrievalvideo相关"><strong>Bidirectional
Likelihood Estimation with Multi-Modal Large Language Models for
Text-Video Retrieval</strong>（text-to-video retrieval，video相关）</h2>
<h1 id="eccv-24">ECCV 24</h1>
<h2 id="rethinking-video-text-understanding-retrieval-from-counterfactually-augmented-datavideo-text-understanding具体是做啥是video理解方面的吗"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/2083_ECCV_2024_paper.php">Rethinking
Video-Text Understanding: Retrieval from Counterfactually Augmented
Data</a>（video-text
understanding？具体是做啥？是video理解方面的吗？）</h2>
<h2 id="rgnet-a-unified-clip-retrieval-and-grounding-network-for-long-videoslong-video相关的不知道是不是长视频理解这方面的"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/3186_ECCV_2024_paper.php">RGNet:
A Unified Clip Retrieval and Grounding Network for Long Videos</a>（long
video相关的，不知道是不是长视频理解这方面的）</h2>
<h2 id="kdpror-a-knowledge-decoupling-probabilistic-framework-for-video-text-retrievaltext-to-video-retrievalvideo相关"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/5033_ECCV_2024_paper.php">KDProR:
A Knowledge-Decoupling Probabilistic Framework for Video-Text
Retrieval</a>（text-to-video retrieval，video相关）</h2>
<h2 id="egocvr-an-egocentric-benchmark-for-fine-grained-composed-video-retrieval细粒度composed-video-retrieval"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/5363_ECCV_2024_paper.php">EgoCVR:
An Egocentric Benchmark for Fine-Grained Composed Video
Retrieval</a>（细粒度Composed Video Retrieval）</h2>
<h2 id="uncertainty-aware-sign-language-video-retrieval-with-probability-distribution-modelingvideo-retrievalvideo相关"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/6074_ECCV_2024_paper.php">Uncertainty-aware
sign language video retrieval with probability distribution
modeling</a>（video retrieval，video相关）</h2>
<h2 id="ea-vtr-event-aware-video-text-retrievaltext-to-video-retrievalvideo相关"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/6845_ECCV_2024_paper.php">EA-VTR:
Event-Aware Video-Text Retrieval</a>（text-to-video
retrieval，video相关）</h2>
<h2 id="rap-retrieval-augmented-planner-for-adaptive-procedure-planning-in-instructional-videosvideo相关的但是具体是做什么的"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/9950_ECCV_2024_paper.php">RAP:
Retrieval-Augmented Planner for Adaptive Procedure Planning in
Instructional Videos</a>（video相关的，但是具体是做什么的？）</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/%E5%85%B3%E4%BA%8ERAG%E7%9A%84%E6%80%9D%E8%80%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/%E5%85%B3%E4%BA%8ERAG%E7%9A%84%E6%80%9D%E8%80%83/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-28 15:49:03" itemprop="dateCreated datePublished" datetime="2025-09-28T15:49:03+08:00">2025-09-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-27 15:24:55" itemprop="dateModified" datetime="2025-12-27T15:24:55+08:00">2025-12-27</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="或许得思考一下为什么rag一直被人诟病它的问题到底在哪里graphrag解决了rag的哪些问题还有哪些本质问题没有解决">或许得思考一下为什么RAG一直被人诟病？它的问题到底在哪里？GraphRAG，解决了RAG的哪些问题？还有哪些本质问题没有解决？</h1>
<h2 id="不妨先从传统rag开始说起那它的最开始的操作把文档进行chunk其实就是一个有很多弊端的操作硬性切分导致内容可能割裂例如一个完整的内容被切割到两个乃至多个chunk中">不妨先从传统RAG开始说起。那它的最开始的操作，把文档进行chunk，其实就是一个有很多弊端的操作：硬性切分，导致内容可能割裂（例如一个完整的内容被切割到两个，乃至多个chunk中）</h2>
<h2 id="还有一个问题现在的rag里的很多技术或者说方法感觉都可能随着基模的发展而变得无用比如我们把知识库组织成graph的格式这是为了更好体现data之间的关系其实相当于我们显式地把这些关系给提炼出来以便模型能掌握到或者说是我们在担心如果不提炼出来那模型就感知不到这个关系但假如基模不断发展它的推理能力也不断提高最终我们只需要把检索到的内容直接拿给它它就能推理出这些关系甚至还能自发的研究更深层的关系那不就没必要搞graph了吗">还有一个问题，现在的RAG里的很多技术，或者说方法，感觉都可能随着基模的发展而变得无用。比如，我们把知识库组织成graph的格式，这是为了更好体现data之间的关系。其实相当于我们显式地把这些关系给提炼出来，以便模型能掌握到（或者说，是我们在担心，如果不提炼出来，那模型就感知不到这个关系）。但假如，基模不断发展，它的推理能力也不断提高，最终我们只需要把检索到的内容直接拿给它，它就能推理出这些关系，甚至还能自发的研究更深层的关系，那不就没必要搞graph了吗？</h2>
<h2 id="另rag里很多时候都是在借用模型本身的能力自己做的实质就是一个prompt-engineer这就显得很没有技术含量但或许也该换个角度看不管这个事在别人看来是否有含金量如果它确实有效我们不妨也能称上一句simple-and-effective">另，RAG里很多时候都是在借用模型本身的能力，自己做的实质就是一个prompt
engineer，这就显得很没有技术含量。但或许也该换个角度看，不管这个事在别人看来是否有含金量，如果它确实有效，我们不妨也能称上一句simple
and effective</h2>
<h2 id="rag的延迟很严重吗确实粗筛rerank精筛假如这一套流程走下来给人感觉步骤很多而且因为是级联的方式上一步的误差有可能影响下一步的误差但就没可能是我们下一步是基于上一步的结果进行纠正和前进吗这是讲故事还是确有其事有必要有可能通过轻量化等技术减缓延迟从而提高其实用性吗">RAG的延迟，很严重吗？确实，粗筛、rerank、精筛，假如这一套流程走下来，给人感觉步骤很多，而且因为是级联的方式，上一步的误差有可能影响下一步的误差（但就没可能是，我们下一步是基于上一步的结果进行纠正和前进吗？）。这是讲故事还是确有其事？有必要、有可能通过轻量化等技术减缓延迟，从而提高其实用性吗</h2>
<h1 id="但不得不说即使模型的上下文窗口再怎么增长且不说它持续增长的情况下性能是否能和短上下文的时候的性能持平也不可能把所有的资料都一口气吃下去不管是大一点的本地资料库还是网络上的资料这都应该没可能全部吃进去也就是说对更大范围的知识以及最新知识的获取始终是模型的一个必要的需求至于说最终手段是不是rag或者说这个手段还叫不叫rag那感觉没那么重要简单来说借用一下机器之心的话rag-本身所代表的核心思想为-llm-提供精准可靠的外部知识的需求是永恒的">但不得不说，即使模型的上下文窗口再怎么增长（且不说它持续增长的情况下，性能是否能和短上下文的时候的性能持平），也不可能把所有的资料都一口气吃下去。不管是大一点的本地资料库，还是网络上的资料，这都应该没可能全部吃进去。也就是说，对更大范围的知识，以及最新知识的获取，始终是模型的一个必要的需求。至于说最终手段是不是RAG，或者说这个手段还叫不叫RAG，那感觉没那么重要。简单来说，借用一下机器之心的话，“RAG
本身所代表的核心思想——为 LLM
提供精准、可靠的外部知识——的需求是永恒的”</h1>
<h2 id="来看看机器之心推文里的说法">来看看机器之心推文里的说法：</h2>
<h3 id="未来的图景更可能是">未来的图景更可能是：</h3>
<ul>
<li><h4 id="rag-的角色转变rag-不再是所有应用的默认核心架构而是被降级为-agent-工具箱中的一个强大组件它将与代码解释器api-调用文件系统操作等工具平起平坐"><strong>RAG
的角色转变</strong>：RAG 不再是所有应用的默认核心架构，而是被「降级」为
Agent 工具箱中的一个强大组件。它将与代码解释器、API
调用、文件系统操作等工具平起平坐。</h4></li>
<li><h4 id="场景决定架构对于需要从海量非结构化数据中快速筛选信息的场景如智能客服企业知识库初筛由-agent-驱动的高度工程化的高级-rag-系统仍是最佳选择"><strong>场景决定架构</strong>：对于需要从海量、非结构化数据中快速筛选信息的场景（如智能客服、企业知识库初筛），由
Agent 驱动的、高度工程化的高级 RAG 系统仍是最佳选择。</h4></li>
<li><h4 id="长上下文的统治力对于需要对少量结构复杂的文档进行深度推理和分析的场景如财报分析法律合同审查长上下文窗口-agent-调查的范式将展现出碾压性的优势"><strong>长上下文的统治力</strong>：对于需要对少量、结构复杂的文档进行深度推理和分析的场景（如财报分析、法律合同审查），「长上下文窗口
+ Agent 调查」的范式将展现出碾压性的优势。</h4>
<h3 id="对于开发者而言关键在于理解不同技术范式的优劣并根据具体的应用场景灵活地将它们组合成最高效最可靠的解决方案">对于开发者而言，关键在于理解不同技术范式的优劣，并根据具体的应用场景，灵活地将它们组合成最高效、最可靠的解决方案。</h3>
<h2 id="总结一下少量上下文的情况下还真不太需要rag了尤其是随着上下文窗口的增长少量的定义也将不断扩大这点不可否认但话又说回来rag本来也不是针对这个场景的吧回忆一下最经典的rag的故事是说模型要接触最新的知识以及其它的可能有用的知识吧-关于第一点rag的降级只能说没彻底死了就是好的可rag什么时候成了必须品了没感觉过啊但确实把它当一个工具还是不错的-而第二点确实当场景需要从大量非结构化数据里快速筛选信息的时候依然需要rag技术吧只不过可能推理啊检索啊之类的结合一下agent效果应该会更好">总结一下，少量上下文的情况下，还真不太需要RAG了。尤其是随着上下文窗口的增长，“少量”的定义也将不断扩大。这点不可否认。但话又说回来，RAG本来也不是针对这个场景的吧。回忆一下，最经典的RAG的故事，是说模型要接触最新的知识，以及其它的可能有用的知识吧<br>关于第一点，RAG的降级，只能说，没彻底死了就是好的。可RAG什么时候成了必须品了？没感觉过啊？但确实，把它当一个工具还是不错的<br>而第二点，确实，当场景需要从大量非结构化数据里快速筛选信息的时候，依然需要RAG技术吧，只不过可能推理啊，检索啊之类的，结合一下agent，效果应该会更好</h2></li>
</ul>
<h1 id="还有个问题随着deepseek-ocr的出现有人说会带来几个影响">还有个问题，随着deepseek
OCR的出现，有人说，会带来几个影响：</h1>
<h2 id="文本embedding会被抛弃因为它觉得ds-ocr能做到高效的压缩编码相比起传统的语义embedding压缩效率高太多了而且它结合现在大厂metagoogle开始越来越多使用grepripgrep做出判断对文本其实我们应该考虑直接去匹配原文">1.
文本embedding会被抛弃。因为它觉得，ds
ocr能做到高效的压缩编码，相比起传统的语义embedding，压缩效率高太多了。而且它结合现在大厂（meta，Google）开始越来越多使用grep/ripgrep，做出判断，对文本，其实我们应该考虑直接去匹配原文。</h2>
<h3 id="但这应该只是纯文本的情况吧多模态rag呢多模态的东西你总得用embedding之类的latent表示吧那这样为了保持联系文本不应该也用embedding表示或者大家都用ds-ocr那样的latent-representation表示好了起码得统一">但这应该只是纯文本的情况吧。多模态RAG呢？多模态的东西，你总得用embedding之类的latent表示吧，那这样，为了保持联系，文本不应该也用embedding表示？或者大家都用ds
ocr那样的latent representation表示好了。起码得统一</h3>
<h2 id="chunk的困境会被破除">2. chunk的困境会被破除</h2>
<h3 id="具体来说它认为因为ds-ocr的压缩效率很高可能一个100页的pdf用ds-ocr压缩之后也能轻松放到上下文窗口里此时一看就没有检索分块的必要了">具体来说，它认为，因为ds
ocr的压缩效率很高，可能一个100页的pdf，用ds
ocr压缩之后，也能轻松放到上下文窗口里。此时一看，就没有检索分块的必要了</h3>
<h3 id="但这也仅仅是针对少数文档的情况吧因为压缩效率很高可以无需检索一旦文档多了比如有一个database的情况该检索还是得检索吧即使ds-ocr压缩效率很高不过确实好像这么一看每个文档我也不需要chunk了不过这样具体该怎么检索呢每个文档给压缩成了若干visual-token不好进行语义检索了吧嗯或许embedding也不是完全的一无是处粗筛一下还是能用的吧">但这也仅仅是针对少数文档的情况吧，因为压缩效率很高，可以无需检索。一旦文档多了，比如有一个database的情况，该检索还是得检索吧，即使ds
ocr压缩效率很高。不过，确实好像这么一看，每个文档我也不需要chunk了？不过这样具体该怎么检索呢？每个文档给压缩成了若干visual
token，不好进行语义检索了吧？嗯，或许embedding也不是完全的一无是处，粗筛一下还是能用的吧</h3>
<h1 id="structure-r1这个有点像是把我想做的给做了具体来说它是把rag检索回来的文档转化成结构化形式感觉可以理解为把结构信息显式化了以便llm理解">structure-R1，这个有点像是把我想做的给做了。具体来说，它是把RAG检索回来的文档转化成结构化形式（感觉可以理解为，把结构信息显式化了，以便llm理解）</h1>
<h1 id="多跳rag感觉实质也是在为chunk和embedding带来的低效检索补窟窿正是因为语义embedding的检索可能检索回来的东西不对chunk又把完整内容给划分得太碎了所以考虑引入graph结构并且进行多跳操作把可能的内容弥补回来这样的话精筛rerank的时候能不能有些不一样的评判标准另外多模态的graph和文本的graph相比多跳的时候有什么不一样吗">多跳RAG，感觉实质也是在为chunk和embedding带来的低效检索补窟窿。正是因为语义embedding的检索可能检索回来的东西不对，chunk又把完整内容给划分得太碎了，所以考虑引入graph结构，并且进行多跳操作，把可能的内容弥补回来（这样的话，精筛/rerank的时候，能不能有些不一样的评判标准？）另外，多模态的graph和文本的graph相比，多跳的时候有什么不一样吗</h1>
<h1 id="还有agentic-rag有必要吗它解决了哪些rag的问题rag真的完全死了吗">还有，agentic
RAG有必要吗？它解决了哪些RAG的问题？RAG真的完全死了吗？</h1>
<h2 id="现在感觉rag并没有完全死吧毕竟它最大的问题是切chunk语义向量检索导致的检索精度差以及上下文不连贯那在相当一部分场景里是不好的但用它来粗筛或者是如果我们追求在大量数据上进行检索且不那么要求高质量那其实rag还是有用武之地的反而此时agentic-rag成本会比较高">现在感觉，RAG并没有完全死吧。毕竟它最大的问题是，切chunk+语义向量检索导致的检索精度差以及上下文不连贯。那在相当一部分场景里是不好的。但用它来粗筛，或者是如果我们追求在大量数据上进行检索，且不那么要求高质量，那其实RAG还是有用武之地的（反而此时agentic
RAG成本会比较高）</h2>
<h2 id="最近进一步激发rag已死言论的是claude-code的出现不仅效果比cursor要好还因为它没有用rag所以没有一个庞大的向量库需要维护因此也省了很多空间而claude-code其实是用回了七十年代的grep和glob这些文件系统工具看起来很返璞归真再联想一下rag的各种弊端似乎rag真的得被淘汰了">最近，进一步激发“RAG已死”言论的，是claude
code的出现，不仅效果比cursor要好，还因为它没有用RAG，所以没有一个庞大的向量库需要维护，因此也省了很多空间。而Claude
code其实是用回了七十年代的grep和glob这些文件系统工具。看起来很返璞归真，再联想一下RAG的各种弊端，似乎RAG真的得被淘汰了？</h2>
<h3 id="但这只是因为grep和glob刚好在编程这一块很实用毕竟代码本质上是一种非常规范的文本但比如说聊天记录之类的这种就完全不规范了那还用grepglob这些能行吗就不好说了吧">但，这只是因为grep和glob刚好在编程这一块很实用。毕竟代码本质上是一种非常规范的文本。但比如说，聊天记录之类的，这种就完全不规范了，那还用grep、glob这些，能行吗？就不好说了吧？</h3>
<h3 id="更进一步的这些都是针对文本的忽略了多模态的情况啊图像怎么办还能globgrep吗显然不行吧虽说文本你用grep这些图像再单独走另一套也不是不行吧但最起码多模态的rag它还是有用的说到底我们对图像的处理基本上还是得处理成向量吧">更进一步的，这些都是针对文本的，忽略了多模态的情况啊。图像怎么办？还能glob/grep吗？显然不行吧？虽说文本你用grep这些，图像再单独走另一套也不是不行吧。但最起码，多模态的RAG，它还是有用的（说到底，我们对图像的处理，基本上还是得处理成向量吧？）</h3>
<h2 id="看看这几篇博文吧感觉都挺好的">看看这几篇博文吧，感觉都挺好的：</h2>
<h3 id="rag与context-engineer的关系"><a target="_blank" rel="noopener" href="https://kirigaya.cn/blog/article?seq=356">RAG与Context
Engineer的关系</a></h3>
<h3 id="一篇疑似对rag已死的翻译的博文不过读起来还是可以的"><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1961345919405514850">一篇疑似对“RAG已死”的翻译的博文</a>，不过读起来还是可以的</h3>
<h3 id="经典的rag已死或者说是rag的讣告">经典的<a target="_blank" rel="noopener" href="https://www.nicolasbustamante.com/p/the-rag-obituary-killed-by-agents">RAG已死，或者说是RAG的讣告</a></h3>
<h3 id="一篇非常务实的回答关于rag与agentic-rag的优缺点"><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/1923191592593892684/answer/1945642914484053463">一篇非常务实的回答，关于RAG与agentic
RAG的优缺点</a></h3>
<h3 id="这个是关于agentic-rl的整理感觉它可以拓宽眼界从而能更加了解agentic-rag的必要性以及它的可能的用途">这个是<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1963453208383984904">关于agentic
RL的整理</a>。感觉它可以拓宽眼界，从而能更加了解agentic
RAG的必要性，以及它的可能的用途</h3>
<h2 id="还有一个很关键的问题上述关于rag已死的言论似乎都是默认在文本模态下工作的吧一旦引入了图像音频视频之类的多模态除了编码成向量还能怎样总不能像文本那样可以grep了吧如果要在这方面做改进感觉确实得在检索方面下一些功夫了这个就比较底层应该也比较难吧">还有一个很关键的问题。上述关于RAG已死的言论，似乎都是默认在文本模态下工作的吧？一旦引入了图像、音频、视频之类的多模态，除了编码成向量，还能怎样？总不能像文本那样可以grep了吧？如果要在这方面做改进，感觉确实得在检索方面下一些功夫了，这个就比较底层，应该也比较难吧</h2>
<h2 id="agentic-rag它的一大优点就是能动性可以自主地根据场合做决定而不需要依赖我们事先定义好的工作流也就是在当前场合下它会自动采取一个动作但这个动作具体怎么执行通常还是人来规定的这一点好不好长远来说可能不好吧我们当然希望agent能完全自主但这个还是有点远的吧至少现在就这么些规定好的动作让agent学会自主选择都还挺难的资源开销也不小了关于动作内容的自主化可能也是一个未来的研究方向吧">agentic
RAG，它的一大优点，就是“能动性”，可以自主地根据场合做决定，而不需要依赖我们事先定义好的工作流。也就是，在当前场合下，它会自动采取一个动作。但这个动作具体怎么执行，通常还是人来规定的。这一点好不好？长远来说可能不好吧，我们当然希望agent能完全自主。但这个还是有点远的吧？至少现在，就这么些规定好的动作，让agent学会自主选择，都还挺难的，资源开销也不小了。关于动作内容的自主化，可能也是一个未来的研究方向吧</h2>
<h1 id="我们如果做agentic-mmgraphrag可以吗它的确是没什么人做但是价值在哪呢以及能不能和现有的大厂做出来的agent进行融入就是作为插件加入到它们那边如果不行那我们是否需要换一个关注点比如它们的agent开销比较大模型大api调用花费多而我们就专注在小模型上这样对比也只需要跟小模型的方法对比而且训练也只需要训练小模型或许会好一些">我们如果做agentic
mmgraphrag，可以吗？它的确是没什么人做，但是价值在哪呢？以及能不能和现有的大厂做出来的agent进行融入（就是作为插件加入到它们那边）？如果不行，那我们是否需要换一个关注点，比如它们的agent开销比较大（模型大/api调用花费多），而我们就专注在小模型上，这样对比也只需要跟小模型的方法对比，而且训练也只需要训练小模型，或许会好一些</h1>
<h1 id="rag里确实基本假设是静态的知识库遇到新的知识来了呢">RAG里确实基本假设是静态的知识库。遇到新的知识来了呢</h1>
<h2 id="不断有新知识出现这并不是一个可以直接由上网检索就能解决的问题因为新知识出现的地方也不止是网上很多企业应该都会有大量的业务数据这些数据显然不可能公开所以会有私有增量数据的情况此时就需要更新知识库了">不断有新知识出现，这并不是一个可以直接由上网检索就能解决的问题，因为新知识出现的地方也不止是网上。很多企业应该都会有大量的业务数据，这些数据显然不可能公开，所以会有私有增量数据的情况。此时，就需要更新知识库了</h2>
<h3 id="更新知识库的时候也会有一些问题比如新旧知识之间的融合合并或者如果它们出现了冲突怎么办又或者有一些问题需要跨度比较大的新旧知识一起来分析怎么办旧的知识好像不应该一味地丢弃吧像之前读到过的versionrag其实就是关注了一个相当小的方面一个好一点的工作应该能完全囊括它吧">更新知识库的时候也会有一些问题，比如，新旧知识之间的融合？合并？或者如果它们出现了冲突怎么办？又或者有一些问题需要跨度比较大的新旧知识，一起来分析，怎么办？旧的知识好像不应该一味地丢弃吧？（像之前读到过的VersionRAG，其实就是关注了一个相当小的方面。一个好一点的工作，应该能完全囊括它吧）</h3>
<h2 id="其实rag的一个重要应用领域就是私有数据库上的检索即使llm继续发展它调用网络检索工具的能力更加提高了对于私有数据没有获取权限也没办法只有私有数据的拥有者可以部署模型并构建rag进行检索或者说我们也不需要一直强调rag但是私有数据的确需要被检索这点是真的不过如果是这样那其实反正是要部署在私有数据上为什么不用agentic-rag呢这里可能就会涉及到rag-routing了这样一想倒是明确了agentic-rag的efficiency肯定也是一个值得研究的东西">其实，RAG的一个重要应用领域就是私有数据库上的检索。即使llm继续发展，它调用网络检索工具的能力更加提高了，对于私有数据，没有获取权限也没办法。只有私有数据的拥有者可以部署模型，并构建RAG进行检索（或者说，我们也不需要一直强调RAG。但是私有数据的确需要被检索，这点是真的）（不过，如果是这样，那其实反正是要部署在私有数据上，为什么不用agentic
rag呢？这里可能就会涉及到rag
routing了？）（这样一想，倒是明确了，agentic
rag的efficiency肯定也是一个值得研究的东西）</h2>
<h2 id="哦对而且之所以说在私有数据库上要进行检索而不是微调模型喂给模型知识也是因为微调很麻烦资源需求大吧还可能有遗忘其它知识的风险rag就是一种免训练的方法in-context-learning固然也是一种方法但是直观上它只能在一些相对简单的任务上通过提供一些例子帮助llm理解而且不是有研究说icl的话提供过多的例子的时候其实没太多提升吗">哦对，而且之所以说在私有数据库上要进行检索，而不是微调模型喂给模型知识，也是因为微调很麻烦，资源需求大吧，还可能有遗忘其它知识的风险。RAG就是一种免训练的方法（In-Context
Learning固然也是一种方法，但是直观上，它只能在一些相对简单的任务上，通过提供一些例子帮助llm理解。而且不是有研究说，icl的话，提供过多的例子的时候，其实没太多提升吗）</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/27/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20%20KV%20Cache%E5%8E%8B%E7%BC%A9%E6%96%B0%E9%98%B6%E6%AE%B5%EF%BC%9A%E8%B5%B0%E5%90%91%E9%97%AE%E9%A2%98%E6%8C%87%E4%BB%A4%E6%97%A0%E5%85%B3%E4%B8%8B%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%8E%A2%E7%B4%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/27/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20%20KV%20Cache%E5%8E%8B%E7%BC%A9%E6%96%B0%E9%98%B6%E6%AE%B5%EF%BC%9A%E8%B5%B0%E5%90%91%E9%97%AE%E9%A2%98%E6%8C%87%E4%BB%A4%E6%97%A0%E5%85%B3%E4%B8%8B%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%8E%A2%E7%B4%A2/" class="post-title-link" itemprop="url">博客阅读 KV Cache压缩新阶段：走向问题指令无关下的压缩探索</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-09-27 15:16:00 / Modified: 15:32:04" itemprop="dateCreated datePublished" datetime="2025-09-27T15:16:00+08:00">2025-09-27</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/blog%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">blog阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/blog%E9%98%85%E8%AF%BB/llm/" itemprop="url" rel="index"><span itemprop="name">llm</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/blog%E9%98%85%E8%AF%BB/llm/efficiency/" itemprop="url" rel="index"><span itemprop="name">efficiency</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/blog%E9%98%85%E8%AF%BB/llm/efficiency/kv-cache/" itemprop="url" rel="index"><span itemprop="name">kv cache</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>
<h1 id="核心观点">核心观点：</h1>
<h2 id="简单来讲现在的kv-cache的一大问题是一旦没有特定的问题压缩效果就会大幅下降如果有特定的问题那压缩比例可以特别大且性能不降低太多然而如果没有特定的问题则稍微压缩一点都很容易损失精度">简单来讲，现在的kv
cache的一大问题是，一旦没有特定的问题，压缩效果就会大幅下降。（如果有特定的问题，那压缩比例可以特别大，且性能不降低太多。然而如果没有特定的问题，则稍微压缩一点都很容易损失精度）</h2>
<h2 id="因此博客提出在没有特定问题情况下的kv-cache-compression其实是值得研究的因为现有方法做不好有很大的提升空间基于此可以考虑">因此，博客提出，在没有特定问题情况下的kv
cache
compression其实是值得研究的（因为现有方法做不好，有很大的提升空间）。基于此，可以考虑：</h2>
<h3 id="提出更好的指标来衡量token的重要性">提出更好的指标来衡量token的重要性</h3>
<h3 id="提出更好的kv-cache-budget-allocation策略">提出更好的kv cache
budget allocation策略</h3>
<h1 id="关于博客里的一些术语的介绍">关于博客里的一些术语的介绍：</h1>
<h2 id="chunked-prefill博客里的chunked-prefill应该是指对输入的超长序列prompt进行分块然后在各自的块内进行prefill操作这主要是因为prefill的时候需要计算注意力它是会利用prompt产生的所有token进行计算的而注意力机制是平方级的计算复杂度输入序列又是超长的那一起计算的话显存开销就无法承受了所以需要chunk再prefill另一套的chunked-prefill好像和通信什么的有关来着-另需要注意chunked-prefill虽然说会先chunk然后各自在块内进行prefill但块内的prefill并不会像一般的prefill那样生成第一个token那样就会很奇怪相当于基于截断的信息生成了一个token而且有很多个chunk最后就会是基于很多个阶段的信息各自生成一个token这些token可以认为其实没什么用的所以实际上是chunk完在各自块内计算kv然后进行压缩最后把压缩完的各个块的kv拼到一起来生成真正意义上的第一个token">chunked
prefill：博客里的chunked
prefill，应该是指，对输入的超长序列（prompt），进行分块，然后在各自的块内进行prefill操作。这主要是因为，prefill的时候需要计算注意力，它是会利用prompt产生的所有token进行计算的。而注意力机制是平方级的计算复杂度，输入序列又是超长的，那一起计算的话显存开销就无法承受了。所以需要chunk再prefill（另一套的chunked
prefill好像和通信什么的有关来着）<br>（另，需要注意，chunked
prefill虽然说会先chunk，然后各自在块内进行prefill，但块内的prefill并不会像一般的prefill那样生成第一个token。那样就会很奇怪，相当于基于截断的信息生成了一个token。而且有很多个chunk，最后就会是：基于很多个阶段的信息各自生成一个token。这些token可以认为其实没什么用的。所以实际上是chunk完，在各自块内计算kv，然后进行压缩，最后把压缩完的各个块的kv拼到一起，来生成真正意义上的第一个token）</h2>
<h2 id="前缀上下文指用户在多轮对话中在具体提出问题前给出的背景性引导性信息本质上就是context模型的回答需要基于这些内容">前缀上下文：指用户在多轮对话中，在具体提出问题前，给出的背景性、引导性信息。本质上就是context，模型的回答需要基于这些内容</h2>
<h1 id="我的问题">我的问题：</h1>
<h2 id="带问题指令的kv-cache-compression是怎么工作的有哪些方法">带问题（指令）的kv
cache compression，是怎么工作的？有哪些方法？</h2>
<h2 id="多轮对话场景为什么是不带指令的kv-cache压缩场景">多轮对话场景为什么是不带指令的kv
cache压缩场景？</h2>
<h3 id="因为多轮对话里必然会有多个问题如果要带着问题指令进行压缩那就需要挑出一个问题来对kv-cache进行挑选但是这样就会有偏颇有可能一些内容对于这个问题而言是不重要的但是对于另外一个问题而言其实很重要我们不能保证用户之后不会问这个问题">因为多轮对话里必然会有多个问题。如果要带着问题（指令）进行压缩，那就需要挑出一个问题来对kv
cache进行挑选。但是这样就会有偏颇，有可能一些内容对于这个问题而言是不重要的，但是对于另外一个问题而言其实很重要。我们不能保证用户之后不会问这个问题</h3>
<h2 id="kv-cache-compression是针对哪些token而言的是针对prompt还是针对模型生成的token">kv
cache
compression是针对哪些token而言的？是针对prompt，还是针对模型生成的token？</h2>
<h3 id="其实都可以prefill完是否对prompt-token的kv-cache进行压缩是一个可选的操作比如chunked-prefill里一般就会边chunk-prefill边压缩也就是一种流式的操作因为不然的话显存开销太大了把超长序列的所有token的kv-cache都存下来都叫超长序列了肯定是很多token的比如输入了一个很长的文档之类的">其实都可以。prefill完是否对prompt
token的kv cache进行压缩，是一个可选的操作。比如chunked
prefill里，一般就会边chunk
prefill，边压缩（也就是一种流式的操作）。因为不然的话，显存开销太大了（把超长序列的所有token的kv
cache都存下来。都叫超长序列了，肯定是很多token的。比如输入了一个很长的文档之类的）</h3>
<h2 id="为什么观察窗口都采用近期的若干token这样不是会有点局限吗能不能通过采样把之前的一些token也采样进观察窗口这样会不会全面一点">为什么观察窗口都采用近期的若干token？这样不是会有点局限吗？能不能通过“采样”，把之前的一些token也采样进观察窗口？这样会不会全面一点？</h2>
<h2 id="生成的token是如何压缩的看起来似乎是生成一定数量之后对所有的历史kv进行全量重新压缩有什么论文佐证吗可能得读一下snapkv了">生成的token是如何压缩的？看起来似乎是“生成一定数量之后，对所有的历史kv进行全量重新压缩”？有什么论文佐证吗？可能得读一下SnapKV了</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/27/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/kv%20cache%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/27/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/kv%20cache%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">kv cache基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-09-27 15:14:00 / Modified: 15:15:55" itemprop="dateCreated datePublished" datetime="2025-09-27T15:14:00+08:00">2025-09-27</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/blog%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">blog阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/blog%E9%98%85%E8%AF%BB/llm/" itemprop="url" rel="index"><span itemprop="name">llm</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/blog%E9%98%85%E8%AF%BB/llm/efficiency/" itemprop="url" rel="index"><span itemprop="name">efficiency</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/blog%E9%98%85%E8%AF%BB/llm/efficiency/kv-cache/" itemprop="url" rel="index"><span itemprop="name">kv cache</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="在了解kv-cache的过程中读到了游凯超的一篇回答感觉真的写的很详细而且不仅局限于kv-cache包括为何这样设计也讲清楚了">在了解kv
cache的过程中，读到了<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/596900067/answer/3424958454">游凯超的一篇回答</a>，感觉真的写的很详细，而且不仅局限于kv
cache，包括为何这样设计，也讲清楚了</h1>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/09/27/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/kv%20cache%E5%9F%BA%E7%A1%80/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/24/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/knowledge-graph/DuetGraph%EF%BC%9ACoarse-to-Fine%20Knowledge%20Graph%20Reasoning%20with%20Dual-Pathway%20Global-Local%20Fusion/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/24/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/knowledge-graph/DuetGraph%EF%BC%9ACoarse-to-Fine%20Knowledge%20Graph%20Reasoning%20with%20Dual-Pathway%20Global-Local%20Fusion/" class="post-title-link" itemprop="url">DuetGraph：Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-09-24 17:15:00 / Modified: 17:28:18" itemprop="dateCreated datePublished" datetime="2025-09-24T17:15:00+08:00">2025-09-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/" itemprop="url" rel="index"><span itemprop="name">nlp</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/knowledge-graph/" itemprop="url" rel="index"><span itemprop="name">knowledge graph</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="venuenips-25">Venue：NIPS 25</h1>
<h1 id="date2025-07-15">date：2025-07-15</h1>
<h1 id="动机">动机：</h1>
<h2 id="现有的kg推理方法通常会遇到score-oversmoothing的问题有点类似gnn里的oversmoothing也就是推理后正确答案和错误答案的分数极为接近导致无法很好的分辨论文认为现有方法一味堆叠message-passing-layer和attn-layer导致score-oversmoothing问题进一步加剧同时现有方法大多是one-shot-reasoning因此判别能力有所不足">现有的KG推理方法通常会遇到score
oversmoothing的问题（有点类似gnn里的oversmoothing）。也就是推理后，正确答案和错误答案的分数极为接近，导致无法很好的分辨。论文认为，现有方法一味堆叠message
passing layer和attn layer，导致score
oversmoothing问题进一步加剧；同时现有方法大多是one-shot
reasoning，因此判别能力有所不足</h2>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/09/24/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/knowledge-graph/DuetGraph%EF%BC%9ACoarse-to-Fine%20Knowledge%20Graph%20Reasoning%20with%20Dual-Pathway%20Global-Local%20Fusion/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">bluemouse</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">252</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">83</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">104</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bluemouse</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
