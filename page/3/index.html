<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"blueeemouse.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="bluemouse&#39;s blog">
<meta property="og:url" content="https://blueeemouse.github.io/page/3/index.html">
<meta property="og:site_name" content="bluemouse&#39;s blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="bluemouse">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://blueeemouse.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>bluemouse's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">bluemouse's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/10/19/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E6%84%9F%E6%83%B3%E4%B8%8E%E6%80%9D%E8%80%83/%E9%9A%8F%E7%AC%941/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/19/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E6%84%9F%E6%83%B3%E4%B8%8E%E6%80%9D%E8%80%83/%E9%9A%8F%E7%AC%941/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-10-19 11:44:01" itemprop="dateCreated datePublished" datetime="2025-10-19T11:44:01+08:00">2025-10-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-27 15:26:41" itemprop="dateModified" datetime="2025-12-27T15:26:41+08:00">2025-12-27</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>感觉，之所以要从参与到基模的研究，一个很重要的原因是，参与到基模的研究，可以让你更了解基模发展的水平，以免出现像以前大模型刚出来的时候的惨案，因为基模水平上涨，把很多方向直接给干掉了，比如各种应用方向（看到其它人也有这个焦虑，起码说明这确实是个问题）……或者说，基模的研究是很保值的，至少当下来看</p>
<p>向他人汇报，其实是一个很好的倒逼自己进行总结、思考的过程啊（只要对方不会因为你汇报不好就急眼……）</p>
<p>RAG，如果说大家最近因为llm的context-window不断增加，以及因为Claude
Code那种grep式的文本检索很高效且效果很好，而进一步质疑它的必要性；但检索外部知识这个需求一定是在的。检索的模态显然也不可能局限于文本模态。一旦涉及到其它模态（图像、视频，乃至现在还不算特别成熟的音频模态），grep终归还是不奏效了。且涉及多模态的话，最容易想到，也可能是最成熟的方案就是embedding了。不用embedding的话呢？会不会就类似于退回到以前了……（wc，我tm这里写的竟然和一个多月前写的几乎完全一样（见[[关于RAG的思考]]）……不知道该说是思想一致还是毫无长进了）</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/10/10/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E9%95%BF%E6%9C%9F%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E6%80%9D%E8%80%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/10/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E9%95%BF%E6%9C%9F%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E6%80%9D%E8%80%83/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-10-10 15:35:48" itemprop="dateCreated datePublished" datetime="2025-10-10T15:35:48+08:00">2025-10-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-12-31 12:22:47" itemprop="dateModified" datetime="2025-12-31T12:22:47+08:00">2025-12-31</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>先找找看有没有什么和多模态相关的，但是不那么废卡的
LVLM幻觉相关的，感觉上是很重要的，但不知道落地上如何。可以参考这个<a target="_blank" rel="noopener" href="https://github.com/Purshow/Awesome-LVLM-Hallucination">仓库</a>，niu神搞的</p>
<p>RAG for
vision，有一说一，这个是比较切实的，但是一个问题在于，它是否合理？是否有必要？还是说只是为了缝合发论文而做的？值得思考。如果找到合理恰当的切入点，应该也是能作出一些好工作的。参考这个<a target="_blank" rel="noopener" href="https://github.com/zhengxuJosh/Awesome-RAG-Vision?tab=readme-ov-file#14-multi-modal">仓库</a></p>
<p>另，看看pageindex，这个东西（组织？）好像在研究非向量式的下一代RAG范式？不是很懂，到底是噱头还是确有其事</p>
<p>unified
multimodal，这个应该暂时碰不了，大概是非常废卡的。仓库可以看<a target="_blank" rel="noopener" href="https://github.com/Purshow/Awesome-Unified-Multimodal">这个</a>，同样是牛神搞的。不过，这个现在好像主要还是针对2D图像输入的吧？（不管是生成还是理解）有没有可能之后扩展到兼容3D视频输入的？二者需要的方法，本质上一致吗？还是说其实是有差别的？</p>
<p>视频理解，似乎是多模态里一个不那么废卡的方向，同时也还算有意思。可以看看这个人，<a target="_blank" rel="noopener" href="https://www.xiaohongshu.com/user/profile/5bfe42cb44363b0b17fc3e44?xsec_token=ABeLJ-up-BNIFchzXxqpc5kXsLWH--pCDU2SboKv0jVgA=&amp;xsec_source=pc_note">庞子奇</a>的xhs以及谷歌学术。他是高校学生，也有卡不足的困境</p>
<p>llm
safety，很好讲故事，理论上讲也尤为重要。加上对卡的需求相对没那么大，无疑是学术界的一个很好的研究题目。但为什么有很多人对此诟病呢……（但是safety也不能笼统地讲safety。它包含的内容是很多的：backdoor之类的比较传统的；幻觉；ai
欺骗（杨耀东那边的）；人类价值观对齐……）</p>
<p>llm
long-context。这个感觉也是很solid的。似乎现在关注度有所下降？但总而言之，很多问题都能归结到这方面上。能提升这个的话，显然会很有影响力。而且现在，怎么说，感觉大家的context
window虽说是有所提升了，但你真的聊多了，其实还是不行，效果下降得比较多（也就是降智比较严重）。如何设计更本质的metric以及构造更有效的benchmark，或许是很重要的</p>
<p>现在在做的，算是routing大类。往上扩展一下，应该就是collaboration了吧？比如llm
collaboration？这是否又可以扩展到multi-agents的合作呢？当单agent的能力足够的情况下，multi-agents会不会真正的有意义了呢（如果是一群菜鸡互啄，好像也就那样吧？）
关于rag，有没有可能，一个可以做的就是，评价现有的指标，然后提出新的指标？因为起码EM指标就是感觉上都觉得它不太合理的。不过要说什么新的指标，其实llm-as-a-judge就差不多了吧</p>
<p>lmsys看一看吧。就算不是专门做这个，肯定也是懂得越多越好。一个<a target="_blank" rel="noopener" href="https://lmsys.org/blog/">网站</a>，chayenne zhao组织的。这个<a target="_blank" rel="noopener" href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/tree/main?tab=readme-ov-file">GitHub仓库</a>更是值得细细学习一下。以及，这个<a target="_blank" rel="noopener" href="https://www.zhihu.com/people/alan-70-79-23/posts">知乎博客</a>，可以从最早的开始读起，能感受到成长的快速……
<a target="_blank" rel="noopener" href="https://skyzh.github.io/tiny-llm/">tiny-llm</a>，疑似是cmu的一门课</p>
<p>agent的efficiency研究？这会是一个重要的问题吗？但它的efficiency研究，和对llm的efficiency研究，区别在哪里？得找到这个区别，才有专门研究的价值和意义吧。（而且也才有创新）。这也算蹭上agent热度了（尤其是单agent的efficiency，感觉现在是连它都没做好，就一堆工作想着去做multi-agent的collaboration之类的东西了）</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/10/09/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/video/Packing%20Input%20Frame%20Context%20in%20Next-Frame%20Prediction%20Models%20for%20Video%20Generation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/09/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/video/Packing%20Input%20Frame%20Context%20in%20Next-Frame%20Prediction%20Models%20for%20Video%20Generation/" class="post-title-link" itemprop="url">Packing Input Frame Context in Next-Frame Prediction Models for Video Generation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-10-09 00:18:00" itemprop="dateCreated datePublished" datetime="2025-10-09T00:18:00+08:00">2025-10-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-11-15 22:39:29" itemprop="dateModified" datetime="2025-11-15T22:39:29+08:00">2025-11-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/" itemprop="url" rel="index"><span itemprop="name">cv</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/video/" itemprop="url" rel="index"><span itemprop="name">video</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/video/video-generation/" itemprop="url" rel="index"><span itemprop="name">video generation</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="venuearxiv">Venue：arxiv</h1>
<h1 id="date2025-04-21">date：2025-04-21</h1>
<h1 id="动机">动机：</h1>
<h1 id="insight">insight：</h1>
<h2 id="初版论文里提到的drifting-problem感觉上是比较自然地会出现的因为是自回归式的生成如果当前帧生成效果不好比如动作生成失误了那基于当前帧生成的下一帧的效果可能也不会好论文里似乎提到了这表明drifting其实仅发生在因果采样里即模型只能访问过去的帧为了打破这一点从而减缓drifting-problem论文考虑引入未来帧作为双向的上下文先不说别的光是这个动机的考量就很充足比起莫名其妙地引入双向上下文要合理多了">（初版）论文里提到的drifting
problem，感觉上是比较自然地会出现的：因为是自回归式的生成，如果当前帧生成效果不好（比如动作生成失误了），那基于当前帧生成的下一帧的效果可能也不会好。论文里似乎提到了，这表明，drifting其实仅发生在因果采样里——即模型只能访问“过去”的帧。为了打破这一点，从而减缓drifting
problem，论文考虑引入“未来”帧作为双向的上下文。先不说别的，光是这个动机的考量，就很充足，比起莫名其妙地引入双向上下文要合理多了</h2>
<h2 id="论文明确指出了drifting和forgetting-problem二者是相互矛盾的为此需要对二者进行一个balance而论文的做法是分别设计一个部件专门负责解决一个问题这个思路到底是不是终极思路先不说起码明确指出二者需要balance这一点也是很重要的提供了一个明确的认知">论文明确指出了drifting和forgetting
problem二者是相互矛盾的。为此，需要对二者进行一个balance。而论文的做法是，分别设计一个部件，专门负责解决一个问题。这个思路到底是不是终极思路先不说，起码明确指出二者需要balance这一点，也是很重要的。提供了一个明确的认知</h2>
<h2 id="论文里压缩到定长的方法是采用了几何级数的压缩率这个虽然是人为规定的压缩率但感觉上特别漂亮并且的确是确保了context-length有一个上限不会过大">论文里压缩到定长的方法，是采用了几何级数的压缩率。这个虽然是人为规定的压缩率，但感觉上特别漂亮，并且的确是确保了context
length有一个上限，不会过大</h2>
<h1 id="contribution">contribution：</h1>
<h2 id="提出了一种基于几何级数的压缩方法可以确保把无限长的输入都压缩到一个context-upper-bound下并且相对会保留重要的信息">提出了一种基于几何级数的压缩方法，可以确保把无限长的输入都压缩到一个context
upper bound下，并且相对会保留重要的信息</h2>
<h2 id="引入bi-directional-context从而减缓drifting-problem进而辅助生成更长的视频但是本身计算量上并没有增加太多">引入bi-directional
context，从而减缓drifting
problem，进而辅助生成更长的视频，但是本身计算量上并没有增加太多</h2>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/10/09/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/cv/video/Packing%20Input%20Frame%20Context%20in%20Next-Frame%20Prediction%20Models%20for%20Video%20Generation/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/10/07/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/speculative-decoding/%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20%20%E6%8A%95%E6%9C%BA%E8%A7%A3%E7%A0%81%E2%80%94%E2%80%94What%20makes%20for%20efficient%20speculative%20decoding%EF%BC%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/07/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/speculative-decoding/%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20%20%E6%8A%95%E6%9C%BA%E8%A7%A3%E7%A0%81%E2%80%94%E2%80%94What%20makes%20for%20efficient%20speculative%20decoding%EF%BC%9F/" class="post-title-link" itemprop="url">博客阅读 投机解码——What makes for efficient speculative decoding？</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-10-07 11:02:00" itemprop="dateCreated datePublished" datetime="2025-10-07T11:02:00+08:00">2025-10-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-08 12:23:40" itemprop="dateModified" datetime="2025-10-08T12:23:40+08:00">2025-10-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/" itemprop="url" rel="index"><span itemprop="name">nlp</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/" itemprop="url" rel="index"><span itemprop="name">llm</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/" itemprop="url" rel="index"><span itemprop="name">efficiency</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/speculative-decoding/" itemprop="url" rel="index"><span itemprop="name">speculative decoding</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="原博客链接">原博客<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/27272034867">链接</a></h1>
<h1 id="通过这篇博客也算稍微了解了一点点投机解码权当扩展知识面了">通过这篇博客，也算稍微了解了一点点投机解码。权当扩展知识面了</h1>
<h2 id="首先给一句话简单概括speculative-decoding在干什么它在利用generate-next-token过程中冗余的算力预测未来若干个token-只要有几个预测对了一般都是赚的">首先，给一句话简单概括speculative
decoding在干什么：它在利用generate next
token过程中，冗余的算力，预测未来若干个token<br>只要有几个预测对了，一般都是赚的</h2>
<h2 id="挨个说明几个问题-为什么生成下一个token过程中会有算力冗余-用什么方法预测未来的若干个token的-怎么判断是否赚了">挨个说明几个问题：<br>为什么生成下一个token过程中，会有算力冗余？<br>用什么方法预测未来的若干个token的？<br>怎么判断是否赚了？</h2>
<h2 id="算力冗余问题">算力冗余问题：</h2>
<h3 id="生成下一个token的过程其实就是用最新生成的token的query和之前所有token包括这个token它自己的key进行attn来聚合value最后送到分类头那里预测下一个token的类别这个过程里我们只需要对最新的token计算qkv因为前面的token的key和value有kv-cache保留不需要重新算在此论文其实是作出了一些假设的即假设使用场景不是long-context因此可以暂且忽略掉除了计算qkv以外的地方所消耗的算力比如attn部分norm部分softmax部分激活函数部分等">生成下一个token的过程，其实就是用最新生成的token的query，和之前所有token（包括这个token它自己）的key进行attn，来聚合value，最后送到分类头那里预测下一个token的类别。这个过程里，我们只需要对最新的token计算qkv（因为前面的token的key和value，有kv
cache保留，不需要重新算）。在此，论文其实是作出了一些假设的，即假设使用场景不是long
context。因此可以暂且忽略掉除了计算qkv以外的地方所消耗的算力（比如attn部分，norm部分，softmax部分，激活函数部分，等）</h3>
<h3 id="因此在这个场景下我们假设了计算部分只考虑矩阵乘法因为qkv就是矩阵乘法访存部分也就只考虑矩阵乘法中要用到的参数矩阵的访存开销假设输入为seq_len-embed_dim关于输入形状的假设也比较重要这里是原博客里的假设也即假设batch-size为1了后面会针对这一点进行细讲为什么假设成了1却不会影响结果矩阵形状为embed_dim-hidden_dim记seq_len为sembed_dim为ehidden_dim为h则我们得到此时的计算密度computation-intensityci为其定义为计算量除以访存量ci_gemmfrac2scdot-ecdot-hscdot-e-ecdot-hfrac2scdot-hshfrac2cdot-s1fracsh-approx-2cdot-s-关于这个计算过程首先需要说明分子是计算量然后之所以分子有个2是因为这里把加法和乘法都考虑进去且分开算了而分母的scdot-eecdot-h则是在把权重和计算输入都进行搬移所需要的访存量之后一步就是一个约分而再往后一步是同除一个h之所以进行这个操作是因为我们假设当前不是long-context场景也就是s会比较小相对而言有s-ll-h因此同除h后我们可以看得更清楚倒数第二步的分母里的fracsh就可以近似为0了因此得到了最后的近似结果两倍的seq_len就是说在近似之后short-context情况下计算密度其实就是两倍的seq_len而且需要说明的是上面的计算其实是指计算kv的过程所以我们的seq_len实质是指需要计算kv的token的个数而生成过程中我们也提到了每次只需要计算新生成的那个token的qkv因此seq_len可以当成1因而计算密度也就是2这显然是会比显卡的计算密度要小的故我们说生成过程是memory-bound的一个过程有算力冗余">因此，在这个场景下，我们假设了，计算部分只考虑矩阵乘法（因为qkv就是矩阵乘法），访存部分也就只考虑矩阵乘法中要用到的参数矩阵的访存开销。假设输入为(seq_len,
embed_dim)（关于输入形状的假设，也比较重要。这里是原博客里的假设，也即假设batch
size为1了。后面会针对这一点进行细讲，为什么假设成了1却不会影响结果），矩阵形状为(embed_dim,
hidden_dim)。记seq_len为s，embed_dim为e，hidden_dim为h，则我们得到此时的计算密度（Computation
Intensity，CI）为（其定义为计算量除以访存量）<span class="math inline">\(CI_{GEMM}=\frac{2s\cdot e\cdot h}{s\cdot e +
e\cdot h}=\frac{2s\cdot h}{s+h}=\frac{2\cdot s}{1+\frac{s}{h}} \approx
2\cdot
s\)</span><br>关于这个计算过程，首先需要说明，分子是计算量。然后之所以分子有个2，是因为这里把加法和乘法都考虑进去，且分开算了。而分母的<span class="math inline">\(s\cdot e+e\cdot
h\)</span>，则是在把权重和计算输入都进行搬移所需要的访存量。之后一步就是一个约分，而再往后一步是同除一个h。之所以进行这个操作，是因为我们假设当前不是long
context场景，也就是s会比较小。相对而言，有<span class="math inline">\(s
\ll
h\)</span>。因此同除h后，我们可以看得更清楚：倒数第二步的分母里的<span class="math inline">\(\frac{s}{h}\)</span>就可以近似为0了，因此得到了最后的近似结果，两倍的seq_len。就是说，在近似之后，short
context情况下，计算密度其实就是两倍的seq_len。而且需要说明的是，上面的计算其实是指计算kv的过程，所以我们的seq_len实质是指需要计算kv的token的个数。而生成过程中，我们也提到了，每次只需要计算新生成的那个token的qkv。因此seq_len可以当成1，因而计算密度也就是2。这显然是会比显卡的计算密度要小的。故，我们说，生成过程是memory
bound的一个过程，有算力冗余。</h3>
<h3 id="大体是这么个分析过程不过有一些细节应该还要考虑">大体是这么个分析过程。不过有一些细节应该还要考虑</h3>
<h4 id="其一batch-size为什么没考虑进去因为直观上这应该会对计算密度的结果有影响考虑了batch-size显然计算量上是要乘以batch-size的但是访存量则未必参数矩阵还是只用取一次只不过输入确实也是乘了batch-size的这样的话记batch-size为b则表达式应该是ci_gemmfrac2cdot-bcdot-scdot-ecdot-hbcdot-scdot-e-ecdot-hfrac2cdot-bcdot-scdot-hbcdot-shfrac2cdot-bcdot-sbfracsh到这我们应该就能发现其实不影响结果了因为还是short-context场景所以fracsh那一项可以近似为0则此时分子分母的b就可以消掉了结论还是不变的不知道作者是不是知道这一点所以出于计算的方便省掉了batch-size维度">其一，batch
size为什么没考虑进去？因为直观上，这应该会对计算密度的结果有影响。考虑了batch
size，显然计算量上是要乘以batch
size的，但是访存量则未必。参数矩阵还是只用取一次，只不过输入确实也是乘了batch
size的。这样的话，记batch size为b，则表达式应该是<span class="math inline">\(CI_{GEMM}=\frac{2\cdot b\cdot s\cdot e\cdot
h}{b\cdot s\cdot e + e\cdot h}=\frac{2\cdot b\cdot s\cdot h}{b\cdot
s+h}=\frac{2\cdot b\cdot
s}{b+\frac{s}{h}}\)</span>到这我们应该就能发现，其实不影响结果了。因为还是short
context场景，所以<span class="math inline">\(\frac{s}{h}\)</span>那一项可以近似为0，则此时分子分母的b就可以消掉了。结论还是不变的（不知道作者是不是知道这一点，所以出于计算的方便，省掉了batch
size维度……）</h4>
<h4 id="其二如何用计算密度判断是memory-bound还是compute-bound它的本质是什么-这个其实就是一个理解上的问题而已计算密度本质上是说每取出1字节的数据能完成的flops计算那么当我们的操作ci大于显卡的ci时表明我们用这个显卡的时候取出1字节的数据量后完成的计算量不够因此这个操作是compute-bound而当我们的操作的ci小于显卡的ci的时候这说明我们用这个显卡取出1字节的数据量还没用完全部的计算量这个操作就完成了此时有一些算力的冗余但是没有数据了所以是memory-bound">其二，如何用计算密度判断是memory
bound还是compute
bound？它的本质是什么？<br>这个其实就是一个理解上的问题而已。计算密度，本质上是说，每取出1字节的数据，能完成的FLOPs计算。那么，当我们的操作CI大于显卡的CI时，表明，我们用这个显卡的时候，取出1字节的数据量后，完成的计算量不够。因此这个操作是compute
bound。而当我们的操作的CI小于显卡的CI的时候，这说明我们用这个显卡取出1字节的数据量，还没用完全部的计算量，这个操作就完成了。此时有一些算力的冗余，但是没有数据了。所以是memory
bound</h4>
<h2 id="如何预测未来的若干个token的">如何预测未来的若干个token的：</h2>
<h3 id="这里就涉及到投机解码的一个基本的思路drafting-verification大体上是说用某种方法预测未来的若干个token然后让llm来验证这些token里对了多少个我们会采用直到第一个错误token之前的所有猜测结果因为llm进行预测虽然是对多个token进行预测但是根据前面的分析生成阶段是memory-bound因此一般情况下检验多个token是否正确其时间依然和生成一个token的时间差不多主要还是访存卡时间此时我们的某种猜测方法虽然它肯定也要消耗一些时间和算力但一般它的开销都会小很多因此只要不是全都猜错了通常都是赚的">这里就涉及到投机解码的一个基本的思路：drafting-verification。大体上是说，用某种方法预测未来的若干个token，然后让llm来验证这些token里对了多少个。我们会采用直到第一个错误token之前的所有猜测结果。因为llm进行预测，虽然是对多个token进行预测，但是根据前面的分析，生成阶段是memory
bound，因此一般情况下，检验多个token是否正确，其时间依然和生成一个token的时间差不多。主要还是访存卡时间。此时，我们的某种猜测方法，虽然它肯定也要消耗一些时间和算力，但一般它的开销都会小很多。因此只要不是全都猜错了，通常都是赚的</h3>
<h3 id="至于说猜测的方法一般是用一个小模型当然也有用大模型乃至model-free的对于这个猜测的模型一般称作draft-modelllm本身则被称为target-model">至于说猜测的方法，一般是用一个小模型。当然也有用大模型，乃至model-free的。对于这个猜测的模型，一般称作draft
model。llm本身则被称为target model</h3>
<h3 id="另外这里需要详细说说具体的llm的verify的过程这里我们考虑用model的猜测方法那么draft-model给出了后续的gamma个时间步的token这里采用和原博客一样的记号此时我们可以得到这gamma个token的hidden-state怎么verify呢就是把这个gamma个token的hidden-state拿去给llm让它计算预测这些token应该是什么类别看看和draft-model的预测结果是否一致我们认为一个token只有当llm和draft-model的预测结果一致的时候才算通过否则我们就认为有可能出错了我们采用结果也是只采用到第一个错误token前的结果举个例子draft-model一共预测未来8个token验证发现前三个是对的第四个是错的即使说第五个到第八个都是对的我们也不会用只会用前三个正确的猜测结果这里之所以能有加速的效果就是因为llm-verify的过程是真的可以并行的只需要把这gamma个token的hidden-state拿去进行一些计算最后给分类头进行分类即可并不是一个自回归式的过程因为已经有了这些token的特征了否则如果verify也要自回归式的生成那完全失去意义了为什么不老老实实让llm生成呢-这里很容易产生一个问题直接用draft-model它很可能是一个小模型产生的hidden-state拿去给llm预测这样真的合理吗verify的结果真的准吗事实上这就是很多工作聚集和改进的点一些工作里它们为了确保verify能尽可能准会约束draft-model产生的hidden-state尽量和llm产生的hidden-state尽量一致虽然也有后面的工作发现这其实并非必要的另外我们verify的时候llm的权重不会动也就是会用到llm本身的知识此外verify的标准是llm和小模型预测token结果一致才算这个token预测正确了这类似一个双重保险只要二者不一致就视为不正确这在某种程度上也确保了verify的准确性">另外，这里需要详细说说具体的llm的verify的过程。这里我们考虑用model的猜测方法。那么，draft
model给出了后续的<span class="math inline">\(\gamma\)</span>个时间步的token（这里采用和原博客一样的记号）。此时我们可以得到这<span class="math inline">\(\gamma\)</span>个token的hidden
state。怎么verify呢？就是把这个<span class="math inline">\(\gamma\)</span>个token的hidden
state，拿去给llm，让它计算、预测这些token应该是什么类别，看看和draft
model的预测结果是否一致。我们认为，一个token只有当llm和draft
model的预测结果一致的时候，才算通过；否则我们就认为有可能出错了。我们采用结果，也是只采用到第一个错误token前的结果（举个例子，draft
model一共预测未来8个token。验证发现前三个是对的，第四个是错的。即使说第五个到第八个都是对的，我们也不会用。只会用前三个正确的猜测结果）。这里之所以能有加速的效果，就是因为，llm
verify的过程是真的可以并行的。只需要把这<span class="math inline">\(\gamma\)</span>个token的hidden
state拿去进行一些计算，最后给分类头进行分类即可，并不是一个自回归式的过程。因为已经有了这些token的特征了（否则，如果verify也要自回归式的生成，那完全失去意义了，为什么不老老实实让llm生成呢）<br>这里很容易产生一个问题：直接用draft
model（它很可能是一个小模型）产生的hidden
state，拿去给llm预测，这样真的合理吗？verify的结果真的准吗？事实上，这就是很多工作聚集和改进的点。一些工作里，它们为了确保verify能尽可能准，会约束draft
model产生的hidden state尽量和llm产生的hidden
state尽量一致（虽然也有后面的工作发现，这其实并非必要的）；另外，我们verify的时候，llm的权重不会动，也就是会用到llm本身的知识；此外，verify的标准是，llm和小模型预测token结果一致，才算这个token预测正确了。这类似一个双重保险。只要二者不一致，就视为不正确。这在某种程度上也确保了verify的准确性</h3>
<h2 id="怎么判断是否赚了">怎么判断是否赚了：</h2>
<h3 id="判断是否赚了其实主要是看是否有加速加速比有多高毕竟投机解码是一个加速推理的技术直观上当我们的一次draft-verification过程里接收的token越多也就是经过verify的token越多draft-model一次预测的时间开销越小llm并行verify未来gamma个token的耗时越小加速的程度应该越大如果要说加速比那显然就是llm正常生成一个token的时间相对于我们预测验证生成token的时间越长加速比越大由此可以得到一个公式speedupapprox-tau-times-fracl_tgamma-times-l_dl_t其中整体上分子表示llm正常生成一个token的耗时其余项大体表示我们用投机解码平均生成一个token的耗时可以看成是frac1fracgamma-times-l_dl_ttautau表示平均接受距离也就是平均一次draft-verification-cycle中有多少个正确token会被输出gamma表示我们要往后预测的token的个数l_d表示draft-model预测一次的耗时l_t表示llm并行verify-gamma个token的耗时l_t则表示llm正常生成一个token的耗时虽说我们是在利用llm的冗余算力并行地去验证gamma个token是否正确但毕竟它和正常生成一个token的耗时还是略有不同不过我们看待这个式子的时候也可以把l_t姑且看成和l_t一样这样后面的分式项就是小于1的但我们的tau通常不会是1这也太倒霉了就是说draft-model全错只要draft-model不太差一般加速比还是能大于1的">判断是否赚了，其实主要是看是否有加速，加速比有多高（毕竟投机解码是一个加速推理的技术）。直观上，当我们的一次draft-verification过程里，接收的token越多（也就是经过verify的token越多），draft
model一次预测的时间开销越小，llm并行verify未来<span class="math inline">\(\gamma\)</span>个token的耗时越小，加速的程度应该越大。如果要说加速比，那显然就是，llm正常生成一个token的时间相对于我们预测+验证生成token的时间越长，加速比越大。由此可以得到一个公式：<span class="math display">\[Speedup\approx \tau \times
\frac{L_{t}^{&#39;}}{\gamma \times
L_{d}+L_{t}}\]</span>其中，整体上，分子表示llm正常生成一个token的耗时；其余项大体表示我们用投机解码平均生成一个token的耗时（可以看成是<span class="math inline">\(\frac{1}{\frac{\gamma \times
L_{d}+L_{t}}{\tau}}\)</span>）。<span class="math inline">\(\tau\)</span>表示平均接受距离。也就是平均一次draft-verification
cycle中，有多少个正确token会被输出<span class="math inline">\(\gamma\)</span>表示我们要往后预测的token的个数，<span class="math inline">\(L_{d}\)</span>表示draft model预测一次的耗时，<span class="math inline">\(L_{t}\)</span>表示llm并行verify <span class="math inline">\(\gamma\)</span>个token的耗时，<span class="math inline">\(L_{t}^{&#39;}\)</span>则表示llm正常生成一个token的耗时（虽说，我们是在利用llm的冗余算力，并行地去验证<span class="math inline">\(\gamma\)</span>个token是否正确，但毕竟它和正常生成一个token的耗时还是略有不同）。不过，我们看待这个式子的时候，也可以把<span class="math inline">\(L_{t}^{&#39;}\)</span>姑且看成和<span class="math inline">\(L_{t}\)</span>一样。这样，后面的分式项就是小于1的，但我们的<span class="math inline">\(\tau\)</span>通常不会是1（这也太倒霉了，就是说draft
model全错）。只要draft model不太差，一般加速比还是能大于1的</h3>
<h3 id="总结一下的话我们可以认为投机解码加速的地方在于我们用gamma次小模型的计算一次大模型的计算验证换了tau次大模型的计算">总结一下的话，我们可以认为，投机解码加速的地方在于，我们用<span class="math inline">\(\gamma\)</span>次小模型的计算+一次大模型的计算（验证）换了<span class="math inline">\(\tau\)</span>次大模型的计算</h3>
<h1 id="上述其实就是一些基础的投机解码相关的概念和内容博客的后续内容就是在阐述经典sota方法以及他们的工作是如何改进的整体的思路其实都是围绕上面的加速比公式展开的通过观察哪些因子可以改进分析应当怎么改进设计方法剩下就暂时不细讲了挑一些有疑问的地方进行解释">上述其实就是一些基础的投机解码相关的概念和内容。博客的后续内容就是在阐述经典sota方法以及他们的工作是如何改进的。整体的思路其实都是围绕上面的加速比公式展开的，通过观察哪些因子可以改进，分析应当怎么改进，设计方法。剩下就暂时不细讲了，挑一些有疑问的地方进行解释：</h1>
<h2 id="eagle为什么要对齐feature">EAGLE为什么要对齐feature？</h2>
<h3 id="博客里说是为了让小模型在推理阶段自回归的输入能更加稳定但我个人感觉其实是为了让llm-verify的时候准确率能高一点毕竟只有当小模型得到的特征和大模型尽可能接近的时候大模型verify的准确率才会更高">博客里说是为了让小模型在推理阶段自回归的输入能更加稳定。但我个人感觉其实是为了让llm
verify的时候准确率能高一点。毕竟，只有当小模型得到的特征和大模型尽可能接近的时候，大模型verify的准确率才会更高</h3>
<h1 id="动机">动机：</h1>
<h1 id="insight">insight：</h1>
<h1 id="contribution">contribution：</h1>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/10/07/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/speculative-decoding/%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB%20%20%E6%8A%95%E6%9C%BA%E8%A7%A3%E7%A0%81%E2%80%94%E2%80%94What%20makes%20for%20efficient%20speculative%20decoding%EF%BC%9F/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/10/03/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/MC-LLaVA%EF%BC%9AMulti-Concept%20Personalized%20Vision-Language%20Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/03/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/MC-LLaVA%EF%BC%9AMulti-Concept%20Personalized%20Vision-Language%20Model/" class="post-title-link" itemprop="url">MC-LLaVA：Multi-Concept Personalized Vision-Language Model</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-10-03 21:22:00 / Modified: 23:59:29" itemprop="dateCreated datePublished" datetime="2025-10-03T21:22:00+08:00">2025-10-03</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/MLLM/" itemprop="url" rel="index"><span itemprop="name">MLLM</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/MLLM/personalized-VLMs/" itemprop="url" rel="index"><span itemprop="name">personalized VLMs</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="venuearxiv">Venue：arxiv</h1>
<h1 id="date2025-03-26">date：2025-03-26</h1>
<h1 id="动机">动机：</h1>
<h2 id="论文关注的任务是multi-concept-personalization是要让模型理解并记忆用户自定义的特定概念由此作出回答的任务例如给两幅图片一幅是关于某个任务的简介可能包括了这个人的名字另一幅图里就包含了这个人用户可能就会问到另一幅图里这个人在干什么我们希望模型回答的时候能回答名字而不是说那个人">论文关注的任务是multi-concept
personalization，是要让模型理解并记忆用户自定义的特定概念，由此作出回答的任务。（例如，给两幅图片，一幅是关于某个任务的简介，可能包括了这个人的名字；另一幅图里就包含了这个人，用户可能就会问到另一幅图里这个人在干什么。我们希望模型回答的时候能回答名字，而不是说“那个人”）</h2>
<h2 id="论文创新的点也是现有研究缺乏的点就是大多研究聚焦于single-concept-personalization但是忽略了multi-concept-personalization一次让模型学习多个概念">论文创新的点，也是现有研究缺乏的点，就是：大多研究聚焦于single-concept
personalization，但是忽略了multi-concept
personalization（一次让模型学习多个概念）</h2>
<h1 id="insight">insight：</h1>
<h2 id="指令微调真的很强大感觉论文最主要的部分应该就是收集数据进行指令微调我估计光是这样下来就已经效果不错了至于后面的personalized-textual-prompt以及visual-prompt有点复杂而且有点像在找补提高性能有可能收集数据才是最麻烦的">指令微调，真的很强大……感觉论文最主要的部分应该就是收集数据，进行指令微调。我估计光是这样下来就已经效果不错了。至于后面的personalized
textual prompt以及visual
prompt，有点复杂，而且有点像在找补，提高性能（有可能收集数据才是最麻烦的）</h2>
<h2 id="另外不同领域的指令微调可能区别以及贡献都在于设计相应的合适的微调任务以及指令微调感觉上还是比较能scaling的">另外，不同领域的指令微调，可能区别（以及贡献）都在于设计相应的合适的微调任务。以及，指令微调，感觉上还是比较能scaling的</h2>
<h2 id="不过personalized-vlms这个领域到底有没有意义呢它并不是在扩展模型的能力边界好像不够exciting可是未来如果vlm这些模型继续发展能做到人手一个模型的话是不是需要落实到个性化这个方面呢">不过，personalized
VLMs，这个领域到底有没有意义呢……它并不是在扩展模型的能力边界，好像不够exciting；可是未来如果vlm这些模型继续发展，能做到人手一个模型的话，是不是需要落实到个性化这个方面呢？</h2>
<h1 id="contribution">contribution：</h1>
<h2 id="提出一套训练策略用于提高模型的multi-concept-personalization能力">提出一套训练策略，用于提高模型的multi-concept
personalization能力</h2>
<h2 id="提出一套关于multi-concept-personalization的数据集">提出一套关于multi-concept
personalization的数据集</h2>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/10/03/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/MLLM/MC-LLaVA%EF%BC%9AMulti-Concept%20Personalized%20Vision-Language%20Model/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/30/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/%E5%A4%9A%E6%A8%A1%E6%80%81GraphRAG%E7%9B%B8%E5%85%B3paper%E8%B0%83%E7%A0%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/30/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/%E5%A4%9A%E6%A8%A1%E6%80%81GraphRAG%E7%9B%B8%E5%85%B3paper%E8%B0%83%E7%A0%94/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-30 10:48:01" itemprop="dateCreated datePublished" datetime="2025-09-30T10:48:01+08:00">2025-09-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-10-04 16:26:10" itemprop="dateModified" datetime="2025-10-04T16:26:10+08:00">2025-10-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="acl-25">ACL 25</h1>
<h2 id="query-driven-multimodal-graphrag-dynamic-local-knowledge-graph-construction-for-online-reasoning多模态的多模态graphrag但是用于online-reasoning"><strong>Query-Driven
Multimodal GraphRAG: Dynamic Local Knowledge Graph Construction for
Online Reasoning</strong>（多模态的，多模态GraphRAG，但是用于online
reasoning）</h2>
<h1 id="naacl-25">NAACL 25</h1>
<h2 id="mes-rag-bringing-multi-modal-entity-storage-and-secure-enhancements-to-rag多模态的疑似多模态graphrag并非它的数据组织形式不是graph所以不算是mmgraphrag不过这个感觉关注的点也还好既有回答的精确性也有安全性方面的但重点可能在于它支持多模态的输出"><strong>MES-RAG:
Bringing Multi-modal, Entity-Storage, and Secure Enhancements to
RAG</strong>（多模态的）（疑似多模态GraphRAG）（并非，它的数据组织形式不是Graph，所以不算是MMGraphRAG。不过这个感觉关注的点也还好，既有回答的精确性，也有安全性方面的，但重点可能在于它支持多模态的输出？）</h2>
<h1 id="icml-25">ICML 25</h1>
<h2 id="scenir-visual-semantic-clarity-through-unsupervised-scene-graph-retrieval多模态的但是是scene-graph相关的这个可以算到graphrag吗不过是scene-graph相关的可能有点关系好吧其实这篇是做image-to-image-retrieval的只不过用到了scene-graph这个技术手段而已"><a target="_blank" rel="noopener" href="https://icml.cc/virtual/2025/poster/43841">SCENIR: Visual Semantic
Clarity through Unsupervised Scene Graph
Retrieval</a>（多模态的？但是是scene
graph相关的。这个可以算到GraphRAG吗？）（不过是scene
graph相关的，可能有点关系）（好吧，其实这篇是做image-to-image
retrieval的，只不过用到了scene graph这个技术手段而已）</h2>
<h2 id="recurrence-enhanced-vision-and-language-transformers-for-robust-multimodal-document-retrieval检索多模态的文档不知道有没有相关真不相关吧"><a target="_blank" rel="noopener" href="https://github.com/aimagelab/ReT">Recurrence-Enhanced
Vision-and-Language Transformers for Robust Multimodal Document
Retrieval</a>（检索多模态的文档，不知道有没有相关？）（真不相关吧）</h2>
<h1 id="iccv-25">ICCV 25</h1>
<h2 id="taming-the-untamed-graph-based-knowledge-retrieval-and-reasoning-for-mllms-to-conquer-the-unknown多模态的vlm方面的以及涉及graph其实也不相关不过这篇论文研究的点感觉有一点道理它是想说现在的mllm其实在遇到不熟悉的领域的时候表现不够好毕竟没有这方面的知识而论文想做的似乎是提高mllm利用外部知识的效率主要是通过提出multi-agent-retriever来实现感觉agentic-rag确实是有必要的"><strong>Taming
the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to
Conquer the
Unknown</strong>（多模态的，VLM方面的，以及涉及graph）（其实也不相关。不过这篇论文研究的点感觉有一点道理？它是想说现在的mllm其实在遇到不熟悉的领域的时候，表现不够好，毕竟没有这方面的知识。而论文想做的似乎是提高mllm利用外部知识的效率。主要是通过提出multi-agent
retriever来实现？感觉agentic rag确实是有必要的）</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/SnapKV%EF%BC%9ALLM%20Knows%20What%20You%20Are%20Looking%20for%20before%20Generation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/SnapKV%EF%BC%9ALLM%20Knows%20What%20You%20Are%20Looking%20for%20before%20Generation/" class="post-title-link" itemprop="url">SnapKV：LLM Knows What You Are Looking for before Generation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-09-29 14:31:00 / Modified: 18:42:47" itemprop="dateCreated datePublished" datetime="2025-09-29T14:31:00+08:00">2025-09-29</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/" itemprop="url" rel="index"><span itemprop="name">nlp</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/" itemprop="url" rel="index"><span itemprop="name">llm</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/" itemprop="url" rel="index"><span itemprop="name">efficiency</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/" itemprop="url" rel="index"><span itemprop="name">kv-cache</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="venue">Venue：</h1>
<h1 id="date">date：</h1>
<h1 id="动机">动机：</h1>
<h2 id="多数方法忽视-prompt-的-kv-缓存压缩仅关注generated-token的kv-cache-compression但其实prompt有可能远比generated-token要长比如输入文档的情况下进行文档qa">多数方法<strong>忽视
prompt 的 KV 缓存压缩</strong>，仅关注generated token的KV cache
compression。但其实prompt有可能远比generated
token要长（比如输入文档的情况下，进行文档QA）</h2>
<h1 id="insight">insight：</h1>
<h2 id="论文通过实验发现对于input-seq-tokens是存在一个consistent-attention-allocation-pattern的这为kv-cache-compression提供了可能因为consistent确保了保留下来的kv-cache会尽可能的有用不会说关键token一直在变化那样的话可能我们生成每个token都需要依赖不同的关键token那某个token的kv-cache一旦被剔除后面生成可能又要用到了">论文通过实验发现，对于input
seq tokens，是存在一个consistent attention allocation pattern的。这为kv
cache compression提供了可能。因为，consistent确保了保留下来的kv
cache会尽可能的有用；不会说关键token一直在变化（那样的话，可能我们生成每个token都需要依赖不同的关键token，那某个token的kv
cache一旦被剔除，后面生成可能又要用到了）</h2>
<h2 id="另外在生成之前事先知道这个attention-allocation-pattern是可行的这也很重要因为这个性质我们才能在生成前知道要保留哪些prompt-token的kv-cache">另外，在生成之前，事先知道这个attention
allocation
pattern，是可行的。这也很重要，因为这个性质，我们才能在生成前知道要保留哪些prompt
token的kv cache</h2>
<h1 id="contribution">contribution：</h1>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/efficiency/kv-cache/SnapKV%EF%BC%9ALLM%20Knows%20What%20You%20Are%20Looking%20for%20before%20Generation/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/DrVideo%EF%BC%9ADocument%20Retrieval%20Based%20Long%20Video%20Understanding/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/DrVideo%EF%BC%9ADocument%20Retrieval%20Based%20Long%20Video%20Understanding/" class="post-title-link" itemprop="url">DrVideo：Document Retrieval Based Long Video Understanding</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-09-29 10:41:00 / Modified: 11:27:51" itemprop="dateCreated datePublished" datetime="2025-09-29T10:41:00+08:00">2025-09-29</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/" itemprop="url" rel="index"><span itemprop="name">nlp</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/" itemprop="url" rel="index"><span itemprop="name">llm</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/" itemprop="url" rel="index"><span itemprop="name">RAG</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-RAG/" itemprop="url" rel="index"><span itemprop="name">multi-modal RAG</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="venuecvpr-25">Venue：CVPR 25</h1>
<h1 id="date2024-11-24">date：2024-11-24</h1>
<h1 id="动机">动机：</h1>
<h1 id="insight">insight：</h1>
<h2 id="对于视频我们总是希望找到它的关键帧关键部分并且是希望能一次性地在任务开始时就找到但是其实也未必如此如果采用一种不断完善的方法来寻找视频的关键信息最终也能回答好问题那其实也是可以的就像这篇论文前面的操作其实都是最朴素的操作了可就是因为引入了两个agent所以有弥补的空间可以决定是否要重新去检索关键帧可以决定是否要深挖已有的关键帧">对于视频，我们总是希望找到它的关键帧/关键部分，并且是希望能一次性地在任务开始时就找到。但是其实也未必如此，如果采用一种不断完善的方法来寻找视频的关键信息，最终也能回答好问题，那其实也是可以的。就像这篇论文，前面的操作其实都是最朴素的操作了，可就是因为引入了两个agent，所以有弥补的空间：可以决定是否要重新去检索关键帧；可以决定是否要深挖已有的关键帧</h2>
<h1 id="contribution">contribution：</h1>
<h2 id="再稍微读一下感觉没什么贡献啊可能就引入agent那一步值得说到一下其它感觉都是现有的而且那个retrieval-module不就是一个简单的检索吗这也能包装成一个之前没有的东西吗">再稍微读一下，感觉没什么贡献啊……可能就引入agent那一步值得说到一下，其它感觉都是现有的。而且那个retrieval
module不就是一个简单的检索吗，这也能包装成一个之前没有的东西吗……</h2>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/09/29/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/DrVideo%EF%BC%9ADocument%20Retrieval%20Based%20Long%20Video%20Understanding/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/VideoRAG%EF%BC%9ARetrieval-Augmented%20Generation%20over%20Video%20Corpus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/VideoRAG%EF%BC%9ARetrieval-Augmented%20Generation%20over%20Video%20Corpus/" class="post-title-link" itemprop="url">VideoRAG：Retrieval-Augmented Generation over Video Corpus</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-28 17:05:00" itemprop="dateCreated datePublished" datetime="2025-09-28T17:05:00+08:00">2025-09-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-09-29 10:37:54" itemprop="dateModified" datetime="2025-09-29T10:37:54+08:00">2025-09-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/" itemprop="url" rel="index"><span itemprop="name">nlp</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/" itemprop="url" rel="index"><span itemprop="name">llm</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/" itemprop="url" rel="index"><span itemprop="name">RAG</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-RAG/" itemprop="url" rel="index"><span itemprop="name">multi-modal RAG</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="venueacl-25-findings">Venue：ACL 25 findings</h1>
<h1 id="date2025-05-28">date：2025-05-28</h1>
<h1 id="动机">动机：</h1>
<h2 id="现有rag方法通常忽视了视频模态但视频里其实也包含了很丰富的信息-尽管最近有一些研究在尝试利用视频来辅助回答但它们要么不够动态即人工预先定义好query的几个相关视频或者按照固定规则来定义相关视频要么损失了视频中丰富的信息把视频转成文字描述-因此论文提出videorag来直接检索回query相关的视频能同时利用文字和视觉信息">现有RAG方法通常忽视了视频模态。但视频里其实也包含了很丰富的信息<br>尽管最近有一些研究在尝试利用视频来辅助回答，但它们要么不够动态（即人工预先定义好query的几个相关视频，或者按照固定规则来定义相关视频），要么损失了视频中丰富的信息（把视频转成文字描述）<br>因此论文提出VideoRAG，来直接检索回query相关的视频，能同时利用文字和视觉信息</h2>
<h3 id="关于现有方法不够动态的问题可以举几个例子来理解比如人工预先定义的话可能针对打领带这个query人为的找出两三个教学视频它们的确是打领带的教学视频之后如果有query是关于这个的则它们的参考视频就只会是这两三个而不会从海量的视频候选库里检索">关于现有方法不够动态的问题，可以举几个例子来理解。比如人工预先定义的话，可能针对“打领带”这个query，人为的找出两三个教学视频，它们的确是打领带的教学视频。之后如果有query是关于这个的，则它们的参考视频就只会是这两三个，而不会从海量的视频候选库里检索。</h3>
<h2 id="虽然现在有很多image-text-rag但视频终究是有一些独特的性质导致它不能被图像完全取代吧">虽然现在有很多image-text
RAG，但视频终究是有一些独特的性质，导致它不能被图像完全取代吧</h2>
<h1 id="insight">insight：</h1>
<h2 id="判断视频是否和query相关其实也很重要千万不能忽视这一点否则检索的空间太大了">判断视频是否和query相关，其实也很重要。千万不能忽视这一点，否则检索的空间太大了</h2>
<h2 id="视频模态的特点感觉体现在包括但不限于以下的几方面">视频模态的特点，感觉体现在（包括但不限于以下的几方面）：</h2>
<h3 id="多帧之间的时序关系">多帧之间的时序关系</h3>
<h3 id="画面图像和文本语音之间的对应关系">画面（图像）和文本/语音之间的对应关系</h3>
<h1 id="contribution">contribution：</h1>
<h2 id="支持了动态视频的检索包括能动态判断哪些视频是相关的并从中提取信息用于辅助生成">支持了动态视频的检索，包括能动态判断哪些视频是相关的，并从中提取信息用于辅助生成</h2>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/multi-modal-rag/video-understanding/VideoRAG%EF%BC%9ARetrieval-Augmented%20Generation%20over%20Video%20Corpus/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blueeemouse.github.io/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/video%E7%9B%B8%E5%85%B3%E7%9A%84RAGpaper%E8%B0%83%E7%A0%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bluemouse">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bluemouse's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/09/28/%E8%AE%BA%E6%96%87%E5%92%8C%E5%8D%9A%E5%AE%A2%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/nlp/llm/RAG/video%E7%9B%B8%E5%85%B3%E7%9A%84RAGpaper%E8%B0%83%E7%A0%94/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2025-09-28 15:55:06 / Modified: 17:00:02" itemprop="dateCreated datePublished" datetime="2025-09-28T15:55:06+08:00">2025-09-28</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="acl-25">ACL 25</h1>
<h2 id="videorag-retrieval-augmented-generation-over-video-corpus多模态的视频相关"><strong>VideoRAG:
Retrieval-Augmented Generation over Video
Corpus</strong>（多模态的，视频相关）</h2>
<h1 id="iclr-25">ICLR 25</h1>
<h2 id="tempme-video-temporal-token-merging-for-efficient-text-video-retrieval多模态的video和efficiency结合的看起来是在压缩video输入的也算是video相关的">TempMe:
Video Temporal Token Merging for Efficient Text-Video
Retrieval（多模态的，video和efficiency结合的，看起来是在压缩video输入的。也算是video相关的）</h2>
<h2 id="generalized-video-moment-retrieval多模态的video相关">Generalized
Video Moment Retrieval（多模态的,video相关）</h2>
<h1 id="nips-24">NIPS 24</h1>
<h2 id="diffusion-inspired-truncated-sampler-for-text-video-retrievaltext-video-retrieval">Diffusion-Inspired
Truncated Sampler for Text-Video Retrieval（text-video retrieval）</h2>
<h1 id="cvpr-25">CVPR 25</h1>
<h2 id="drvideo-document-retrieval-based-long-video-understanding真对口了长视频理解方面的"><strong>DrVideo:
Document Retrieval Based Long Video
Understanding</strong>（真对口了，长视频理解方面的）</h2>
<h2 id="salova-segment-augmented-long-video-assistant-for-targeted-retrieval-and-routing-in-long-form-video-analysis这也是经典了也是长视频理解这一块的">SALOVA:
Segment-Augmented Long Video Assistant for Targeted Retrieval and
Routing in Long-Form Video
Analysis（这也是经典了，也是长视频理解这一块的）</h2>
<h2 id="vlog-video-language-models-by-generative-retrieval-of-narration-vocabulary似乎是video相关的但是理解方面的吗"><strong>VLog:
Video-Language Models by Generative Retrieval of Narration
Vocabulary</strong>（似乎是video相关的，但是理解方面的吗？）</h2>
<h2 id="learning-audio-guided-video-representation-with-gated-attention-for-video-text-retrieval又是text-video-retrieval啊"><strong>Learning
Audio-guided Video Representation with Gated Attention for Video-Text
Retrieval</strong>（又是text-video retrieval啊）</h2>
<h2 id="rethinking-noisy-video-text-retrieval-via-relation-aware-alignment还是text-video-retrieval"><strong>Rethinking
Noisy Video-Text Retrieval via Relation-aware
Alignment</strong>（还是text-video retrieval）</h2>
<h2 id="video-colbert-contextualized-late-interaction-for-text-to-video-retrieval还是text-to-video-retrieval"><strong>Video-ColBERT:
Contextualized Late Interaction for Text-to-Video
Retrieval</strong>（还是text-to-video retrieval）</h2>
<h2 id="multivent-2.0-a-massive-multilingual-benchmark-for-event-centric-video-retrievalbenchmark类不过是关于video-retrieval的"><strong>MultiVENT
2.0: A Massive Multilingual Benchmark for Event-Centric Video
Retrieval</strong>（benchmark类，不过是关于video retrieval的）</h2>
<h2 id="the-devil-is-in-the-prompts-retrieval-augmented-prompt-optimization-for-text-to-video-generation不会是prompt-engineering吧关注text-to-video-generation文生视频吗"><strong>The
Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for
Text-to-Video Generation</strong>（不会是prompt
engineering吧……）（关注text-to-video generation？文生视频吗？）</h2>
<h2 id="narrating-the-video-boosting-text-video-retrieval-via-comprehensive-utilization-of-frame-level-captionstext-to-video-retrieval"><a target="_blank" rel="noopener" href="https://multimodal-understanding-group.github.io/NarVid/">Narrating
the Video: Boosting Text-Video Retrieval via Comprehensive Utilization
of Frame-Level Captions</a>（text-to-video retrieval）</h2>
<h2 id="discovla-discrepancy-reduction-in-vision-language-and-alignment-for-parameter-efficient-video-text-retrieval呃efficiency和video结合text-to-video-retrieval"><a target="_blank" rel="noopener" href="https://github.com/LunarShen/DsicoVLA">DiscoVLA: Discrepancy
Reduction in Vision, Language, and Alignment for Parameter-Efficient
Video-Text Retrieval</a>（呃，efficiency和video结合，text-to-video
retrieval）</h2>
<h1 id="iccv-25">ICCV 25</h1>
<h2 id="hybrid-tower-fine-grained-pseudo-query-interaction-and-generation-for-text-to-video-retrievaltext-to-video-retrievalvideo相关"><strong>Hybrid-Tower:
Fine-grained Pseudo-query Interaction and Generation for Text-to-Video
Retrieval</strong>（text-to-video retrieval，video相关）</h2>
<h2 id="beyond-simple-edits-composed-video-retrieval-with-dense-modificationscomposed-video-retrievalvideo相关的"><strong>Beyond
Simple Edits: Composed Video Retrieval with Dense
Modifications</strong>（Composed Video Retrieval，video相关的）</h2>
<h2 id="borrowing-eyes-for-the-blind-spot-overcoming-data-scarcity-in-malicious-video-detection-via-cross-domain-retrieval-augmentation这是啥video-detection嗯也算是video相关的但应该是那种low-level的video相关工作"><a target="_blank" rel="noopener" href="https://github.com/ronpay/CRAVE">Borrowing Eyes for the Blind
Spot: Overcoming Data Scarcity in Malicious Video Detection via
Cross-Domain Retrieval Augmentation</a>（这是啥？video
detection？嗯，也算是video相关的，但应该是那种low-level的video相关工作）</h2>
<h2 id="enhancing-partially-relevant-video-retrieval-with-hyperbolic-learningvideo-retrieval"><strong>Enhancing
Partially Relevant Video Retrieval with Hyperbolic
Learning</strong>（video retrieval）</h2>
<h2 id="ophclip-hierarchical-retrieval-augmented-learning-for-ophthalmic-surgical-video-language-pretraining这是不太懂不过看起来是video相关的"><strong>OphCLIP:
Hierarchical Retrieval-Augmented Learning for Ophthalmic Surgical
Video-Language
Pretraining</strong>（这是？不太懂，不过看起来是video相关的）</h2>
<h2 id="quantifying-and-narrowing-the-unknown-interactive-text-to-video-retrieval-via-uncertainty-minimizationtext-to-video-retrievalvideo相关"><strong>Quantifying
and Narrowing the Unknown: Interactive Text-to-Video Retrieval via
Uncertainty Minimization</strong>（text-to-video
retrieval，video相关）</h2>
<h2 id="prototypes-are-balanced-units-for-efficient-and-effective-partially-relevant-video-retrievalvideo-retrievalvideo相关"><strong>Prototypes
are Balanced Units for Efficient and Effective Partially Relevant Video
Retrieval</strong>（video retrieval，video相关）</h2>
<h2 id="bidirectional-likelihood-estimation-with-multi-modal-large-language-models-for-text-video-retrievaltext-to-video-retrievalvideo相关"><strong>Bidirectional
Likelihood Estimation with Multi-Modal Large Language Models for
Text-Video Retrieval</strong>（text-to-video retrieval，video相关）</h2>
<h1 id="eccv-24">ECCV 24</h1>
<h2 id="rethinking-video-text-understanding-retrieval-from-counterfactually-augmented-datavideo-text-understanding具体是做啥是video理解方面的吗"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/2083_ECCV_2024_paper.php">Rethinking
Video-Text Understanding: Retrieval from Counterfactually Augmented
Data</a>（video-text
understanding？具体是做啥？是video理解方面的吗？）</h2>
<h2 id="rgnet-a-unified-clip-retrieval-and-grounding-network-for-long-videoslong-video相关的不知道是不是长视频理解这方面的"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/3186_ECCV_2024_paper.php">RGNet:
A Unified Clip Retrieval and Grounding Network for Long Videos</a>（long
video相关的，不知道是不是长视频理解这方面的）</h2>
<h2 id="kdpror-a-knowledge-decoupling-probabilistic-framework-for-video-text-retrievaltext-to-video-retrievalvideo相关"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/5033_ECCV_2024_paper.php">KDProR:
A Knowledge-Decoupling Probabilistic Framework for Video-Text
Retrieval</a>（text-to-video retrieval，video相关）</h2>
<h2 id="egocvr-an-egocentric-benchmark-for-fine-grained-composed-video-retrieval细粒度composed-video-retrieval"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/5363_ECCV_2024_paper.php">EgoCVR:
An Egocentric Benchmark for Fine-Grained Composed Video
Retrieval</a>（细粒度Composed Video Retrieval）</h2>
<h2 id="uncertainty-aware-sign-language-video-retrieval-with-probability-distribution-modelingvideo-retrievalvideo相关"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/6074_ECCV_2024_paper.php">Uncertainty-aware
sign language video retrieval with probability distribution
modeling</a>（video retrieval，video相关）</h2>
<h2 id="ea-vtr-event-aware-video-text-retrievaltext-to-video-retrievalvideo相关"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/6845_ECCV_2024_paper.php">EA-VTR:
Event-Aware Video-Text Retrieval</a>（text-to-video
retrieval，video相关）</h2>
<h2 id="rap-retrieval-augmented-planner-for-adaptive-procedure-planning-in-instructional-videosvideo相关的但是具体是做什么的"><a target="_blank" rel="noopener" href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/9950_ECCV_2024_paper.php">RAP:
Retrieval-Augmented Planner for Adaptive Procedure Planning in
Instructional Videos</a>（video相关的，但是具体是做什么的？）</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">bluemouse</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">256</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">83</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">104</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bluemouse</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
